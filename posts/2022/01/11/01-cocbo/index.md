---
tags: [tech, C++]
---

# クラスタサイズを指定できるk-meansベースのクラスタリング手法を実装した話

あけましておめでとうございます。季節感もなにもないブログですが、修論締切間近の時期に研究で使った技術をまとめようという点は季節感かもしれません。

今回のネタは、クラスタサイズに制約を設けてクラスタリングをしようという話です。

クラスタリングといったら、もっとも代表的な手法は k-means です。 k-means は<b>クラスタ数</b>を事前に指定して、クラスタリングを行います。つまり、 k-means を使うときは、データを <var>k</var> 個に分けたら何か傾向が見えるかもな～という気持ちで使うことになります。このとき、1クラスタに属するデータ数（<b>クラスタサイズ</b>）は、クラスタごとに異なります。

では、クラスタサイズを事前に指定するような方法はないのでしょうか。データが大量にあるので、データを <var>c</var> 個に均等に分割して処理したいな～というときに、どうしたらいいのでしょうか。というわけで今日の論文紹介です。

- [最適化に基づくマージン付きサイズ均等クラスタリングアルゴリズム](https://www.jstage.jst.go.jp/article/fss/32/0/32_329/_article/-char/ja)
- [Controlled-sized clustering based on optimization](https://ieeexplore.ieee.org/document/8023341)

上が日本語版、下が英語版で、書いてあることは同じです。この論文では、クラスタサイズの基準 <var>K</var> と、クラスタサイズの下限 $\underline{K}$ 、上限 $\overline{K}$ を指定すると、クラスタサイズがこの範囲内に収まるようにいい感じにクラスタリングする方法が示されています。英語版では、このアルゴリズムを COCBO と呼んでいるので、この記事でも COCBO と呼んでいこうと思います。

## アルゴリズムの説明

パラメータは、クラスタサイズの基準 <var>K</var> と、クラスタサイズの下限 $\underline{K}$ 、上限 $\overline{K}$ です。このとき、このアルゴリズムを使うと、$c = \left\lfloor \frac{n}{K} \right\rfloor$ 個（<var>n</var> はデータ数）のクラスタにクラスタリングすることができます。ただし、以下の条件を満たす必要があります。

$$
\begin{align}
\underline{K} & \leq K \\
\overline{K} & \geq K+1 \\
0 < n & \leq (K+1) \left\lfloor \frac{n}{K} \right\rfloor
\end{align}
$$

最後の条件は、次に説明する最適化問題を解いたときに、すべてのデータをいずれかのクラスタに属させることができるかを表しています。

では、アルゴリズムの中身に行きます。アルゴリズムのベースは k-means ですが、データがどのクラスタに属するかを計算する部分が異なります。 k-means では、各データがもっとも近い重心のクラスタに属するよう帰属度を更新していました。この部分を、クラスタサイズを制約条件とする線形計画問題として解いてしまおうというのが、 COCBO のアイデアです。別の言い方をすると、先の条件を満たしていれば、この問題は線形計画問題に落とし込めるという発見です。

アルゴリズムの流れはこのようになります。

1. 初期のクラスタ重心を設定する。データからランダムに <var>c</var> 個を選んで重心にすれば良い。
2. 帰属度（データがどのクラスタに属するか）を更新する。
3. クラスタ重心を更新する。重心は、クラスタに属するデータの平均となる。
4. クラスタ重心が変化しなければ終了、そうでなければ、2へ。

手順2以外は k-means と同じになります。

では、どのように帰属度を求めるのか見ていきましょう。まず記号を定義していきます。クラスタ重心を $v_i \ (i=1,\cdots,c)$ と表します。帰属度を $u_{ki} \ (k=1,\cdots,n, \quad i=1,\cdots,c)$ と表します。データ $x_k$ がクラスタ <var>i</var> に属するときを $u_{ki}=1$ 、そうでないときを $u_{ki}=0$ と表します。

このとき、次の目的関数を最小化する問題を考えます。目的変数はすべての $u_{ki}$ です。つまり重心からの距離を最小化するような帰属度を求めるということです。

$$
\begin{equation}
J = \sum_{k=1}^n \sum_{i=1}^c u_{ki} \| x_k - v_i \| ^2
\end{equation}
$$

制約条件は、次のふたつです。

$$
\begin{align}
\sum_{i=1}^c u_{ki} = 1 \quad & (k=1,\cdots,n) \\
\underline{K} \leq \sum_{k=1}^n u_{ki} \leq \overline{K} \quad & (i=1,\cdots,c)
\end{align}
$$

ひとつ目は、データはひとつのクラスタだけに属していることを表します。ふたつ目は、各クラスタがクラスタサイズ制約を満たしていることを表します。ひとつ目の制約は、すべての <var>k</var> について考える必要があり、ふたつ目の制約は、すべての <var>i</var> について考える必要があります。つまり、制約条件は $nc$ 個あります。

この最適化問題はシンプレックス法で解くことができます。シンプレックス法って何？ 調べてみましたが、行列で連立方程式を解く懐かしく面倒くさい方法を思い出させられたのでつらくなりました。 Wikipedia によれば、計算回数は、ほとんどの場合、変数の数か制約条件の数の大きい方の回数だけ反復することになるらしいので、このアルゴリズムでは大体 $nc$ 回の計算をすれば解けることがわかります。

## mlpack と GLPK を使って実装する

研究の都合上、私のブログでは珍しく C++ です。

シンプレックス法に入力できる制約条件はわかりましたが、アルゴリズムは頭が理解を拒否するので、線形計画問題を解いてくれるライブラリを使っていきます。 <kbd>apt search</kbd> で良いライブラリがないか探していたところ、 [GLPK (GNU Linear Programming Kit)](https://www.gnu.org/software/glpk/) というのを見つけたので、これを使っていきます。他にも線形計画問題を解くライブラリはありますが、使えるかは調べていません。今回解く問題では、目的変数の値が0か1しか取れないという条件があるので、これを表せる必要があります。

それから、 C++ 界の numpy として、 [mlpack](https://www.mlpack.org/) と [Armadillo](http://arma.sourceforge.net/) を使っていきます。 mlpack には k-means の実装があるので、それに似せて作っていきましょう。

まず、作成する関数のシグネチャです。

```cpp
#include <mlpack/core.hpp>

void ClusterWithCocbo(const arma::mat &data, size_t k, size_t lower_bound,
                      size_t upper_bound, arma::Row<size_t> &assignments,
                      arma::mat &centroids, size_t max_iterations = 1000);
```

入力引数に、データとパラメータ、最大繰り返し回数を取り、出力引数に、各データがどのクラスタに属するかと、重心を取ります。 <var>data</var> はひとつのデータを縦ベクトルとした行列です。つまり、行数がデータの次元数、列数がデータ数となります。

TODO: GLPK の使い方
