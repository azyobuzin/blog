<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ja-JP"><author><name>azyobuzin</name><uri>https://twitter.com/azyobuzin</uri></author><id>https://blog.azyobuzi.net/feed.atom</id><link href="https://blog.azyobuzi.net/feed.atom" rel="self" type="application/atom+xml" /><link href="https://blog.azyobuzi.net/" rel="alternate" type="text/html" /><title>あじょろぐ</title><updated>2021-10-15T16:31:38+09:00</updated><entry><content type="html">&#x3C;p>こんにちは。 Xperia Ace II ユーザーです。どうもこのクソスマホ、もともとエントリークラスということもあり、あんまりレビューが荒れていない印象があります。しかし、使い込むほどにボロが出てくるので、もしも安さやサイズだけで買おうとしている皆様に警告をしようと思い、メモを残しておきます。&#x3C;/p>
&#x3C;h2>なぜ買った？&#x3C;/h2>
&#x3C;figure class="fig-tweet">
&#x3C;blockquote class="twitter-tweet" data-dnt="true">&#x3C;p lang="ja" dir="ltr">左から順に、最高、妥協、大妥協 &#x3C;a href="https://t.co/dR0hfGfqec">pic.twitter.com/dR0hfGfqec&#x3C;/a>&#x3C;/p>— あじょぶじん (@azyobuzin) &#x3C;a href="https://twitter.com/azyobuzin/status/1398260223115030530?ref_src=twsrc%5Etfw">May 28, 2021&#x3C;/a>&#x3C;/blockquote>
&#x3C;/figure>
&#x3C;p>もともと Xperia XZ1 Compact ユーザーでしたが、3年以上が経過し、ストレージ 32GB に限界を感じていたので乗り換えました。あまりにもコンパクトスマホが出ないので、来年の新商品を待とうと思い、つなぎとして安くてコンパクトな Ace II を買いました。今思うと XZ1 Compact は下取りに出さないで、ゲーム機として取っておけばよかったなぁと思いましたが後の祭り。&#x3C;/p>
&#x3C;h2>ここが微妙だよ Ace II&#x3C;/h2>
&#x3C;p>ほぼ全部微妙です。なぜなら微妙な価格帯なので。それはともかく、いにしえの SoC に最新の Android を乗せたみたいな機種なので、そもそも動作が怪しいところがあります。というわけで、困る順に紹介していきます。&#x3C;/p>
&#x3C;h3>モバイル Suica 関連が異常に遅い&#x3C;/h3>
&#x3C;p>残高を調べたい？ 余裕をもって行動しましょう。モバイル Suica アプリを起動したり、 Google Pay アプリで残高を更新すると、最低で 20 秒、最大で 2 分程度待つことになります。&#x3C;/p>
&#x3C;p>チャージも同様です。私は Google Pay しか使ったことがないですが、チャージボタンを押してから通信が安定した場所で数分放置する必要があります。すぐに反映されることを期待してはいけません。また反映されないからといってやり直したら二重にチャージされます。必要なのは忍耐力です。&#x3C;/p>
&#x3C;p>さて、最高に深刻なのが楽天ペイの Suica 連携機能です。これは運です。基本的にはこうなります。&#x3C;/p>
&#x3C;figure class="fig-img">&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20210929/20210929143248.jpg" alt="エラーコード: AA_JRF3005">&#x3C;/figure>
&#x3C;p>このエラーメッセージでググっても完全一致は見当たらなかったので、本当に機種依存バグ案件に思えます。「お問い合わせ先」は Suica になってるので、楽天ペイの案件をこの窓口に投げるのもなーという気持ちになって放置しています。&#x3C;/p>
&#x3C;p>楽天ペイの Suica を使う方法は、スマホを再起動して、起動直後かつちょっと安定したくらいのタイミングで使うことです。運が良ければ楽天ペイ経由でチャージできるのではないでしょうか。&#x3C;/p>
&#x3C;h3>指紋認証がリセットされる&#x3C;/h3>
&#x3C;p>再起動すると、指紋認証の設定を変えていなくても、指を再登録したという扱いになります。例えば Bitwarden アプリだとこんな感じに。&#x3C;/p>
&#x3C;figure class="fig-img">&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20211015/20211015162228.jpg" alt="「生体認証の変更が検出されました。マスターパスワードを使用してログインすると再度有効化できます。」">&#x3C;/figure>
&#x3C;p>これが致命的なのが、住信SBIネット銀行のアプリで、指を再登録すると2要素認証の設定を最初からやり直すことになります。つまり再起動するたびに再設定する羽目に。&#x3C;/p>
&#x3C;h3>Twitter がたびたび落ちる&#x3C;/h3>
&#x3C;p>かわいい美少女イラストを見ていると落ちます。画像表示回りに機種依存バグがありそうです。しんどいね。&#x3C;/p>
&#x3C;h3>Wi-Fi の出力が弱すぎる&#x3C;/h3>
&#x3C;p>自宅では、もっともアクセスポイントから遠い部屋に生息しているのですが Wi-Fi 5 (11ac) の 5GHz がまったく安定しません。 XZ1 Compact ではギリギリセーフ、 iPad Air 2 は余裕という感じですが、 Ace II はギリギリアウトでした。単純に出力が弱そうという感じです。&#x3C;/p>
&#x3C;p>ということもあって 11n (2.4GHz) をメインに使っています。が、どうあがいてもリンク速度が 65Mbps にしかならない（電波強度の問題ではなく、これが限界っぽい）ので、もう高速インターネットは諦めました。&#x3C;/p>
&#x3C;h3>ゲームはできないと思え&#x3C;/h3>
&#x3C;p>そう思って買ったけど、想像以上に無理でした。&#x3C;/p>
&#x3C;figure class="fig-tweet">
&#x3C;blockquote class="twitter-tweet" data-conversation="none" data-dnt="true">&#x3C;p lang="ja" dir="ltr">なんとか回収してきたけど、ゲーム困難スマホすぎて画面遷移ごとに1年が経過しそうなレベル。画面移動だけで疲れて音ゲーやろうという気にならなかった…… &#x3C;a href="https://t.co/n1yfwRXyTp">pic.twitter.com/n1yfwRXyTp&#x3C;/a>&#x3C;/p>— あじょぶじん (@azyobuzin) &#x3C;a href="https://twitter.com/azyobuzin/status/1435656383400067072?ref_src=twsrc%5Etfw">September 8, 2021&#x3C;/a>&#x3C;/blockquote>
&#x3C;figcaption>画面遷移ごとに10秒以上待たされて疲れてしまった図&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;figure class="fig-tweet">
&#x3C;blockquote class="twitter-tweet" data-dnt="true">&#x3C;p lang="ja" dir="ltr">Xperia Ace 2 ユナイトチャレンジ、ここで落ちるので終了 &#x3C;a href="https://t.co/ziF7rTXryN">pic.twitter.com/ziF7rTXryN&#x3C;/a>&#x3C;/p>— あじょぶじん (@azyobuzin) &#x3C;a href="https://twitter.com/azyobuzin/status/1440895715316699138?ref_src=twsrc%5Etfw">September 23, 2021&#x3C;/a>&#x3C;/blockquote>&#x3C;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&#x3C;/script>
&#x3C;figcaption>ポケモンユナイトの起動すら叶わなかった図&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>ついでに、&#x3C;a href="https://stopcovid19.metro.tokyo.lg.jp/">「&#x3C;cite>東京都 新型コロナウイルス感染症対策サイト&#x3C;/cite>」&#x3C;/a>のグラフを見るのもなかなかストレスフルです。ユニバーサルデザイン（軽量化）が求められている。&#x3C;/p>
&#x3C;h3>そもそも Xperia ではない&#x3C;/h3>
&#x3C;p>Xperia といえばウォークマン由来のエフェクト機能ですよね。 XZ1 Compact には ClearAudio+ とか DSEE とかがありました。 Ace II にはそんなもの一切ありません。まぁ使わないので大した問題ではないのですが、これ本当に Xperia なのかな。&#x3C;/p>
&#x3C;h2>一応いいところも挙げましょう&#x3C;/h2>
&#x3C;h3>安い、コンパクト&#x3C;/h3>
&#x3C;p>安いです。ノリで機種変できます。&#x3C;/p>
&#x3C;p>コンパクト、嘘です。しかしこのスマホ巨大化時代においては相対的にコンパクトです。だから仕方なく買いました。仕方なく。&#x3C;/p>
&#x3C;h3>意外とマクロでピントが合うカメラ&#x3C;/h3>
&#x3C;p>カメラもまあまあお察しな性能で、適当に触って映えるということはほぼないのですが、扱い方がわかってくると、得意な撮り方がわかってきました。&#x3C;/p>
&#x3C;p>かなり寄って撮影してもピントが合います。これは XZ1 Compact はちょっと苦手な部類だったはずなので、びっくりしました。&#x3C;/p>
&#x3C;figure class="fig-img">
&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20210909/20210909180236.jpg" alt="">
&#x3C;figcaption>丸亀製麵のトマたまカレーうどん&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>あとは、すべて自動で任せないで、明るさを調整したり HDR のオンオフを切り替えたり、余裕があるときはしっかりパラメータをいじると、たまに当たりが出ます。&#x3C;/p>
&#x3C;figure class="fig-img">
&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20210925/20210925154247.jpg" alt="">
&#x3C;figcaption>何度か調整した玉ねぎ（泉の森 郷土民家園）&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;h2>まとめ&#x3C;/h2>
&#x3C;p>やめとけ&#x3C;/p></content><id>https://blog.azyobuzi.net/2021/09/29/01-xperia/</id><link href="https://blog.azyobuzi.net/2021/09/29/01-xperia/" rel="alternate" type="text/html" /><link href="https://pbs.twimg.com/media/E2eeQl3VcAAByCy?format=jpg&#x26;name=large" rel="enclosure" /><published>2021-09-29T15:27:00+09:00</published><title type="html">Xperia Ace II (SO-41B) に関するメモ</title><updated>2021-10-15T16:31:38+09:00</updated></entry><entry><category term="tech" label="tech" /><category term="JavaScript" label="JavaScript" /><content type="html">&#x3C;p>blog.azyobuzi.net を開設して1年強、メンテナンスも AsciiDoc も面倒になってきて、はてなブログに戻るのもアリだなぁという気持ちが若干発生してきていました。そもそもブログ自体書いてないじゃん。はい。すいません。&#x3C;/p>
&#x3C;p>AsciiDoc というか Asciidoctor を使うことに思うところがあり、 Gatsby + Asciidoctor.js という構成をやめ、 Markdown + お手製静的サイトジェネレータ という構成に変更したというお話です。&#x3C;/p>
&#x3C;p>（AsciiDoc から Markdown への移行は9月の頭には完了していましたが、記事を書く余裕がなかったので、今書いています。）&#x3C;/p>
&#x3C;h2>なぜ Markdown&#x3C;/h2>
&#x3C;p>このブログを開設して最初の記事で、なぜ AsciiDoc を選んだかを説明しました。&#x3C;/p>
&#x3C;figure class="fig-quote">
&#x3C;blockquote cite="https://blog.azyobuzi.net/2020/04/04/01-hello-gatsby/">
&#x3C;p>プレーンな Markdown （GitHub Flavored ではない）を思い出してください。機能が何もかも足りていないですね。&#x3C;/p>
&#x3C;p>Markdown 処理系を思い出してください。いくつ方言があるんだよお前ら。&#x3C;/p>
&#x3C;p>というわけで、プレーンな Markdown は弱すぎ、方言はみんなバラバラ、 Markdown 対応サービス間でもコピペしたあとに修正を加えるなんて日常茶飯事な、そんなマークアップ言語で書きたくはありません。そこで、もともと機能が豊富で、さらに要素の拡張方法も仕様に含まれている AsciiDoc を採用することにしました。機能豊富なぶん、 HTML への変換結果と、それに必要なスタイルシートがつらいという問題はありますが、該当機能を使うまでは問題を先延ばしにできます。先延ばしていけ。&#x3C;/p>
&#x3C;/blockquote>
&#x3C;figcaption>3. なぜ AsciiDoc, &#x3C;a href="https://blog.azyobuzi.net/2020/04/04/01-hello-gatsby/">&#x3C;cite>さよならはてなブログ、こんにちはGatsby&#x3C;/cite>&#x3C;/a>&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>うんうん……。正直今ならほとんど反論できますね……。&#x3C;/p>
&#x3C;p>まずは方言問題。使ってみてわかりましたが、 Asciidoctor という方言は強烈です。オリジナルの AsciiDoc に対する拡張がかなりあります。結局 Asciidoctor という方言を書くことになってしまいました。対して Markdown は &#x3C;a href="https://commonmark.org/">CommonMark&#x3C;/a> という最小かつ曖昧さのほとんどない仕様が存在します。またデファクトスタンダードである &#x3C;a href="https://github.github.com/gfm/">GitHub Flavored Markdown&#x3C;/a> は、 CommonMark への機能追加という形で仕様が公開されています。さまざまな方言があるように見えますが、 CommonMark 以外に目を向けなければ、かなり安定した仕様と言えます。&#x3C;/p>
&#x3C;p>そして次に、 AsciiDoc は&#x3C;q>機能豊富なぶん、 HTML への変換結果と、それに必要なスタイルシートがつらい&#x3C;/q>と書きましたが、これがかなりつらさにつながっていました。ブログを書いて Web に公開するとはどういうことかというと、 HTML をアウトプットするということです。セマンティックの正しい HTML を出力することについて、 AsciiDoc の機能および Asciidoctor の出力はかなりの足かせになってしまいました。私は HTML が書きたいのであって、 AsciiDoc や DocBook を書きたいわけではないのです。この点において Markdown はとても優秀なツールです。 CommonMark の機能はほぼ HTML タグと1対1対応になっており、簡単に出力される HTML を予想することができます。また CommonMark では HTML をインラインまたはブロックとして直接書くことも許されています（AsciiDoc にも Passthrough Block という機能がありますが）。つまり Markdown に不満があったら HTML を書けばいいのです。 Markdown に多くを求めなければ Markdown は HTML の糖衣構文として使うことができるのです。&#x3C;/p>
&#x3C;p>このような背景で、 Markdown への移行を決めました。基本方針は GitHub Flavored Markdown にある機能だけを使い、より複雑なことがしたいならば HTML を手書きする です。追加機能が欲しい場合は、カスタム要素を使用します（カスタム要素は静的サイトジェネレータで処理されます。インタラクティブな要素が必要になったときは、そのまま出力して Web Components にしてしまおうと考えています）。 Markdown 自体は拡張しません。&#x3C;/p>
&#x3C;h2>静的サイトジェネレータ&#x3C;/h2>
&#x3C;p>Next.js や Gatsby を一度でも使ったことがあれば共感していただけると思うのですが、 JSX って HTML テンプレート言語として最強だと思うんですよ。ということで JSX を捨てたくなかったのですが、どのツールもブラウザに React をロードさせることが前提になっていました。 Gatsby の時代は過激な名前のプラグインをインストールして &#x3C;code>&#x26;#x3C;script>&#x3C;/code> タグを潰していましたね。&#x3C;/p>
&#x3C;figure class="fig-quote">
&#x3C;blockquote cite="https://blog.azyobuzi.net/2020/04/04/01-hello-gatsby/">
&#x3C;p>私が作りたいのは React でできたサイトではなく、ブログ本文が書かれた HTML が置いてあるだけのシンプルなブログです。 PWA でプリロード？ 知らん、読むかもわからんページを先読みしたところでたかが知れてるし、そのスクリプト分だけデータ量は増え、ブラウザの負荷もあります。エコじゃない。&#x3C;/p>
&#x3C;p>&#x3C;a href="https://www.gatsbyjs.org/packages/gatsby-plugin-no-javascript/">gatsby-plugin-no-javascript&#x3C;/a> という過激な名前のサードパーティープラグインがあり、吐き出される HTML の script タグを全部消し去ります。今は特に動的な部分はないので、これで満足しています。&#x3C;/p>
&#x3C;/blockquote>
&#x3C;figcaption>5.1. ブラウザにとって静的なサイトになりたい, &#x3C;a href="https://blog.azyobuzi.net/2020/04/04/01-hello-gatsby/">&#x3C;cite>さよならはてなブログ、こんにちはGatsby&#x3C;/cite>&#x3C;/a>&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>というわけで JSX を書けて React に依存しないものを探していました。ツールは見つかりませんでしたが、いい感じのライブラリは見つけました。 &#x3C;a href="https://github.com/syntax-tree/hastscript">hastscript&#x3C;/a>。これで JSX 構文で AST を吐き出すことができます。&#x3C;/p>
&#x3C;h3>remark, rehype, unified&#x3C;/h3>
&#x3C;p>最近 JavaScript で Markdown を解析するなら &#x3C;a href="https://github.com/remarkjs/remark">remark&#x3C;/a> が最有力でしょうか？ remark は &#x3C;a href="https://github.com/unifiedjs/unified">unified&#x3C;/a> という共通 AST 処理基盤を利用する仕組みになっており、 Markdown → Markdown AST (&#x3C;a href="https://github.com/syntax-tree/mdast">mdast&#x3C;/a>) → HTML AST (&#x3C;a href="https://github.com/syntax-tree/hast">hast&#x3C;/a>) → HTML といった変換工程を簡単に書くことができます。嘘です。すでに用意されてるパッケージを使うだけならうまく隠蔽されていますが、パイプラインとしてはなかなか最悪の実装になっており、それを理解してプラグインを自作することになります。&#x3C;/p>
&#x3C;p>今見ているこのページの Markdown は、こんな感じのパイプラインで HTML 化されています。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>Markdown 処理パイプライン (&#x3C;a href="https://github.com/azyobuzin/blog/blob/7913138eff88596512ec8403c17005bba57beb31/generator/lib/posts.ts#L361-L385" rel="external">posts.ts&#x3C;/a>)&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-js">&#x3C;span class="hljs-keyword">const&#x3C;/span> processor = &#x3C;span class="hljs-title hljs-function">unified&#x3C;/span>()
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(remarkParse) &#x3C;span class="hljs-comment">// remark-parse (Parser): Markdown → mdast （この後の「拡張のロード」はここで使われる）&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(remarkGfm) &#x3C;span class="hljs-comment">// remark-gfm: GFM 拡張のロード&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(remarkFrontmatter) &#x3C;span class="hljs-comment">// remark-frontmatter: --- で囲まれた frontmatter を mdast のノードとして出力させる拡張のロード&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(remarkExtractFrontmatter, {
    &#x3C;span class="hljs-attr">yaml&#x3C;/span>: yaml.&#x3C;span class="hljs-property">parse&#x3C;/span>,
    &#x3C;span class="hljs-attr">name&#x3C;/span>: &#x3C;span class="hljs-string">"frontmatter"&#x3C;/span>,
    &#x3C;span class="hljs-attr">throws&#x3C;/span>: &#x3C;span class="hljs-literal">true&#x3C;/span>,
  }) &#x3C;span class="hljs-comment">// remark-extract-frontmatter: ↑ を AST からメタデータ領域にコピーしてくる&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(extractTitle) &#x3C;span class="hljs-comment">// 独自: # (h1) をタイトルとして扱う&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(remarkMath) &#x3C;span class="hljs-comment">// remark-math: $ で囲まれた部分を math ノードとして扱う拡張のロード&#x3C;/span>
  &#x3C;span class="hljs-comment">// Markdown ここまで&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(remarkRehype, { &#x3C;span class="hljs-attr">allowDangerousHtml&#x3C;/span>: &#x3C;span class="hljs-literal">true&#x3C;/span> }) &#x3C;span class="hljs-comment">// remark-rehype: mdast → hast&#x3C;/span>
  &#x3C;span class="hljs-comment">// HTML ここから&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(rehypeRaw) &#x3C;span class="hljs-comment">// remark-raw: Markdown に手書きした HTML を有効な hast ノードに変換する&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(sectionNumbering) &#x3C;span class="hljs-comment">// 独自: 見出しにセクション番号を付与する（記事ごとに有効か無効かを設定できる）&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(sampElement) &#x3C;span class="hljs-comment">// 独自: &#x26;#x3C;code class="language-samp"> を &#x26;#x3C;samp> タグにすげ替える&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(assignNoHighlight) &#x3C;span class="hljs-comment">// 独自: ↓ で勝手にシンタックスハイライトされないように class="no-highlight" を設定する&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(rehypeHighlight) &#x3C;span class="hljs-comment">// rehype-highlight: &#x26;#x3C;pre>&#x26;#x3C;code> をシンタックスハイライト&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(removeHljsClass) &#x3C;span class="hljs-comment">// 独自: ↑ で無駄な class が設定されるので削除&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(figureNumbering) &#x3C;span class="hljs-comment">// 独自: 図表番号を付与する&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(rehypeCustomElements) &#x3C;span class="hljs-comment">// 独自: カスタム属性を処理する&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(rehypeKatex) &#x3C;span class="hljs-comment">// rehype-katex: remark-math で抽出した数式を KaTeX で処理する&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(lintFigureClass) &#x3C;span class="hljs-comment">// 独自: &#x26;#x3C;figure> に class 属性を付け忘れていたら警告する&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">use&#x3C;/span>(toPost) &#x3C;span class="hljs-comment">// 独自 (Compiler): 出力オブジェクトを生成する&#x3C;/span>
  .&#x3C;span class="hljs-title hljs-function">freeze&#x3C;/span>()
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>できるだけシンプルにするぞと思っていたのですが、なかなか処理が多いですね。しかし Markdown 言語自体を拡張することはほとんどしておらず、処理のほとんどは HTML の AST を変形しています。このように HTML の世界に閉じ込めることで、言語を拡張するとかいう不毛なことを考えなくて済みます。&#x3C;/p>
&#x3C;h3>hastscript ベースのページテンプレート&#x3C;/h3>
&#x3C;p>素の hastscript は hast を生成するための簡単な操作しか行うことができませんが、ちょっとしたラッパーを書くことで React の関数コンポーネントの書き味を得ることができます。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>React の書き味に似せるためのラッパー (&#x3C;a href="https://github.com/azyobuzin/blog/blob/7913138eff88596512ec8403c17005bba57beb31/generator/lib/jsx.ts" rel="external">jsx.ts&#x3C;/a>)&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-js">&#x3C;span class="hljs-keyword">import&#x3C;/span> { h &#x3C;span class="hljs-keyword">as&#x3C;/span> hastscript } &#x3C;span class="hljs-keyword">from&#x3C;/span> &#x3C;span class="hljs-string">"hastscript"&#x3C;/span>

&#x3C;span class="hljs-keyword">export&#x3C;/span> &#x3C;span class="hljs-keyword">function&#x3C;/span> &#x3C;span class="hljs-title hljs-function">h&#x3C;/span>(&#x3C;span class="hljs-params">selector, properties, ...children&#x3C;/span>) {
  &#x3C;span class="hljs-keyword">return&#x3C;/span> &#x3C;span class="hljs-keyword">typeof&#x3C;/span> selector === &#x3C;span class="hljs-string">"function"&#x3C;/span>
    ? &#x3C;span class="hljs-title hljs-function">selector&#x3C;/span>({ children, ...properties }) &#x3C;span class="hljs-comment">// 関数コンポーネント&#x3C;/span>
    : &#x3C;span class="hljs-title hljs-function">hastscript&#x3C;/span>(
        selector,
        properties,
        &#x3C;span class="hljs-comment">// hastscript は boolean を入力すると例外をスローするのでフィルター&#x3C;/span>
        children.&#x3C;span class="hljs-title hljs-function">filter&#x3C;/span>(&#x3C;span class="hljs-function">(&#x3C;span class="hljs-params">x&#x3C;/span>) =>&#x3C;/span> x != &#x3C;span class="hljs-literal">null&#x3C;/span> &#x26;#x26;&#x26;#x26; x !== &#x3C;span class="hljs-literal">true&#x3C;/span> &#x26;#x26;&#x26;#x26; x !== &#x3C;span class="hljs-literal">false&#x3C;/span>)
      )
}
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>このような関数を用意すると、ほぼ React の感覚で JSX を書くことができます。実際の使用例は、このブログのジェネレータのソースコード（&#x3C;a href="https://github.com/azyobuzin/blog/tree/7913138eff88596512ec8403c17005bba57beb31/generator/pages">pages ディレクトリ&#x3C;/a>）を見てください。&#x3C;/p>
&#x3C;h2>まとめ&#x3C;/h2>
&#x3C;p>以上が AsciiDoc を捨てて Markdown に移行した理由と、新しい静的サイトジェネレータの実装でした。 HTML が置いてあるトラディショナル静的サイトであることをモットーにしているので、このような構成が落ち着きますね。これからは Asciidoctor のドキュメントとにらめっこせず、 HTML を書いていきます。ブログ書けよ。&#x3C;/p></content><id>https://blog.azyobuzi.net/2021/09/24/01-markdown/</id><link href="https://blog.azyobuzi.net/2021/09/24/01-markdown/" rel="alternate" type="text/html" /><published>2021-09-24T23:30:00+09:00</published><title type="html">結局ブログをMarkdownで書くことにした話</title><updated>2021-09-27T19:22:31+09:00</updated></entry><entry><category term="tech" label="tech" /><category term="C#" label="C#" /><category term="Android" label="Android" /><content type="html">&#x3C;p>TL;DR: Xamarin.Android のグローバル例外ハンドラは &#x3C;code>AppDomain.UnhandledException&#x3C;/code>。これで Java の例外も拾えます。ただし、例外が発生したスレッドによってはうまく拾えないケースがあり、現在修正中です（&#x3C;a href="https://github.com/xamarin/xamarin-android/issues/6211">xamarin-android#6211&#x3C;/a>）。&#x3C;/p>
&#x3C;h2>はじめに&#x3C;/h2>
&#x3C;p>ハンドルされない例外は、アプリにとって異常事態ですから、さっさと&#x3C;a href="https://github.com/xamarin/xamarin-android/blob/916d24b7d83a79853dd1d1cf060d327f98c46e77/src/java-runtime/java/mono/android/Seppuku.java">切腹&#x3C;/a>する必要があります。 Xamarin.Android アプリでは、 Java の例外と .NET の例外が入り混じり、境界ではそれぞれの例外に相互変換されています。では、相互変換を繰り返し、最終的に誰にもキャッチされなかった例外は、どのように処理されるのでしょうか？ そして、もし最後の砦、グローバル例外ハンドラを設定するなら、どこに設定するのが良いのでしょうか？&#x3C;/p>
&#x3C;h2>普通の Android アプリの死に方&#x3C;/h2>
&#x3C;p>まずはピュア Java の Android アプリを例外で落としてみましょう。適当な場所に &#x3C;code>throw new RuntimeException();&#x3C;/code> と書けばいいだけですね。今回は &#x3C;code>MainActivity.onStart&#x3C;/code> に仕込んでみます。これで起動した瞬間に落ちるはずです。&#x3C;/p>
&#x3C;p>実行するとアプリが終了し、 logcat にはこのようなログが残ります。&#x3C;/p>
&#x3C;pre>&#x3C;samp class="language-samp">E AndroidRuntime: FATAL EXCEPTION: main
E AndroidRuntime: Process: com.example.ochiruapplication, PID: 6823
E AndroidRuntime: java.lang.RuntimeException
E AndroidRuntime:        at com.example.ochiruapplication.MainActivity.onStart(MainActivity.java:18)
E AndroidRuntime:        at android.app.Instrumentation.callActivityOnStart(Instrumentation.java:1425)
E AndroidRuntime:        at android.app.Activity.performStart(Activity.java:7825)
E AndroidRuntime:        at android.app.ActivityThread.handleStartActivity(ActivityThread.java:3294)
E AndroidRuntime:        at android.app.servertransaction.TransactionExecutor.performLifecycleSequence(TransactionExecutor.java:221)
E AndroidRuntime:        at android.app.servertransaction.TransactionExecutor.cycleToPath(TransactionExecutor.java:201)
E AndroidRuntime:        at android.app.servertransaction.TransactionExecutor.executeLifecycleState(TransactionExecutor.java:173)
E AndroidRuntime:        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:97)
E AndroidRuntime:        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2016)
E AndroidRuntime:        at android.os.Handler.dispatchMessage(Handler.java:107)
E AndroidRuntime:        at android.os.Looper.loop(Looper.java:214)
E AndroidRuntime:        at android.app.ActivityThread.main(ActivityThread.java:7356)
E AndroidRuntime:        at java.lang.reflect.Method.invoke(Native Method)
E AndroidRuntime:        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)
E AndroidRuntime:        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)
&#x3C;/samp>&#x3C;/pre>
&#x3C;p>さて、例外の中身を知っているのは例外を起こしたプロセスだけですから、このログを吐き出した犯人を探すことで、 Android のグローバル例外ハンドラを探すことができそうです。 &#x3C;a href="https://cs.android.com/">Android Code Search&#x3C;/a> で「FATAL EXCEPTION」と検索すると、&#x3C;a href="https://cs.android.com/android/platform/superproject/+/master:frameworks/base/core/java/com/android/internal/os/RuntimeInit.java;l=80;drc=56ab231a8fa86f4aa5107d9248d2cf6285469edb">それっぽい行&#x3C;/a>が見つかりました。&#x3C;/p>
&#x3C;p>さらに呼び出し元を調べることで仕組みがわかります。プロセス起動時（Zygote からフォークした直後）に呼びされる &#x3C;code>RuntimeInit.commonInit&#x3C;/code> に次のようなプログラムが入っています。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>&#x3C;a href="https://cs.android.com/android/platform/superproject/+/master:frameworks/base/core/java/com/android/internal/os/RuntimeInit.java;l=225-231;drc=56ab231a8fa86f4aa5107d9248d2cf6285469edb">RuntimeInit.commonInit の一部&#x3C;/a>&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-java">&#x3C;span class="hljs-type">LoggingHandler&#x3C;/span> &#x3C;span class="hljs-variable">loggingHandler&#x3C;/span> &#x3C;span class="hljs-operator">=&#x3C;/span> &#x3C;span class="hljs-keyword">new&#x3C;/span> &#x3C;span class="hljs-title hljs-class">LoggingHandler&#x3C;/span>();
RuntimeHooks.setUncaughtExceptionPreHandler(loggingHandler);
Thread.setDefaultUncaughtExceptionHandler(&#x3C;span class="hljs-keyword">new&#x3C;/span> &#x3C;span class="hljs-title hljs-class">KillApplicationHandler&#x3C;/span>(loggingHandler));
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>Java が管理するスレッドで発生した例外は、スレッド自体に例外ハンドラを設定していなければ &#x3C;code>Thread.setDefaultUncaughtExceptionHandler&#x3C;/code> で設定したハンドラで処理されます。 Android では &#x3C;code>RuntimeInit$KillApplicationHandler&#x3C;/code> が設定されており、これが最後の砦をやっています。また、 Android には Java 標準の &#x3C;code>Thread&#x3C;/code> クラスにはない &#x3C;code>setUncaughtExceptionPreHandler&#x3C;/code> があり、もしデフォルトのハンドラがアプリのコードによって書き換えられたとしても、 &#x3C;code>RuntimeInit$LoggingHandler&#x3C;/code> だけは呼び出されて、 logcat に例外ログが吐きだされるようになっています。&#x3C;/p>
&#x3C;p>&#x3C;code>KillApplicationHandler&#x3C;/code> は、 &#x3C;code>ActivityManager&#x3C;/code> サービスに後処理（アクティビティを終了させ、必要ならばクラッシュダイアログを表示する）を任せて、プロセスを終了します。&#x3C;/p>
&#x3C;p>まとめ: Xamarin ではないピュアな Android アプリでは、基本的にすべてのスレッドを Java が管理しているので、 &#x3C;code>Thread.setDefaultUncaughtExceptionHandler&#x3C;/code> で設定したハンドラによって未ハンドルの例外が処理されます。 Android ではハンドラとして &#x3C;code>com.android.internal.os.RuntimeInit$KillApplicationHandler&#x3C;/code> が設定されており、アクティビティとプロセスの終了を担っています。&#x3C;/p>
&#x3C;h2>Xamarin アプリを例外で落とす&#x3C;/h2>
&#x3C;p>同じことを Xamarin.Android でやってみましょう。 &#x3C;code>MainActivity.OnStart&#x3C;/code> に &#x3C;code>throw new Exception();&#x3C;/code> を仕込んで実行すると、このようなログが得られます。&#x3C;/p>
&#x3C;pre>&#x3C;samp class="language-samp">E AndroidRuntime: FATAL EXCEPTION: main
E AndroidRuntime: Process: com.companyname.ochiruappxamarin, PID: 9701
E AndroidRuntime: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
E AndroidRuntime: 	at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:502)
E AndroidRuntime: 	at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)
E AndroidRuntime: Caused by: java.lang.reflect.InvocationTargetException
E AndroidRuntime: 	at java.lang.reflect.Method.invoke(Native Method)
E AndroidRuntime: 	at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)
E AndroidRuntime: 	... 1 more
E AndroidRuntime: Caused by: java.lang.Exception
E AndroidRuntime: 	at crc64a14461782825e2ee.MainActivity.n_onStart(Native Method)
E AndroidRuntime: 	at crc64a14461782825e2ee.MainActivity.onStart(MainActivity.java:55)
E AndroidRuntime: 	at android.app.Instrumentation.callActivityOnStart(Instrumentation.java:1425)
E AndroidRuntime: 	at android.app.Activity.performStart(Activity.java:7825)
E AndroidRuntime: 	at android.app.ActivityThread.handleStartActivity(ActivityThread.java:3294)
E AndroidRuntime: 	at android.app.servertransaction.TransactionExecutor.performLifecycleSequence(TransactionExecutor.java:221)
E AndroidRuntime: 	at android.app.servertransaction.TransactionExecutor.cycleToPath(TransactionExecutor.java:201)
E AndroidRuntime: 	at android.app.servertransaction.TransactionExecutor.executeLifecycleState(TransactionExecutor.java:173)
E AndroidRuntime: 	at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:97)
E AndroidRuntime: 	at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2016)
E AndroidRuntime: 	at android.os.Handler.dispatchMessage(Handler.java:107)
E AndroidRuntime: 	at android.os.Looper.loop(Looper.java:214)
E AndroidRuntime: 	at android.app.ActivityThread.main(ActivityThread.java:7356)
E AndroidRuntime: 	... 3 more
I MonoDroid: UNHANDLED EXCEPTION:
I MonoDroid: Java.Lang.RuntimeException: java.lang.reflect.InvocationTargetException ---> Java.Lang.Reflect.InvocationTargetException: Exception of type 'Java.Lang.Reflect.InvocationTargetException' was thrown. ---> Java.Lang.Exception: Exception of type 'Java.Lang.Exception' was thrown.
I MonoDroid:   at OchiruAppXamarin.MainActivity.OnStart () [0x0000d] in &#x26;#x3C;c931122de5944a1da7dcf64a7158eefa>:0
I MonoDroid:   at Android.App.Activity.n_OnStart (System.IntPtr jnienv, System.IntPtr native__this) [0x00008] in &#x26;#x3C;db0280fb1b254cf889f3a750ac3ea0bb>:0
I MonoDroid:   at (wrapper dynamic-method) Android.Runtime.DynamicMethodNameCounter.5(intptr,intptr)
I MonoDroid:    --- End of inner exception stack trace ---
I MonoDroid:    --- End of inner exception stack trace ---
I MonoDroid:   --- End of managed Java.Lang.RuntimeException stack trace ---
I MonoDroid: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
I MonoDroid: 	at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:502)
I MonoDroid: 	at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)
I MonoDroid: Caused by: java.lang.reflect.InvocationTargetException
I MonoDroid: 	at java.lang.reflect.Method.invoke(Native Method)
I MonoDroid: 	at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)
I MonoDroid: 	... 1 more
I MonoDroid: Caused by: java.lang.Exception
I MonoDroid: 	at crc64a14461782825e2ee.MainActivity.n_onStart(Native Method)
I MonoDroid: 	at crc64a14461782825e2ee.MainActivity.onStart(MainActivity.java:55)
I MonoDroid: 	at android.app.Instrumentation.callActivityOnStart(Instrumentation.java:1425)
I MonoDroid: 	at android.app.Activity.performStart(Activity.java:7825)
I MonoDroid: 	at android.app.ActivityThread.handleStartActivity(ActivityThread.java:3294)
I MonoDroid: 	at android.app.servertransaction.TransactionExecutor.performLifecycleSequence(TransactionExecutor.java:221)
I MonoDroid: 	at android.app.servertransaction.TransactionExecutor.cycleToPath(TransactionExecutor.java:201)
I MonoDroid: 	at android.app.servertransaction.TransactionExecutor.executeLifecycleState(TransactionExecutor.java:173)
I MonoDroid: 	at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:97)
I MonoDroid: 	at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2016)
I MonoDroid: 	at android.os.Handler.dispatchMessage(Handler.java:107)
I MonoDroid: 	at android.os.Looper.loop(Looper.java:214)
I MonoDroid: 	at android.app.ActivityThread.main(ActivityThread.java:7356)
I MonoDroid: 	... 3 more
I MonoDroid:
&#x3C;/samp>&#x3C;/pre>
&#x3C;p>見覚えのある前半と、見覚えのない後半ですね。ということは、 &#x3C;code>RuntimeInit$LoggingHandler&#x3C;/code> は呼び出されるようです。 Java のスレッドで例外が発生しているので、 .NET の例外は JNI を通して Java 側にスローされていきます。なので Java のスレッドの例外ハンドラが処理しているのは不思議ではないですね。&#x3C;/p>
&#x3C;p>では後半のログを出しているのは一体誰なのでしょうか？ 答えは &#x3C;code>Thread.getDefaultUncaughtExceptionHandler()&#x3C;/code>（C# では &#x3C;code>Java.Lang.Thread.DefaultUncaughtExceptionHandler&#x3C;/code>）を取得してみるとわかります。 Xamarin.Android の初期化メソッドが存在する &#x3C;code>mono.android.Runtime&#x3C;/code> クラスの静的コンストラクタで、デフォルト例外ハンドラを独自に設定しています。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>&#x3C;a href="https://github.com/xamarin/xamarin-android/blob/681887ebdbd192ce7ce1cd02221d4939599ba762/src/java-runtime/java/mono/android/Runtime.java#L13-L15">Runtime.java の一部&#x3C;/a>&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-java">&#x3C;span class="hljs-keyword">static&#x3C;/span> {
    Thread.setDefaultUncaughtExceptionHandler (&#x3C;span class="hljs-keyword">new&#x3C;/span> &#x3C;span class="hljs-title hljs-class">XamarinUncaughtExceptionHandler&#x3C;/span> (Thread.getDefaultUncaughtExceptionHandler ()));
}
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>このハンドラでは、 Xamarin.Android 独自の処理をしたあと、もともと設定してあったハンドラに処理を投げています。つまり、処理順は PreHandler である &#x3C;code>LoggingHandler&#x3C;/code> が呼び出されたあと、 Xamarin.Android 独自の処理をして、最後に &#x3C;code>KillApplicationHandler&#x3C;/code> を実行する、という順番になります。&#x3C;/p>
&#x3C;p>Xamarin.Android 独自の処理の中身は &#x3C;a href="https://github.com/xamarin/xamarin-android/blob/ab0ed93cc88863b226c917dfef1fa62979c6ead8/src/Mono.Android/Android.Runtime/JNIEnv.cs#L284">&#x3C;code>JNIEnv.PropagateUncaughtException&#x3C;/code>&#x3C;/a> にあります。このメソッドの中には、ログにあった「UNHANDLED EXCEPTION」が見つけられます。また、ここで受け取った例外は &#x3C;code>AppDomain.UnhandledException&#x3C;/code> に投げられることがわかります。&#x3C;/p>
&#x3C;p>まとめ: Java のスレッドで発生した例外は、 Xamarin.Android 独自のハンドラで処理されます。このハンドラは &#x3C;code>AppDomain.UnhandledException&#x3C;/code> イベントを発生させたあと、 Android の標準ハンドラである &#x3C;code>KillApplicationHandler&#x3C;/code> を呼び出すことで Android に後片付けを任せます。&#x3C;/p>
&#x3C;h2>.NET のスレッドで例外を起こす&#x3C;/h2>
&#x3C;p>ここまで Java のスレッドで例外を発生させてきました。しかし、 .NET でもスレッドを作成することができます。 .NET のスレッドで例外が発生した場合はどのように処理されるのでしょうか？&#x3C;/p>
&#x3C;p>前回の実験コードの &#x3C;code>throw new Exception();&#x3C;/code> を &#x3C;code>new Thread(() => throw new Exception()).Start();&#x3C;/code> に書き換えて試してみましょう。実行すると logcat のエラーログはこんな感じになりました。&#x3C;/p>
&#x3C;pre>&#x3C;samp class="language-samp">F mono-rt : [ERROR] FATAL UNHANDLED EXCEPTION: System.Exception: Exception of type 'System.Exception' was thrown.
F mono-rt :   at OchiruAppXamarin.MainActivity+&#x26;#x3C;>c.&#x26;#x3C;OnStart>b__2_0 () [0x00000] in &#x26;#x3C;605572ca36544c48913788216f21b753>:0
F mono-rt :   at System.Threading.ThreadHelper.ThreadStart_Context (System.Object state) [0x00014] in &#x26;#x3C;1b39a03c32ec46258a7821e202e0269f>:0
F mono-rt :   at System.Threading.ExecutionContext.RunInternal (System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, System.Object state, System.Boolean preserveSyncCtx) [0x00071] in &#x26;#x3C;1b39a03c32ec46258a7821e202e0269f>:0
F mono-rt :   at System.Threading.ExecutionContext.Run (System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, System.Object state, System.Boolean preserveSyncCtx) [0x00000] in &#x26;#x3C;1b39a03c32ec46258a7821e202e0269f>:0
F mono-rt :   at System.Threading.ExecutionContext.Run (System.Threading.ExecutionContext executionContext, System.Threading.ContextCallback callback, System.Object state) [0x0002b] in &#x26;#x3C;1b39a03c32ec46258a7821e202e0269f>:0
F mono-rt :   at System.Threading.ThreadHelper.ThreadStart () [0x00008] in &#x26;#x3C;1b39a03c32ec46258a7821e202e0269f>:0
&#x3C;/samp>&#x3C;/pre>
&#x3C;p>ついに Java っぽいログが出なくなりました！&#x3C;/p>
&#x3C;p>これはどういうことかというと、何の細工もなく、 Mono がプロセスを終了しています。普通の .NET アプリと同じです。 Java 側にはまったく通達されません。&#x3C;/p>
&#x3C;p>まとめ: .NET のスレッドで例外が発生すると Mono によってハンドルされ、普通の .NET アプリのようにプロセスが終了します。&#x3C;/p>
&#x3C;h2>総まとめ&#x3C;/h2>
&#x3C;p>Java が管理するスレッドで例外が発生しても、 .NET が管理するスレッドで例外が発生しても、とりあえず &#x3C;code>AppDomain.UnhandledException&#x3C;/code> が呼び出されるので、これが最強の例外ハンドラです。&#x3C;/p>
&#x3C;h2>おまけ: AndroidEnvironment.UnhandledExceptionRaiser って何？&#x3C;/h2>
&#x3C;p>Xamarin.Android の例外処理を調べたことがある人は、 &#x3C;code>AndroidEnvironment.UnhandledExceptionRaiser&#x3C;/code> が強そうな名前に見えて、使えそうに見えてしまったのではないでしょうか。しかし実際のところ、あんまり使い道はありません。&#x3C;/p>
&#x3C;p>&#x3C;code>AndroidEnvironment.UnhandledExceptionRaiser&#x3C;/code> イベントは、 .NET で発生した例外を Java の例外に変換するときに発生します。例えば、今まで &#x3C;code>OnStart&#x3C;/code> メソッドで &#x3C;code>throw new Exception();&#x3C;/code> をする例を示してきましたが、 &#x3C;code>OnStart&#x3C;/code> メソッドの呼び出し元は Java なので、 Java の例外に変換する必要があります。&#x3C;/p>
&#x3C;p>このイベントにハンドラを設定しない場合、もしくはいずれのハンドラも &#x3C;code>e.Handled = true&#x3C;/code> をセットしない場合はデフォルトの挙動をします。デフォルトの挙動は、 .NET の例外を &#x3C;code>Android.Runtime.JavaProxyThrowable&#x3C;/code> でラップし、 Java を例外状態（JNI の &#x3C;code>Throw&#x3C;/code> 関数を呼び出す）にします。&#x3C;/p>
&#x3C;p>使い道としては、 .NET で発生した例外を握りつぶして Java のプログラムを続行させたり（&#x3C;code>e.Handled = true&#x3C;/code> をセットして何もしない）、 &#x3C;code>Android.Runtime.JavaProxyThrowable&#x3C;/code> ではない独自の &#x3C;code>Throwable&#x3C;/code> に変換したり（&#x3C;code>JNIEnv.Throw&#x3C;/code> を呼び出す）、が考えられます。&#x3C;/p></content><id>https://blog.azyobuzi.net/2021/08/28/01-xaexception/</id><link href="https://blog.azyobuzi.net/2021/08/28/01-xaexception/" rel="alternate" type="text/html" /><published>2021-08-27T03:24:00+09:00</published><title type="html">Xamarin.Android アプリが例外で落ちるということ</title><updated>2021-09-24T23:30:48+09:00</updated></entry><entry><category term="tech" label="tech" /><category term="C#" label="C#" /><content type="html">&#x3C;p>また TPL Dataflow の話です。突然ですが、バッファのない PropagatorBlock って欲しくないですか？&#x3C;/p>
&#x3C;p>例えば、複数の SourceBlock があって、それをひとつの SourceBlock として返したいとき。&#x3C;/p>
&#x3C;pre>&#x3C;code class="language-cs">&#x3C;span class="hljs-function">ISourceBlock&#x26;#x3C;T> &#x3C;span class="hljs-title">CreateSource&#x3C;/span>(&#x3C;span class="hljs-params">&#x3C;/span>)&#x3C;/span>
{
    IEnumerable&#x26;#x3C;ISourceBlock&#x26;#x3C;T>> sources = &#x3C;span class="hljs-comment">/* ... */&#x3C;/span>;

    &#x3C;span class="hljs-keyword">var&#x3C;/span> resultBlock = &#x3C;span class="hljs-keyword">new&#x3C;/span> BufferBlock&#x26;#x3C;T>(&#x3C;span class="hljs-keyword">new&#x3C;/span> DataflowBlockOptions() { BoundedCapacity = &#x3C;span class="hljs-number">1&#x3C;/span> });
    &#x3C;span class="hljs-keyword">foreach&#x3C;/span> (&#x3C;span class="hljs-keyword">var&#x3C;/span> s &#x3C;span class="hljs-keyword">in&#x3C;/span> sources) s.LinkTo(resultBlock);

    &#x3C;span class="hljs-keyword">return&#x3C;/span> resultBlock;
}
&#x3C;/code>&#x3C;/pre>
&#x3C;p>どうでしょう？ &#x3C;code>resultBlock&#x3C;/code> は、1件はバッファに持ってしまうので、後段のブロックがどうであれ、ソースからは必ず1件多く取り出されてしまいます。&#x3C;/p>
&#x3C;p>1件くらいいいじゃない？ それは &#x3C;code>sources&#x3C;/code> 次第でしょう。&#x3C;/p>
&#x3C;p>というわけで、本題のバッファのない PropagatorBlock が欲しい、ということです。もし &#x3C;code>resultBlock&#x3C;/code> にバッファがなければ、 &#x3C;code>CreateSource&#x3C;/code> の戻り値を利用する（リンクする）とき、初めて &#x3C;code>sources&#x3C;/code> からデータが取り出されます。やりたいですね。&#x3C;/p>
&#x3C;h2>タイトルオチ&#x3C;/h2>
&#x3C;p>もうタイトルでオチてますが、このような PropagatorBlock はデータフローブロックのプロトコル上、おそらく作れません。プロトコルについては&#x3C;a href="https://blog.azyobuzi.net/2020/04/30/01-reactivestreams/" title="プロトコルから比較する Reactive Streams と TPL Dataflow">以前&#x3C;/a>ざっくりと紹介しましたが、今回はこのプロトコルと、既存のブロックの実装で使われているロックが鍵となります。&#x3C;/p>
&#x3C;p>TPL Dataflow のブロック間の通信は、完全に直列です。ある SourceBlock からは同時に1件しか送信しないし、ある TargetBlock は同時に1件しか受信できません。その制御は &#x3C;code>lock&#x3C;/code> ステートメントで行われています（絶対ボトルネックじゃん）。&#x3C;/p>
&#x3C;p>PropagatorBlock は Source と Target 両方の性質を持っており、 Target で受信したデータを加工して Source がデータを出力します。 Target 部は1件ずつ受信を行い、加工を行うタスクへ投げ、加工が終わったデータは Source 部のキューに積まれ、 Source 部は1件ずつ送信を行います。つまり PropagatorBlock においては Target と Source は並列に動いています。&#x3C;/p>
&#x3C;p>TPL Dataflow のソースコードを読むと、 TargetBlock または PropagatorBlock の Target 部を直列化するために使用されるロックを &#x3C;code>IncomingLock&#x3C;/code>、 SourceBlock または PropagatorBlock の Source 部を直列化するために使用されるロックを &#x3C;code>OutgoingLock&#x3C;/code> と呼んでいるので、この名称を使っていきます。&#x3C;/p>
&#x3C;p>では、このロックを考慮しながら、 Source から Target へデータを送信する各パターンをシーケンス図に表してみます。&#x3C;/p>
&#x3C;figure class="fig-img">&#x3C;img src="https://blog.azyobuzi.net/2021/03/23/01-dataflowblock-without-buffer/basicoffer.svg" alt="Source から Target へデータを送信する様子">&#x3C;/figure>
&#x3C;p>もう複数のロックがあるという時点で嫌ですね。&#x3C;/p>
&#x3C;p>ではここで、間にバッファのない PropagatorBlock が入ったらどうなるでしょう？ 変わりませんね。通信内容をそのまま素通しすればいいだけなので。しかし忘れてはいけないことがあります: 間に入るブロックもブロックなので、ファンインもファンアウトも複数持つことができます。したがって、今注目していた Source と Target 以外の要因によって通信が発生することがあります。例えば、別の Target にデータを送信できたので、次の1件の送信を開始しよう、とすると次の操作が開始します。&#x3C;/p>
&#x3C;figure class="fig-img">&#x3C;img src="https://blog.azyobuzi.net/2021/03/23/01-dataflowblock-without-buffer/offerbypropagator.svg" alt="Propagator が送信を開始する様子">&#x3C;/figure>
&#x3C;p>そろそろ嫌な予感がしてきましたね。 Propagator は Source の OutgoingLock なんてお構いなしに Target にデータの送信を試みることができます。つまり、タイミングによっては……。実際に例を見てみましょう。 Source が Propagator に送信しようとしたら、 Propagator が Target に送信中だった場合、こうなります。&#x3C;/p>
&#x3C;figure class="fig-img">&#x3C;img src="https://blog.azyobuzi.net/2021/03/23/01-dataflowblock-without-buffer/deadlock1.svg" alt="デッドロックが発生する例">&#x3C;/figure>
&#x3C;p>見事なデッドロックですね。並行にロックを取得する場合、取得順を同じにしないとデッドロックするという鉄則がありますが、完全に破る構図です。&#x3C;/p>
&#x3C;p>ただ、このデッドロックは実は回避できます。「(1) OfferMessage」のところで Propagator が「(2) ConsumeMessage」を実行中でまだ返ってきてないぞと判断して、このメッセージを延期させてしまえば、 OutgoingLock が外れるので先に進むことができます。&#x3C;/p>
&#x3C;p>今の例では、 Source, Propagator, Target が 1:1:1 だったので回避できました。が、1:N:1、つまりひとつの Source が複数の Propagator に接続されていて、さらにその Propagator たちがひとつの Target に接続されている場合はどうでしょう。先程の図の (1) が Propagator1 で、 (2) が Propagator2 で起こっていたら、 Propagator 同士はお互いを知らないので調停することができません。&#x3C;/p>
&#x3C;h2>まとめ&#x3C;/h2>
&#x3C;p>バッファを持たない PropagatorBlock は、デッドロックを起こす運命にあります。回避可能なケースは Source, Propagator, Target が 1:1:1 の関係にあるときです。例えば、 &#x3C;a href="https://docs.microsoft.com/ja-jp/dotnet/api/system.threading.tasks.dataflow.dataflowblock.linkto?view=net-5.0#System_Threading_Tasks_Dataflow_DataflowBlock_LinkTo__1_System_Threading_Tasks_Dataflow_ISourceBlock___0__System_Threading_Tasks_Dataflow_ITargetBlock___0__System_Predicate___0__">&#x3C;code>LinkTo&#x3C;/code> メソッドの &#x3C;code>predicate&#x3C;/code> 引数を持つオーバーロード&#x3C;/a>は、内部で PropagatorBlock を作成しています。しかしこのブロックは外部へ公開されず、あくまでリンクのために隠蔽されています。通常のブロックとして、複数のファンイン、ファンアウトを持てるという要件を満たそうとすると、不可能になります。&#x3C;/p>
&#x3C;p>結局この記事で何が言いたかったかというと、拙作の TPL Dataflow 補助ライブラリの &#x3C;a href="https://github.com/azyobuzin/BiDaFlow">BiDaFlow&#x3C;/a> で、バッファなしの &#x3C;code>TransformBlock&#x3C;/code> を提供していたのですが、デッドロックの可能性を排除できなかったので、機能を削除することにしました。悲しい。&#x3C;/p></content><id>https://blog.azyobuzi.net/2021/03/23/01-dataflowblock-without-buffer/</id><link href="https://blog.azyobuzi.net/2021/03/23/01-dataflowblock-without-buffer/" rel="alternate" type="text/html" /><link href="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20210323/20210323033433.png" rel="enclosure" /><published>2021-03-23T03:44:00+09:00</published><title type="html">バッファのない PropagatorBlock はつくれないという話</title><updated>2021-09-27T19:22:31+09:00</updated></entry><entry><category term="日記" label="日記" /><content type="html">&#x3C;p>冬。国内学会の総合大会の季節。間に合わん！&#x3C;/p>
&#x3C;h2>自己紹介&#x3C;/h2>
&#x3C;p>自己紹介。情報工学系修士1年。研究テーマは&#x3C;a href="https://blog.azyobuzi.net/2020/10/11/01-flif/" title="画像可逆圧縮形式 FLIF についてのメモ">前回の投稿&#x3C;/a>みたいな話をやっていきたいというところです。&#x3C;/p>
&#x3C;p>そしてあまりにも進捗が爆発してしまったので、ここに反省文を書こうという気持ちです。こんなもの書いてる暇があったら研究計画を立てろ。すいません。&#x3C;/p>
&#x3C;p>研究テーマは学部の卒論から変更して、心機一転2年間持たせられるネタをということで、今のテーマに落ち着きました。私の所属する研究室は、ほとんどがひとり1プロジェクトかつ放置系なので、自分で分野を探して自分で勝手に始めていく必要があります。もともとは DBMS でも作ろうと思って入った研究室でしたが、新規性のある提案を何ひとつ思いつかず、学部も修士も全然違う分野をやっています。&#x3C;/p>
&#x3C;p>私の弱みは「新規性のある提案を何ひとつ思いつかず」がすべてを物語っています。現状に満足しがちで、課題感がない。その上、知識の幅の狭さ、社会経験の少なさで、社会課題へのアンテナもありません。そんな中からひねり出せるアイデアは、レッドオーシャンで性能バトルをするくらいになってしまいがちです。現在の研究テーマはなんとかレッドオーシャンを回避しているような気がしますが、結局課題解決というより性能バトルな感じになってしまっています。本当は、もっと具体的な課題を用意して、それに絞った研究をすることで、成果を出しやすくするべきなのでしょうが……。&#x3C;/p>
&#x3C;h2>「何もしてないのに多忙」&#x3C;/h2>
&#x3C;p>研究が進みません。研究しなくてはいけないという気持ちがあります。だから忙しいなぁと思います。で、今日どれだけ進んだっけ？ 進捗ゼロですね。みたいなことをもう数ヶ月続けています。1ヶ月に1回まわってくる進捗発表の直前1週間だけ馬鹿力が出ます。&#x3C;/p>
&#x3C;p>そんな逃げ方をしていたら、もう冬でした。&#x3C;/p>
&#x3C;p>プレッシャーの原因は、ほとんど自分自身によるものです。可処分時間を研究に使っていたらこれくらいできるだろうという高い期待がありました。今までの成功体験がありました。奨学生として相応な成果を出さなければという気持ちもありました。プレッシャーが高まると、基本的には馬鹿力が出ます。しかし、本当に間に合いそうにないときは、ただただ無力になり、苦しい気持ちだけが残ります。&#x3C;/p>
&#x3C;p>たぶんこれが、初めての失敗体験になります。&#x3C;/p>
&#x3C;h2>あこがれ&#x3C;/h2>
&#x3C;p>なんであんなに時間を、1日をうまく使えるんでしょうかね。&#x3C;/p>
&#x3C;p>パワフルな人は、朝起きて、作業をして、朝食を食べて、作業をします。&#x3C;a href="https://amzn.to/33yJf6R">「&#x3C;cite>なぜ、あなたの仕事は終わらないのか&#x3C;/cite>」&#x3C;/a>なんかがいい例です。&#x3C;/p>
&#x3C;p>それに比べて私は……、と思うものです。授業開始ギリギリまで寝て、授業を受けて、終わったら寝て、カクヨムを読んで、やっとPCに向かってSNSを眺めて、最後に作業に手を付けるのは深夜、みたいな生活をしています。たまにまともな生活をすることもありますが、作業に集中するあまり深夜になっていて、翌日からは逆戻りです。結局、集中できてしまったときに制御できなくなり、その反動で悪化する、を繰り返しており、規則的な生活でコンスタントな成果を出し続けることができません。&#x3C;/p>
&#x3C;h2>コロナが悪かったのか？&#x3C;/h2>
&#x3C;p>コロナのせいにしたいが、もしコロナが流行ってなかったとしても、成果が出ていた自信は……ないかな。&#x3C;/p>
&#x3C;p>ただ、学部の頃の進捗は、「ついで研究室」に頼っていたのは事実です。授業を受けるために大学に行き、授業後は閉館時間まで研究室に居る。そうして、研究を進めるか雑談をするか以外にできない環境に身を置き続けることで、自分で自分を制御しなくても、研究が進む環境がありました。そして、院生生活もそのように進めていく予定でした。&#x3C;/p>
&#x3C;p>しかし現状はリモート授業になってしまいました。すると先にも挙げたように、授業が終わったらすぐサボれる環境が出来上がっています。その結果、研究について考え、作業を進める時間は大幅に減ったように感じます。時間を区切ったり、週報を書いたりする試みもしましたが、これも「集中できてしまったときに制御できなくなり、その反動で悪化する」のパターンに陥ってしまいました。&#x3C;/p>
&#x3C;p>講義なんてオンラインでも何でもいいんですけれども、「ついで研究室」ができないことが院生にとっては非常に問題だと感じました。給料も出ないのに、自宅で自分を制御することは難しい。皆さんがどのくらい同じ苦しみを感じているかはわかりませんが、私には難しすぎました。&#x3C;/p>
&#x3C;h2>おわりに&#x3C;/h2>
&#x3C;p>自己管理能力のなさがコロナで炙り出されてしまった、と言えばいいのでしょうか。今までの人生であまり失敗を経験せず、ぬるま湯の中で過ごして来てしまったので、今この状況で、まさに苦しいという感情になっています。&#x3C;/p>
&#x3C;p>今できることは、目標を下げに下げまくり、それに自分と教授を納得させることかなと思います。&#x3C;/p>
&#x3C;p>口ではプライドなんてないよみたいなことを言ってきた記憶がありますが、それはプライドが邪魔をするほどの失敗をしたことがなかっただけのような気がします。高すぎる自分への期待を、適切に制御する方法が、今後必要なのでしょうけれど、今はまだその技術を手に入れる方法がわかりません。&#x3C;/p></content><id>https://blog.azyobuzi.net/2020/12/02/01-akirame/</id><link href="https://blog.azyobuzi.net/2020/12/02/01-akirame/" rel="alternate" type="text/html" /><published>2020-12-02T03:52:00+09:00</published><title type="html">諦めのポエム</title><updated>2021-09-01T01:02:14+09:00</updated></entry><entry><category term="tech" label="tech" /><content type="html">&#x3C;p>&#x3C;a href="https://flif.info/">&#x3C;dfn>FLIF&#x3C;/dfn> (Free Lossless Image Format)&#x3C;/a> は、実用されている可逆圧縮形式としておそらく現在最強の圧縮手法です。実際、画像圧縮手法に関する最近の研究では、 FLIF が比較対象となることが多いように思われます。このブログ記事では、 FLIF がどのように圧縮を行っているのか、理解できた範囲で記録していきます。&#x3C;/p>
&#x3C;p>ファイル形式としての特徴は、アルファチャンネル対応、 HDR (サブピクセルが8ビットより大きい) 対応、アニメーション対応と、現代的な画像形式として一般的な構成となっています。&#x3C;/p>
&#x3C;p>圧縮手法としての特徴は、次の2点が挙げられます。&#x3C;/p>
&#x3C;ol>
&#x3C;li>色空間 (YCoCg) や画素値の範囲を変換することで、画素間の相関が大きくなり、効率よく符号化できるようにします。&#x3C;/li>
&#x3C;li>エントロピー符号化に使用する確率分布の使い分け（コンテキスト）を入力画像から決定木の形式で学習します。&#x3C;/li>
&#x3C;/ol>
&#x3C;p>FLIF は、すでに ImageMagick で実装されており、すぐに試すことができます。また、コーデックのリファレンス実装は GitHub にあります (&#x3C;a href="https://github.com/FLIF-hub/FLIF">FLIF-hub/FLIF&#x3C;/a>)。&#x3C;/p>
&#x3C;p>なお、現在 FLIF の開発はストップしており、 FLIF の成果は JPEG XL に取り込まれるようです。ただ &#x3C;a href="https://gitlab.com/wg1/jpeg-xl/-/blob/bf10dc87f9b91cf2eb536b36362987a992b3c25f/doc/xl_overview.md#lossless">JPEG XL の説明&#x3C;/a>を読む限り、以上に挙げた特徴とは違っているので、手法としては別物になるのではないかと思っています。&#x3C;/p>
&#x3C;h2>1. 他の可逆圧縮手法との比較&#x3C;/h2>
&#x3C;p>（あんまり詳しくないので、ツッコミよろ）&#x3C;/p>
&#x3C;p>現在 web でシェアを取っている PNG と WebP は、 Deflate のような辞書型圧縮が使用されています。 PNG や WebP の可逆圧縮モードでは、入力画像の画素値、または隣接画素を使った画素値の予測をしたときの誤差（残差）を Deflate のような手法で圧縮します。&#x3C;/p>
&#x3C;p>FLIF は、このような辞書型圧縮 + ハフマン符号の構成ではなく、算術符号で符号化を行います。算術符号については後で説明します。&#x3C;/p>
&#x3C;p>算術符号を使用する手法としては、 JPEG 2000 や H.264 があります。これらの手法では、2値に対する算術符号が使用されています。 FLIF もこれらの手法を参考にしつつ、算術符号化にもちいる確率分布を獲得する方法を工夫しています。&#x3C;/p>
&#x3C;h2>2. FLIF ファイルの構成&#x3C;/h2>
&#x3C;p>FLIF ファイルは、大きく次のように構成されます。区切り方は &#x3C;a href="https://flif.info/spec.html">&#x3C;cite>FLIF16 Specification&#x3C;/cite>&#x3C;/a> に従っています。&#x3C;/p>
&#x3C;dl>
&#x3C;dt>Main Header&#x3C;/dt>&#x3C;dd>画像の大きさやチャンネル数が記述されます。&#x3C;/dd>
&#x3C;dt>Metadata&#x3C;/dt>&#x3C;dd>任意のデータを書き込めます。ここに Exif とかを入れます。
&#x3C;/dd>&#x3C;dt>Second Header&#x3C;/dt>&#x3C;dd>圧縮に使用するパラメータが記述されます。ここで色空間やその他の変換をするのか、するならば変換に使用するパラメータを記述します。&#x3C;/dd>
&#x3C;dt>Pixel Data&#x3C;/dt>&#x3C;dd>Second Header で指定した変換がなされた画像のデータです。この記事で詳しく説明します。&#x3C;/dd>
&#x3C;/dl>
&#x3C;h2>3. 画素値の符号化順&#x3C;/h2>
&#x3C;p>画素値の符号化には2種類の方法が用意されています。&#x3C;/p>
&#x3C;dl>
&#x3C;dt>非インターレース (Non-interlaced)&#x3C;/dt>
&#x3C;dd>左上の画素から順番に符号化していきます。デフォルトでは、総画素数が1万未満のときに使用されます。&#x3C;/dd>
&#x3C;dt>インターレース (Interlaced)&#x3C;/dt>
&#x3C;dd>画像を 1/2, 1/4, 1/8, …… と縮小していき、小さい画像から順に符号化していきます。画素値を予測するときに、小さい画像の画素値を使って予測を行うことができるので、非インターレースではできないような予測（予測しようとしている画素の右下の画素を使う）ができます。&#x3C;/dd>
&#x3C;/dl>
&#x3C;h3>3.1. 非インターレース方式&#x3C;/h3>
&#x3C;p>非インターレース方式では、 Pixel Data パートは次のような構造になります。&#x3C;/p>
&#x3C;ol>
&#x3C;li>MANIAC 符号化 (&#x3C;a href="https://blog.azyobuzi.net/2020/10/11/01-flif/#sec-meta-adaptive">Section 4.4&#x3C;/a>) に使用する決定木&#x3C;/li>
&#x3C;li>チャンネルごとに、画素値を左上からラスタスキャンの順に MANIAC 符号化したデータ&#x3C;/li>
&#x3C;/ol>
&#x3C;p>実際に符号化する画素値は、予測された画素値との誤差になります。予測に使用する画素は、 &#x3C;a href="https://blog.azyobuzi.net/2020/10/11/01-flif/#img-px-noninterlace">図 1&#x3C;/a> に示すように、予測する画素 X の左上、上、左です。&#x3C;/p>
&#x3C;figure class="fig-img" data-num="図">
&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/px_noninterlace.svg" height="75" alt="">
&#x3C;figcaption>図 1: 非インターレース方式で参照する周辺画素&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>予測値は、 L+T-TL, L, T の中央値です。 X-予測値 が実際に符号化される値になります。&#x3C;/p>
&#x3C;p>アルファチャンネルがある場合、アルファチャンネルが一番最初に符号化されます。なぜなら、 Second Header の項目に、透明ピクセルのデータを捨てる（Aが0ならRGBの値は未定義にする）オプションがあるため、ある座標が透明ピクセルかどうかがわからないと他のチャンネルを符号化・復号化できないからです。アルファチャンネル以外については、 YCoCg はその順番で、 RGB は Second Header の変換で PermutePlanes が指定されているかどうかで決まります。&#x3C;/p>
&#x3C;h3>3.2. インターレース方式&#x3C;/h3>
&#x3C;p>大きいサイズの画像に対しては、非インターレース方式よりも複雑ですが、予測精度の高い手法を用いることで、圧縮効率を稼ぎます。インターレース方式では小さい画像から段々と大きい画像を復元していきます。 PNG だとインターレースを使用するメリットは読み込み途中でも画像を表示できるという程度ですが、 FLIF では圧縮率に貢献します。&#x3C;/p>
&#x3C;p>次の表は実際の復号化中のデータを Y チャンネル（輝度値）について取り出したものです。この場合では、ズームレベル 14 から順番に復元していきます。&#x3C;/p>
&#x3C;figure class="fig-table" data-num="表">
&#x3C;figcaption>表 1: インターレース方式で画素が復元される様子&#x3C;/figcaption>





















































































&#x3C;table>&#x3C;thead>&#x3C;tr>&#x3C;th align="center">ズームレベル&#x3C;/th>&#x3C;th align="center">サイズ&#x3C;/th>&#x3C;th align="center">画像&#x3C;/th>&#x3C;/tr>&#x3C;/thead>&#x3C;tbody>&#x3C;tr>&#x3C;td align="center">0&#x3C;/td>&#x3C;td align="center">120×120 (原画像サイズ)&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_i01_fr00_z00_p00.png" alt="ZL=0">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">1&#x3C;/td>&#x3C;td align="center">120×60&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_i00_fr00_z01_p00.png" alt="ZL=1">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">2&#x3C;/td>&#x3C;td align="center">60×60&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i30_fr00_z02_p00.png" alt="ZL=2">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">3&#x3C;/td>&#x3C;td align="center">60×30&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i27_fr00_z03_p00.png" alt="ZL=3">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">4&#x3C;/td>&#x3C;td align="center">30×30&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i24_fr00_z04_p00.png" alt="ZL=4">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">5&#x3C;/td>&#x3C;td align="center">30×15&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i21_fr00_z05_p00.png" alt="ZL=5">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">6&#x3C;/td>&#x3C;td align="center">15×15&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i18_fr00_z06_p00.png" alt="ZL=6">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">7&#x3C;/td>&#x3C;td align="center">15×8&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i15_fr00_z07_p00.png" alt="ZL=7">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">8&#x3C;/td>&#x3C;td align="center">8×8&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i12_fr00_z08_p00.png" alt="ZL=8">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">9&#x3C;/td>&#x3C;td align="center">8×4&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i09_fr00_z09_p00.png" alt="ZL=9">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">10&#x3C;/td>&#x3C;td align="center">4×4&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i06_fr00_z10_p00.png" alt="ZL=10">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">11&#x3C;/td>&#x3C;td align="center">4×2&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i04_fr00_z11_p00.png" alt="ZL=11">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">12&#x3C;/td>&#x3C;td align="center">2×2&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i02_fr00_z12_p00.png" alt="ZL=12">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">13&#x3C;/td>&#x3C;td align="center">2×1&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i01_fr00_z13_p00.png" alt="ZL=13">&#x3C;/td>&#x3C;/tr>&#x3C;tr>&#x3C;td align="center">14&#x3C;/td>&#x3C;td align="center">1×1&#x3C;/td>&#x3C;td align="center">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/interlace/dec_rough_i00_fr00_z14_p00.png" alt="ZL=14">&#x3C;/td>&#x3C;/tr>&#x3C;/tbody>&#x3C;/table>
&#x3C;/figure>
&#x3C;p>具体的なアルゴリズムを書くと長くなるので、以上のように画素が埋まっていくんだなと解釈してください（雑）。最後のズームレベルは 1×1 になるので、より大きな画像ではズームレベルがさらに多くなります。また、横長、縦長の画像では、あるズームレベルで 1 ピクセルも復元されないことがあります。&#x3C;/p>
&#x3C;p>このように圧縮すると何がうれしいかというと、すでに復号化されている隣接画素の情報を画素値予測に使うことができることができます。図からも 4×4 くらいになれば、手がかりになりそうなデータになっていることが分かると思います。実際、インターレース方式で使用する予測器は、非インターレース方式の予測器よりもリッチです。&#x3C;/p>
&#x3C;p>予測器はズームレベルが偶数か奇数かで少し挙動が変わります。なぜなら周囲の画素の復号化状況が異なるからです。偶数では行を復号化するため、下側の画素を参照することができますが、右側を参照することはできません。奇数では列を復号化するため、逆に右側を参照することできますが、下側を参照することができません。&#x3C;/p>
&#x3C;p>実際の予測器を見てみましょう。予測する画素 X の周辺画素に次のように名前を付けておきます。&#x3C;/p>
&#x3C;figure class="fig-img" data-num="図">
&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/px_interlace.svg" height="150" alt="">
&#x3C;figcaption>図 2: インターレース方式で参照する周辺画素&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>次に示す図は、画素 X を復号化するときの、周辺画素の復号化状況です。背景がグレーになっている画素は前のズームレベルまでに復号化された画素、背景が白の画素は今のズームレベルで復号化する画素です。「?」となっている部分はまだ復号化されていません。この通り、ズームレベル偶数では R を参照することはできず、奇数では B を参照することができません。&#x3C;/p>
&#x3C;figure class="fig-img" data-num="図">
&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/px_horizontal.svg" height="150" alt="">
&#x3C;figcaption>図 3: 偶数ズームレベルにおける周辺画素&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;figure class="fig-img" data-num="図">
&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/px_vertical.svg" height="150" alt="">
&#x3C;figcaption>図 4: 奇数ズームレベルにおける周辺画素&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>また、画像の端っこの画素を処理するときには、参照できない周辺画素があります。その場合は、偶数ズームレベルでは必ず T があり、奇数ズームレベルでは L があるので、その値を代用します。&#x3C;/p>
&#x3C;p>予測器は次の3つから選ぶことができます。チャンネルごとに指定するかズームレベルごとに指定するかが選べます。リファレンス実装のデフォルトでは、チャンネルごとにズームレベル 0 と 1 で試しにすべての予測器で予測させて、誤差が一番少ないものを選択します。&#x3C;/p>
&#x3C;figure class="fig-table" data-num="表">
&#x3C;figcaption>表 2: インターレース方式における予測器&#x3C;/figcaption>
&#x3C;table>
  &#x3C;thead>
    &#x3C;tr>
      &#x3C;th scope="col">予測器&#x3C;/th>
      &#x3C;th scope="col">ズームレベル偶数&#x3C;/th>
      &#x3C;th scope="col">ズームレベル奇数&#x3C;/th>
    &#x3C;/tr>
  &#x3C;/thead>
  &#x3C;tbody>
    &#x3C;tr>
      &#x3C;td>0&#x3C;/td>
      &#x3C;td>(T + B) >> 1&#x3C;/td>
      &#x3C;td>(L + R) >> 1&#x3C;/td>
    &#x3C;/tr>
    &#x3C;tr>
      &#x3C;td>1&#x3C;/td>
      &#x3C;td>
        次の中央値
        &#x3C;ul>
          &#x3C;li>(T + B) >> 1
          &#x3C;/li>&#x3C;li>L + T - TL
          &#x3C;/li>&#x3C;li>L + B - BL
        &#x3C;/li>&#x3C;/ul>
      &#x3C;/td>
      &#x3C;td>
        次の中央値
        &#x3C;ul>
          &#x3C;li>(L + R) >> 1
          &#x3C;/li>&#x3C;li>L + T - TL
          &#x3C;/li>&#x3C;li>R + T - TR
        &#x3C;/li>&#x3C;/ul>
      &#x3C;/td>
    &#x3C;/tr>
    &#x3C;tr>
      &#x3C;td>2&#x3C;/td>
      &#x3C;td>
        次の中央値
        &#x3C;ul>
          &#x3C;li>T
          &#x3C;/li>&#x3C;li>B
          &#x3C;/li>&#x3C;li>L
        &#x3C;/li>&#x3C;/ul>
      &#x3C;/td>
      &#x3C;td>
        次の中央値
        &#x3C;ul>
          &#x3C;li>T
          &#x3C;/li>&#x3C;li>L
          &#x3C;/li>&#x3C;li>R
        &#x3C;/li>&#x3C;/ul>
      &#x3C;/td>
    &#x3C;/tr>
  &#x3C;/tbody>
&#x3C;/table>
&#x3C;/figure>
&#x3C;p>「>> 1」は 2 で割って切り捨てなので、平均を求めていることになります。予測器 0 では両隣の平均、予測器 1 では斜め方向も含めて計算してみて中央値を取る、予測器 3 では周囲の中央値を取るという戦略になっています。予測器で使われない TT や LL といった画素は、 &#x3C;a href="https://blog.azyobuzi.net/2020/10/11/01-flif/#sec-meta-adaptive">Section 4.4&#x3C;/a> で説明する決定木の条件として参照されます。&#x3C;/p>
&#x3C;h2>4. 符号化&#x3C;/h2>
&#x3C;p>それでは、予測値の誤差をどのようにビット表現に変換しているのかについて説明していきましょう。 FLIF ではこの符号化手法のことを &#x3C;dfn>MANIAC&#x3C;/dfn> (Meta-Adaptive Near-zero Integer Arithmetic Coding) と呼んでいます。ここでは、算術符号 (Arithmetic Coding)、適応的算術符号 (Adaptive Arithmtic Coding)、 Near-zero Integer Coding、 Meta-Adaptive に分割して説明していきたいと思います。&#x3C;/p>
&#x3C;h3>4.1. 算術符号&#x3C;/h3>
&#x3C;h4>4.1.1. 実数による算術符号&#x3C;/h4>
&#x3C;p>算術符号は、記号の出現確率分布（累積分布）を表す数直線上で、符号化したい記号列がどの位置にあるのか、を記録する符号化方式です。&#x3C;/p>
&#x3C;p>まずは簡単な概念の説明のために、0～1の実数で考えてみます。 FLIF で使用される算術符号では「0」と「1」の2種類の記号だけが登場する（二値算術符号）記号列を扱うので、ここでも2種類の記号で考えます。例えば、「0」が 40% 、「1」が 60% の確率で出現することがわかっているとします。この確率によって、 0～1 の数直線を分割すると、このようになります。数直線上に点を置いたとき 0～0.4 の範囲にあるならば 0、 0.4～1 ならば 1 を表している、と解釈できます。&#x3C;/p>
&#x3C;figure class="fig-img">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/ac_fig1.svg" alt="算術符号を説明する数直線1">&#x3C;/figure>
&#x3C;p>では、この分割を再帰的に用いて、記号列「101」を数直線上に表してみましょう。&#x3C;/p>
&#x3C;p>最初の記号は 1 なので、 0.4～1 の範囲に注目します。この範囲をさらに 40:60 に分割するとこのようになります。&#x3C;/p>
&#x3C;figure class="fig-img">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/ac_fig2.svg" alt="算術符号を説明する数直線2">&#x3C;/figure>
&#x3C;p>2個目の記号は 0 なので、次は 0.4～0.64 の範囲に注目し、同じように分割します。&#x3C;/p>
&#x3C;figure class="fig-img">&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/ac_fig3.svg" alt="算術符号を説明する数直線3">&#x3C;/figure>
&#x3C;p>この結果から、記号列「101」をこの数直線上に表すと 0.496～0.64 の範囲となることがわかりました！ 符号化結果としては、範囲の左端を使って「0.496」とすることにしましょう。このように、記号列を記号の出現確率を使って数直線上に表す方法が、算術符号になります。復号化するときは、「0.496」がどの記号の範囲に含まれているかを、同じように分割しながら探索していきます。&#x3C;/p>
&#x3C;h4>4.1.2. Range Coder&#x3C;/h4>
&#x3C;p>先ほどの例では実数を使って表しましたが、記号列が長くなると相当な精度の小数を使用しなければ正しく符号化結果を記録できないことがわかると思います。また小数を使用すると計算速度も遅くなります。そこで、現実的な実装方法として、整数を使用する Range Coder という手法が用いられます。 FLIF のリファレンス実装のソースコードでは「RAC」と略されています。&#x3C;/p>
&#x3C;p>Range Coder では、正しく符号化結果を記録できるだけの長さ（整数）を持つ数直線上に、記号列をプロットします。とはいえ、その「十分な長さ」がどれだけ長くなるかわからないので、最初の数直線の長さを決めておき、注目範囲が閾値より小さくなったら、数直線の長さを拡張します。 FLIF では、最初の数直線の長さを 24 ビット、閾値を 16 ビットとしています。数直線の長さを拡張する際、そのとき注目している範囲の左端の上位ビット（ここでは差が 8 ビットなので 8 ビット分）を出力します。なぜなら、左端はこれ以上符号化を進めても、現在の右端を超えることはないため、上位ビットの値はほぼ決まっているからです（場合によっては桁上がりが発生して、上位ビットが変わることがあるため、少し工夫が必要です）。&#x3C;/p>
&#x3C;p>詳細なアルゴリズムについては、私よりもうまい説明に任せたいと思います。&#x3C;/p>
&#x3C;ul>
&#x3C;li>&#x3C;a href="http://fussy.web.fc2.com/algo/compress10_arithmetic.htm">&#x3C;cite>圧縮アルゴリズム (10) 算術符号化&#x3C;/cite>&#x3C;/a> (Fussy's HOMEPAGE)&#x3C;/li>
&#x3C;li>&#x3C;a href="http://www.nct9.ne.jp/m_hiroi/light/pyalgo36.html">&#x3C;cite>Algorithms with Python / レンジコーダ (range coder)&#x3C;/cite>&#x3C;/a>&#x3C;/li>
&#x3C;/ul>
&#x3C;h4>4.1.3. コンテキスト&#x3C;/h4>
&#x3C;p>二値のエントロピー符号化全般として、圧縮率を良くするためには、出現確率が 0 と 1 のどちらかに極端に偏っているほうがうれしいです。&#x3C;/p>
&#x3C;p>例えば、4ビットの整数を3個並べたビット列を、算術符号化することを考えてみます。 10, 11, 12 をそのままビット列にすると「1010 1011 1100」となり、 0 の出現確率は 0.417、 1 の出現確率は 0.583 となります。この確率分布で算術符号化しようとすると、出現確率が 0.5 に近く、圧縮する意味がほとんどないことがわかると思います。&#x3C;/p>
&#x3C;p>しかし、見方を変えると偏った分布に見えます。4ビット整数の最上位ビットだけをみると全部 1 です。さすがに 100% の確率で 1 が出現する、としてしまうと、もし 0 が出てしまったときに符号化不可能になってしまいますが、 1 の出現確率を大きくすることで、これらのビットを効率よく圧縮できます。つまり言いたいことは、ビット列をただそのままビット列として見るのではなく、ビットの持つ意味や符号化の状況（この例では整数の何ビット目か）ごとに確率分布を変えることで、圧縮率を改善できるということです。意味ごとの確率分布をコンテキストと呼びます。&#x3C;/p>
&#x3C;p>ただし FLIF ではコンテキストのコンテキストを考える必要があり、言葉が混乱するので、&#x3C;strong>この後で「確率表 (chance table)」と「コンテキスト」に分割して再定義します&#x3C;/strong>。&#x3C;/p>
&#x3C;h3>4.2. 適応的算術符号&#x3C;/h3>
&#x3C;p>先ほどの例では 0 と 1 の出現確率が分かっているという前提がありました。つまり符号化・復号化を行うには、事前に出現確率を仮定しておくか、出力に出現確率を記録するかをしなければいけません。しかし、雑に出現確率を仮定して符号化をすると、もし実際の記号列が仮定した出現確率と異なる分布だった場合、圧縮率は悪化してしまいます。そこで、出現確率を記録しておく必要はなく、雑な出現確率の仮定で、それなりに圧縮率を改善する方法として、符号化を行いながら確率を変化させる手法があります。実際の記号列に適応していくことから、適応的 (adaptive) と呼ばれます。コンテキストを使用する場合は、コンテキストごとに別々に適応させていくことができます。&#x3C;/p>
&#x3C;p>FLIF で使用されている適応方法は非常に簡単なものです。初期の出現確率は仕様で指定されています。1ビットを符号化する（数直線を変化させる）たびに、出現確率を変化させます。変化量は、ビットが 0 ならば、 0 の出現確率を少し増やす（= 1 の出現確率を少し減らす）、 1 ならば 1 の出現確率を少し増やすというものです。&#x3C;/p>
&#x3C;h3>4.3. Near-zero Integer Coding&#x3C;/h3>
&#x3C;p>FLIF では、各画素について、予測値からの誤差（整数）を記録します。予測が当たれば誤差は 0 に、当たらなくても大抵は近い値になるので誤差は 0 前後になるはずです。そこで、 0 に近いほどビット数が少なく済むような方法で、誤差を記録します。&#x3C;/p>
&#x3C;p>ビット列は、次のような構成になっています。&#x3C;/p>
&#x3C;ol>
&#x3C;li>ゼロフラグ&#x3C;/li>
&#x3C;li>正負符号&#x3C;/li>
&#x3C;li>指数&#x3C;/li>
&#x3C;li>仮数&#x3C;/li>
&#x3C;/ol>
&#x3C;p>もし値がゼロなら、ゼロフラグを 1 としておしまいです。そうでなければ、正(1)か負(0)か、何ビットあるか、数値のビット列、の順で記録します。&#x3C;/p>
&#x3C;p>例えば、「5」を符号化すると次のようになります。&#x3C;/p>
&#x3C;figure class="fig-table" data-num="表">
&#x3C;figcaption>表 3: 「5」を Near-zero Integer Coding で符号化&#x3C;/figcaption>
&#x3C;table>
&#x3C;tbody>&#x3C;tr>
  &#x3C;th scope="row">ビット
  &#x3C;/th>&#x3C;td align="center">0
  &#x3C;/td>&#x3C;td align="center">1
  &#x3C;/td>&#x3C;td align="center">0
  &#x3C;/td>&#x3C;td align="center">0
  &#x3C;/td>&#x3C;td align="center">1
  &#x3C;/td>&#x3C;td align="center">0
  &#x3C;/td>&#x3C;td align="center">1
&#x3C;/td>&#x3C;/tr>&#x3C;tr>
  &#x3C;th scope="row">ビット名
  &#x3C;/th>&#x3C;td align="center">ZERO
  &#x3C;/td>&#x3C;td align="center">SIGN
  &#x3C;/td>&#x3C;td align="center">EXP(0, +)
  &#x3C;/td>&#x3C;td align="center">EXP(1, +)
  &#x3C;/td>&#x3C;td align="center">EXP(2, +)
  &#x3C;/td>&#x3C;td align="center">MANT(1)
  &#x3C;/td>&#x3C;td align="center">MANT(0)
&#x3C;/td>&#x3C;/tr>&#x3C;/tbody>&#x3C;/table>
&#x3C;/figure>
&#x3C;p>指数部は数値が何ビットあるかを表します。数値が何ビットあるかは 0 が連続した数で決まります。この例では、 0 が 2 個続き、その次が 1 なので、 3 ビットの数値を表していることを表現しています。&#x3C;/p>
&#x3C;p>仮数部は、最上位ビット以外の値がそのまま出力されます。最上位ビットについては、何ビットあるかが指数部で示されているので、 1 であることが確定しています。&#x3C;/p>
&#x3C;p>ただし、数値の取りうる範囲によっては、一部ビットが省略されることがあります。ここでは最小値を任意の負値、最大値を 5 として、 5 を符号化した例を見てみましょう。&#x3C;/p>
&#x3C;figure class="fig-table" data-num="表">
&#x3C;figcaption>表 4: 「5」を最大値 5 の Near-zero Integer Coding で符号化&#x3C;/figcaption>
&#x3C;table>
&#x3C;tbody>&#x3C;tr>
  &#x3C;th scope="row">ビット
  &#x3C;/th>&#x3C;td align="center">0
  &#x3C;/td>&#x3C;td align="center">1
  &#x3C;/td>&#x3C;td align="center">0
  &#x3C;/td>&#x3C;td align="center">0
  &#x3C;/td>&#x3C;td align="center">1
&#x3C;/td>&#x3C;/tr>&#x3C;tr>
  &#x3C;th scope="row">ビット名
  &#x3C;/th>&#x3C;td align="center">ZERO
  &#x3C;/td>&#x3C;td align="center">SIGN
  &#x3C;/td>&#x3C;td align="center">EXP(0, +)
  &#x3C;/td>&#x3C;td align="center">EXP(1, +)
  &#x3C;/td>&#x3C;td align="center">MANT(0)
&#x3C;/td>&#x3C;/tr>&#x3C;/tbody>&#x3C;/table>
&#x3C;/figure>
&#x3C;p>まず、指数部の最後のビットが省略されました。なぜなら、最大値 5 は 3 ビットで表されるので 0 が 2 個続いた時点で、 3 ビットであることが確定するからです。次に仮数部の下位2ビット目が省略されました。なぜなら、 3 ビットで表す必要がある数値は 4 または 5 だけなので、下位 2 ビット目は必ず 0 になることが確定しているからです。このように実際に書き込まなくてもわかる場合は、ビットを省略する動作をします。&#x3C;/p>
&#x3C;p>&#x3C;a href="https://blog.azyobuzi.net/2020/10/11/01-flif/#tbl-nz51">表 3&#x3C;/a>、&#x3C;a href="https://blog.azyobuzi.net/2020/10/11/01-flif/#tbl-nz52">表 4&#x3C;/a> には、ビット名という行を用意しました。これは &#x3C;a href="https://blog.azyobuzi.net/2020/10/11/01-flif/#sec-context">Section 4.1.3&#x3C;/a> で説明したコンテキストが実際どのように使用されているのかを表しています。ビット名単位で適応が行われます。つまり予測器の出力が 0 になることが多ければ ZERO が 1 になる確率が適応によって段々と大きくなるし、正になることが多ければ SIGN が 1 になる確率が適応によって段々と大きくなるということです。&#x3C;/p>
&#x3C;p>ビット名は ZERO, SIGN, EXP(0～9, +), EXP(0～9, -), MANT(0～9) があります。 EXP は値が正か負かによって分かれます。これらそれぞれのビットの確率をまとめたものを、 FLIF では chance table と呼んでいます。ここでは便宜上日本語で「確率表」と呼ぶことにします。 Near-zero Integer は確率表を用いて適応的算術符号化を行うことができるということになります。ビット名に対応する初期確率は、仕様で定められています。&#x3C;/p>
&#x3C;h3>4.4. Meta-Adaptive&#x3C;/h3>
&#x3C;h4>4.4.1. ざっくりとした説明&#x3C;/h4>
&#x3C;p>ここまでで、各画素値を周囲の画素値を使って予測し、その予測誤差を確率表を使って適応的算術符号化して記録するということがわかりました。しかしまだ終わりではありません。 FLIF では確率表を状況に応じて使い分けます。つまり&#x3C;strong>確率表のコンテキスト&#x3C;/strong>を考えます。これが FLIF 用語での「コンテキスト」になります。&#x3C;/p>
&#x3C;p>コンテキストについてざっくりいうと、符号化しようとしている画素に関する情報を条件とする決定木によって、使用する確率表が決定します（&#x3C;a href="https://blog.azyobuzi.net/2020/10/11/01-flif/#img-ctx-summary">図 5&#x3C;/a>）。条件には他のチャンネルの画素値や、周辺画素同士の差といった情報が使えます。条件に使用できる情報をそれぞれプロパティと呼び、非インターレース方式で10種類、インターレース方式で17種類のプロパティがあります。プロパティ値がある値より大きい場合と、ある値以下の場合で分岐します。&#x3C;/p>
&#x3C;figure class="fig-img" data-num="図">
&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/ctx_summary.svg" alt="">
&#x3C;figcaption>図 5: 確率表のコンテキストを選択する決定木&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;h4>4.4.2. カウンター&#x3C;/h4>
&#x3C;p>さらに踏み込んで見てみます。もし最初から &#x3C;a href="https://blog.azyobuzi.net/2020/10/11/01-flif/#img-ctx-summary">図 5&#x3C;/a> のように使用する確率表が決まるとすると、それぞれの確率表の初期値はどのように決まるのでしょうか？ 確率表それぞれが別々に適応を行っていくので、すべての確率表を仕様で定められた確率で初期化したら、適応によって確率表が温まるまでの間に全画素についての処理が終わってしまいます。そこで FLIF の決定木にはカウンターという機能が盛り込まれています。&#x3C;/p>
&#x3C;p>カウンターの説明のため、根と2つの葉だけの決定木を考えてみます。葉以外のノードは、条件とカウンターを持っています。この決定木を使って、画像を復号化することを例にカウンターの挙動を説明します。&#x3C;/p>
&#x3C;figure class="fig-img" data-num="図">
&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/ctx_counter_1.svg" height="200" alt="">
&#x3C;figcaption>図 6: 決定木の初期状態&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>この決定木を使って、画素をひとつ復号化してみましょう。まず決定木の根に注目します。するとカウンターの値は2です。注目したノードのカウンターが 0 より大きいとき、そのノードが持つ確率表を使って画素を復号化します。このとき、読み取ったビット列によって適応が行い、確率表1を更新します。そして、ノードのカウンターをデクリメントします。&#x3C;/p>
&#x3C;figure class="fig-img" data-num="図">
&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/ctx_counter_2.svg" height="200" alt="">
&#x3C;figcaption>図 7: カウンターがデクリメントされる&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>次の画素の復号化も同じように行います。すると根のカウンターが 0 になりました。もしノードのカウンターが 0 になったならば、そのノードの子ノードに確率表をコピーします。&#x3C;/p>
&#x3C;figure class="fig-img" data-num="図">
&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/ctx_counter_3.svg" height="200" alt="">
&#x3C;figcaption>図 8: カウンターが0になると子に確率表がコピーされる&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>いま、確率表2と確率表3は、確率表1と同じ内容になっています。&#x3C;/p>
&#x3C;figure class="fig-img" data-num="図">
&#x3C;img src="https://blog.azyobuzi.net/2020/10/11/01-flif/ctx_counter_4.svg" height="200" alt="">
&#x3C;figcaption>図 9: カウンターが0になると条件分岐が行われる&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>次の画素を復号化します。まず決定木の根に注目します。するとカウンターの値は 0 です。注目したノードのカウンターが 0 のとき、そのノードの条件を評価します。ここではプロパティAの値はX以下だったとします。決定木にしたがって分岐を行い、左側の子ノードに注目します。このノードは葉ノードなので、この確率表を使って復号化します。このとき適応によって確率表2が更新されます。&#x3C;/p>
&#x3C;p>このように、カウンターが 0 になって初めて条件分岐が有効になります。つまり、確率表ひとつからスタートし、ある程度適応したら条件によって確率表を分岐させる、という作戦です。このことによって分岐したどの確率表も適応が進んだ状態になっており、効率的な符号化が行えます。この例では根の子が葉でしたが、実際にはもっと複雑な決定木が生成されます。&#x3C;/p>
&#x3C;h4>4.4.3. 符号化時の学習&#x3C;/h4>
&#x3C;p>では、このような決定木をどのように獲得するのでしょうか。 FLIF エンコーダはまず決定木の学習のために何回か画像の符号化を試し、その後完成した決定木を使って最終的な符号化を行います。学習のためのお試し符号化は、デフォルトで2回行われます。&#x3C;/p>
&#x3C;p>決定木の初期状態は1ノードのみ（根かつ葉）で、符号化中に段々と成長していきます。それでは、どのように決定木が成長するのか見てみましょう。&#x3C;/p>
&#x3C;p>葉ノードは次の情報を持っており、これらは1画素を符号化するたびに更新されます。&#x3C;/p>
&#x3C;ul>
&#x3C;li>確率表&#x3C;/li>
&#x3C;li>何回このノードを使ったか &#x3C;var>count&#x3C;/var>&#x3C;/li>
&#x3C;li>このノードを使った符号化で出力した情報量 &#x3C;var>realSize&#x3C;/var>&#x3C;/li>
&#x3C;li>プロパティそれぞれについて
&#x3C;ul>
&#x3C;li>符号化するたびにプロパティ値を足していったもの &#x3C;var>virtPropSum&#x3C;/var> （&#x3C;var>count&#x3C;/var> で割れば平均になる）&#x3C;/li>
&#x3C;li>このプロパティの平均値を条件として分岐していたと仮定したときの確率表 &#x3C;var>virtChances&#x3C;/var> （平均値より大きい場合と、以下の場合のふたつ）&#x3C;/li>
&#x3C;li>このプロパティの平均値を条件として分岐していたと仮定したときの情報量の予測値 &#x3C;var>virtSize&#x3C;/var>&#x3C;/li>
&#x3C;/ul>
&#x3C;/li>
&#x3C;/ul>
&#x3C;p>これらの更新処理を踏まえて、学習における1画素の符号化手順を次に示します。&#x3C;/p>
&#x3C;ol>
&#x3C;li>根から決定木にしたがって葉ノードを探す。&#x3C;/li>
&#x3C;li>&#x3C;var>count&#x3C;/var> をインクリメントする。&#x3C;/li>
&#x3C;li>すべてのプロパティ値を取得し、 &#x3C;var>virtPropSum&#x3C;/var> を更新する。&#x3C;/li>
&#x3C;li>Near-zero Integer のそれぞれのビットを符号化する。
&#x3C;ol>
&#x3C;li>ノードの確率表を使って符号化し、その情報量を &#x3C;var>realSize&#x3C;/var> に加算する。情報量とは算術符号化に使用した確率から求めた、確率が小さいほど大きくなる値のこと。&#x3C;/li>
&#x3C;li>各プロパティについて、 &#x3C;var>virtChances&#x3C;/var> を使って符号化する。 &#x3C;var>virtChances&#x3C;/var> のふたつある確率表のうち、どちらの確率表を使うかは、現在のプロパティ値が &#x3C;code>virtPropSum / count&#x3C;/code> より大きいか、それ以下かで決まる。このときの情報量を &#x3C;var>virtSize&#x3C;/var> に加算する。&#x3C;/li>
&#x3C;/ol>
&#x3C;/li>
&#x3C;/ol>
&#x3C;p>そして、もしもっとも &#x3C;var>virtSize&#x3C;/var> が小さいプロパティについて &#x3C;code>realSize - virtSize&#x3C;/code> が閾値より大きくなったなら、そのプロパティを条件として分岐します。このときの &#x3C;var>count&#x3C;/var> が &#x3C;a href="https://blog.azyobuzi.net/2020/10/11/01-flif/#sec-counter">Section 4.4.2&#x3C;/a> で説明したカウンターになります（実際には決定木自体を符号化するときに効率が良くなるよう、実際の &#x3C;var>count&#x3C;/var> 値よりも少し簡単化します）。&#x3C;/p>
&#x3C;p>このような操作を繰り返して、決定木が成長していきます。適応的符号化のコンテキストを決定木の形式でさらに適応させることから Meta-Adaptive というわけです。&#x3C;/p>
&#x3C;h4>4.4.4. 決定木の符号化&#x3C;/h4>
&#x3C;p>学習した決定木も FLIF ファイルに記録されます。決定木の各ノードについて、条件とするプロパティ番号、カウンター、条件とするプロパティ値が、行きがけ順で記録されます。各ノードについて3つの整数値を記録するので、3つの確率表が用意され、確率表を使って適応的算術符号化されます（Near-zero ではないものもありますが、 Near-zero Integer Coding を利用します）。&#x3C;/p>
&#x3C;h3>4.5. インターレース方式の符号化&#x3C;/h3>
&#x3C;p>非インターレース方式では、すべての画素がこの決定木によって符号化・復号化されます。一方でインターレース方式では、最初から決定木を使うわけではなく、ズームレベルの小さい（数字の大きい）ほうから 12 個については確率表の慣らし運転をします。&#x3C;/p>
&#x3C;p>インターレース方式では、次の順番で符号化されます。&#x3C;/p>
&#x3C;ol>
&#x3C;li>各チャンネルの左上1ピクセルを、定数の確率表を使って符号化&#x3C;/li>
&#x3C;li>根ノードのみを持つ決定木を作成&#x3C;/li>
&#x3C;li>最初の 12 ズームレベルを符号化&#x3C;/li>
&#x3C;li>残りのズームレベルで決定木の学習を行う&#x3C;/li>
&#x3C;li>決定木を符号化&#x3C;/li>
&#x3C;li>残りのズームレベルを符号化&#x3C;/li>
&#x3C;/ol>
&#x3C;p>復号化は、これに合わせて次の順番で行われます。&#x3C;/p>
&#x3C;ol>
&#x3C;li>各チャンネルの左上1ピクセルを、定数の確率表を使って復号化&#x3C;/li>
&#x3C;li>根ノードのみを持つ決定木を作成&#x3C;/li>
&#x3C;li>最初の 12 ズームレベルを復号化&#x3C;/li>
&#x3C;li>決定木を復号化&#x3C;/li>
&#x3C;li>残りのズームレベルを復号化&#x3C;/li>
&#x3C;/ol>
&#x3C;h2>5. まとめ&#x3C;/h2>
&#x3C;p>FLIF は画像を次のように圧縮符号化しています。&#x3C;/p>
&#x3C;ol>
&#x3C;li>色空間やパレットの変換（説明できるほど読み込んでいないので、この記事では紹介できませんでした）&#x3C;/li>
&#x3C;li>画素値を周辺画素から予測し、予測誤差を求める&#x3C;/li>
&#x3C;li>MANIAC という手法で予測誤差を符号化
&#x3C;ol>
&#x3C;li>画像を試しに符号化してみて、予測誤差の傾向を決定木の形式で学習&#x3C;/li>
&#x3C;li>決定木も出力ファイルに記録&#x3C;/li>
&#x3C;/ol>
&#x3C;/li>
&#x3C;/ol>
&#x3C;p>この記事が、画像の可逆圧縮アルゴリズムを調べている方の助けになればと思います。&#x3C;/p></content><id>https://blog.azyobuzi.net/2020/10/11/01-flif/</id><link href="https://blog.azyobuzi.net/2020/10/11/01-flif/" rel="alternate" type="text/html" /><link href="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20201011/20201011144205.png" rel="enclosure" /><published>2020-10-11T20:51:00+09:00</published><title type="html">画像可逆圧縮形式 FLIF についてのメモ</title><updated>2021-09-27T19:22:31+09:00</updated></entry><entry><category term="tech" label="tech" /><category term="C#" label="C#" /><category term="Docker" label="Docker" /><content type="html">&#x3C;p>開発環境を Docker でいい感じにしてくれるやつとして、 Visual Studio では「コンテナー開発ツール」が、 Visual Studio Code には Remote 拡張があります。これらは Dockerfile や docker-compose.yml を用意すると、その中でアプリを動かすことができるやつです。しかし、同じものではないので、挙動はまったく異なります。それぞれメリット、デメリットがあるので、両方使えるとうれしいわけです。そこで、うまいこと両方で使える docker-compose.yml を書いてみようという試みをやっていきます。&#x3C;/p>
&#x3C;h2>それぞれのメリット、デメリット&#x3C;/h2>
&#x3C;p>コンテナ化、特に Docker Compose を使いたい理由として、クラサバ型データベースを開発環境に置きたいという欲求があります。適当にデバッグ実行したら適当なデータベースが動いていると便利です。というわけで、今回は PostgreSQL コンテナとアプリ開発環境が共存することを目標とします。&#x3C;/p>
&#x3C;p>Visual Studio の Docker 連携は、コンテナにビルド結果とデバッガーの口をマウントして、コンテナ内でアプリを実行してくれます。メリットは、開発環境はホストにあるので、 Visual Studio をフルに使えることです。デメリットは、コンテナ内に入って何か操作するというのが面倒なところです。&#x3C;/p>
&#x3C;p>VSCode Remote は、コンテナの中で VSCode が動きます。ホストのディレクトリをコンテナにマウントすることで、ホストのファイルを編集できます。メリットは、 VSCode のターミナルからコンテナ内を触り放題なところです。例えば Windows で開発していて、 Linux で動かしたい開発ツールがあるときには便利です。デメリットは、 Visual Studio に慣れた人間にとって、 VSCode の C# 拡張は不足を感じるところです。&#x3C;/p>
&#x3C;p>データベースを置くという今回の仮定では、データベースを手で操作するときに簡単に環境に入るために VSCode を使いたいものの、メインの開発は Visual Studio でしたい、となり、共存させたい欲求が発生しています。&#x3C;/p>
&#x3C;h2>やっていく&#x3C;/h2>
&#x3C;h3>1. Visual Studio で連携を設定する&#x3C;/h3>
&#x3C;p>ここで説明する手順を実行するには、 Visual Studio 2019 で「ASP.NET と Web 開発」または「.NET Core クロスプラットフォームの開発」ワークロードがインストールされている必要があります。&#x3C;/p>
&#x3C;p>ソリューションエクスプローラーで、 Docker で動かしたいプロジェクトを右クリックし、「コンテナー オーケストレーターのサポート」を追加します。&#x3C;/p>
&#x3C;figure class="fig-img">&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20200928/20200928004102.png" alt="「コンテナー オーケストレーターのサポート」を追加">&#x3C;/figure>
&#x3C;p>いろいろ聞かれますが、 OS は Linux、ツールは Docker Compose としておけば OK です。&#x3C;/p>
&#x3C;p>完了すると、 Dockerfile と「docker-compose」というプロジェクトが生えます。&#x3C;/p>
&#x3C;figure class="fig-img">&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20200928/20200928004106.png" alt="完了後のソリューション">&#x3C;/figure>
&#x3C;p>これで、必要なファイルを Visual Studio に自動生成させることができました。ここから先は生成されたファイル書き換えたり移動させたりして VSCode にフィットさせていきましょう。&#x3C;/p>
&#x3C;h3>2. Dockerfile を改変する&#x3C;/h3>
&#x3C;p>生成された Dockerfile を確認すると、本番ビルド用のスクリプトが書かれています。今回はこれを完全に捨てることにします。ただ、プロジェクトディレクトリ下に Dockerfile がないと Visual Studio が認識してくれないので、ここに開発環境を作成するスクリプトを書きましょう。本番用 Dockerfile はどこか別のところに置いてください……。&#x3C;/p>
&#x3C;p>最低限必要なのは &#x3C;code>FROM mcr.microsoft.com/dotnet/core/sdk:3.1-buster&#x3C;/code> だけです。「buster」のところは好きなディストリビューションに変えてください。必要に応じて、例えば今回の仮定ならば postgresql-client を入れたりするのもいいでしょう。&#x3C;/p>
&#x3C;h3>3. docker-compose.yml を改変する&#x3C;/h3>
&#x3C;p>ここからの操作は Visual Studio を破壊するので、すべてが完了するまで Visual Studio は閉じておきましょう。&#x3C;/p>
&#x3C;p>いま、ソリューションディレクトリ直下に「docker-compose.yml」と「docker-compose.override.yml」があります。直下にあってもわかりにくいので、後で devcontainer.json というファイルを入れることになる .devcontainer というディレクトリをつくっておき、そこに移動させます。&#x3C;/p>
&#x3C;figure class="fig-img">&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20200928/20200928010233.png" alt="docker-compose.yml を .devcontainer へ移動">&#x3C;/figure>
&#x3C;p>さらに、 docker-compose.override.yml という名前だと Visual Studio 用なのか VSCode 用なのかわかりにくいので、 docker-compose.vs.yml に改名しておくといいでしょう。&#x3C;/p>
&#x3C;p>いま docker-compose.yml の中身はこのようになっていると思います。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>docker-compose.yml&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-yaml">&#x3C;span class="hljs-attr">version:&#x3C;/span> &#x3C;span class="hljs-string">"3.4"&#x3C;/span>

&#x3C;span class="hljs-attr">services:&#x3C;/span>
  &#x3C;span class="hljs-attr">mydatabaseapp:&#x3C;/span>
    &#x3C;span class="hljs-attr">image:&#x3C;/span> &#x3C;span class="hljs-string">${DOCKER_REGISTRY-}mydatabaseapp&#x3C;/span>
    &#x3C;span class="hljs-attr">build:&#x3C;/span>
      &#x3C;span class="hljs-attr">context:&#x3C;/span> &#x3C;span class="hljs-string">.&#x3C;/span>
      &#x3C;span class="hljs-attr">dockerfile:&#x3C;/span> &#x3C;span class="hljs-string">MyDatabaseApp/Dockerfile&#x3C;/span>
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>改変が必要なポイントは次のふたつです。&#x3C;/p>
&#x3C;ul>
&#x3C;li>&#x3C;code>build.context&#x3C;/code> のパスを正しく直す。 docker-compose.yml を移動したので、それに合わせます。&#x3C;/li>
&#x3C;li>PostgreSQL を追加する。&#x3C;/li>
&#x3C;/ul>
&#x3C;p>改変結果はこんな感じです。 docker-compose.yml の構文バージョンやプロジェクト名は、環境に合わせて書き換えてください。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>docker-compose.yml&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-yaml">&#x3C;span class="hljs-attr">version:&#x3C;/span> &#x3C;span class="hljs-string">"3.4"&#x3C;/span>

&#x3C;span class="hljs-attr">services:&#x3C;/span>
  &#x3C;span class="hljs-attr">mydatabaseapp:&#x3C;/span>
    &#x3C;span class="hljs-attr">build:&#x3C;/span>
      &#x3C;span class="hljs-attr">context:&#x3C;/span> &#x3C;span class="hljs-string">..&#x3C;/span>
      &#x3C;span class="hljs-attr">dockerfile:&#x3C;/span> &#x3C;span class="hljs-string">MyDatabaseApp/Dockerfile&#x3C;/span>

  &#x3C;span class="hljs-attr">db:&#x3C;/span>
    &#x3C;span class="hljs-attr">image:&#x3C;/span> &#x3C;span class="hljs-string">postgres:11&#x3C;/span>
    &#x3C;span class="hljs-attr">environment:&#x3C;/span>
      &#x3C;span class="hljs-attr">POSTGRES_PASSWORD:&#x3C;/span> &#x3C;span class="hljs-string">postgres&#x3C;/span>
    &#x3C;span class="hljs-attr">volumes:&#x3C;/span>
      &#x3C;span class="hljs-bullet">-&#x3C;/span> &#x3C;span class="hljs-string">./db/data:/var/lib/postgresql/data&#x3C;/span>
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>データベースのデータの永続化は、ホストのパスを指定するか、この docker-compose.yml の外で作成したボリュームを割り当ててください。でないと、 VS と VSCode で Docker Compose のプロジェクト名が異なるので、同じデータを見てくれません。&#x3C;/p>
&#x3C;h3>4. docker-compose.dcproj を改変する&#x3C;/h3>
&#x3C;p>docker-compose.yml を移動したので、 docker-compose.dcproj も書き換えます。これもソリューションディレクトリ直下にあると邪魔なので .devcontainer に移動させてしまいましょう。&#x3C;/p>
&#x3C;p>さらにファイル名変更を反映して、ディレクトリ外に行ってしまった .dockerignore をプロジェクトから消します。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>docker-compose.dcproj&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-diff"> &#x26;#x3C;?xml version="1.0" encoding="utf-8"?>
 &#x26;#x3C;Project ToolsVersion="15.0" Sdk="Microsoft.Docker.Sdk">
   &#x26;#x3C;PropertyGroup Label="Globals">
     &#x26;#x3C;ProjectVersion>2.1&#x26;#x3C;/ProjectVersion>
     &#x26;#x3C;DockerTargetOS>Linux&#x26;#x3C;/DockerTargetOS>
     &#x26;#x3C;ProjectGuid>3caba81b-3f76-4ecf-9907-78b96280d41c&#x26;#x3C;/ProjectGuid>
   &#x26;#x3C;/PropertyGroup>
   &#x26;#x3C;ItemGroup>
&#x3C;span class="hljs-deletion">-    &#x26;#x3C;None Include="docker-compose.override.yml">&#x3C;/span>
&#x3C;span class="hljs-addition">+    &#x26;#x3C;None Include="docker-compose.vs.yml">&#x3C;/span>
       &#x26;#x3C;DependentUpon>docker-compose.yml&#x26;#x3C;/DependentUpon>
     &#x26;#x3C;/None>
     &#x26;#x3C;None Include="docker-compose.yml" />
&#x3C;span class="hljs-deletion">-    &#x26;#x3C;None Include=".dockerignore" />&#x3C;/span>
   &#x26;#x3C;/ItemGroup>
 &#x26;#x3C;/Project>
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>またソリューションファイルもパスを書き換えます。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>MyDatabaseApp.sln&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-diff">&#x3C;span class="hljs-deletion">-Project("{E53339B2-1760-4266-BCC7-CA923CBCF16C}") = "docker-compose", "docker-compose.dcproj", "{3CABA81B-3F76-4ECF-9907-78B96280D41C}"&#x3C;/span>
&#x3C;span class="hljs-addition">+Project("{E53339B2-1760-4266-BCC7-CA923CBCF16C}") = "docker-compose", ".devcontainer\docker-compose.dcproj", "{3CABA81B-3F76-4ECF-9907-78B96280D41C}"&#x3C;/span>
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;h3>5. VSCode 向けの docker-compose.yml をつくる&#x3C;/h3>
&#x3C;p>VSCode 向けに .devcontainer/docker-compose.vscode.yml を作っていきます。ポイントは次のふたつです。&#x3C;/p>
&#x3C;ul>
&#x3C;li>コンテナが終了しないように無限ループさせる&#x3C;/li>
&#x3C;li>作業ディレクトリをマウントする&#x3C;/li>
&#x3C;/ul>
&#x3C;p>実際の YAML で表すとこれだけです。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>docker-compose.vscode.yml&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-yaml">&#x3C;span class="hljs-attr">version:&#x3C;/span> &#x3C;span class="hljs-string">"3.4"&#x3C;/span>

&#x3C;span class="hljs-attr">services:&#x3C;/span>
  &#x3C;span class="hljs-attr">mydatabaseapp:&#x3C;/span>
    &#x3C;span class="hljs-attr">command:&#x3C;/span> &#x3C;span class="hljs-string">/bin/sh&#x3C;/span> &#x3C;span class="hljs-string">-c&#x3C;/span> &#x3C;span class="hljs-string">"while sleep 1000; do :; done"&#x3C;/span>
    &#x3C;span class="hljs-attr">volumes:&#x3C;/span>
      &#x3C;span class="hljs-bullet">-&#x3C;/span> &#x3C;span class="hljs-string">..:/workspace:cached&#x3C;/span>
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>必要に応じて、ポートを公開するために &#x3C;code>ports&#x3C;/code> を追加したりしてください。&#x3C;/p>
&#x3C;p>参考: &#x3C;a href="https://bufferings.hatenablog.com/entry/2020/06/11/233201">&#x3C;cite>VS Code Remote - Containers を Docker Compose で使うのだー！ - Mitsuyuki.Shiiba&#x3C;/cite>&#x3C;/a>&#x3C;/p>
&#x3C;h3>6. devcontainer.json をつくる&#x3C;/h3>
&#x3C;p>devcontainer.json は VSCode にコンテナ作成を指示する設定ファイルです。これも .devcontainer に置きます。&#x3C;/p>
&#x3C;p>最小限の devcontainer.json はこんな感じです。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>devcontainer.json&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-json">&#x3C;span class="hljs-punctuation">{&#x3C;/span>
  &#x3C;span class="hljs-attr">"dockerComposeFile"&#x3C;/span>&#x3C;span class="hljs-punctuation">:&#x3C;/span> &#x3C;span class="hljs-punctuation">[&#x3C;/span>&#x3C;span class="hljs-string">"docker-compose.yml"&#x3C;/span>&#x3C;span class="hljs-punctuation">,&#x3C;/span> &#x3C;span class="hljs-string">"docker-compose.vscode.yml"&#x3C;/span>&#x3C;span class="hljs-punctuation">]&#x3C;/span>&#x3C;span class="hljs-punctuation">,&#x3C;/span>

  &#x3C;span class="hljs-comment">// docker-compose.yml の services のうち、開発環境につかうもの&#x3C;/span>
  &#x3C;span class="hljs-attr">"service"&#x3C;/span>&#x3C;span class="hljs-punctuation">:&#x3C;/span> &#x3C;span class="hljs-string">"mydatabaseapp"&#x3C;/span>&#x3C;span class="hljs-punctuation">,&#x3C;/span>

  &#x3C;span class="hljs-comment">// docker-compose.vscode.yml で指定したマウント先&#x3C;/span>
  &#x3C;span class="hljs-attr">"workspaceFolder"&#x3C;/span>&#x3C;span class="hljs-punctuation">:&#x3C;/span> &#x3C;span class="hljs-string">"/workspace"&#x3C;/span>&#x3C;span class="hljs-punctuation">,&#x3C;/span>

  &#x3C;span class="hljs-comment">// 事前にインストールしておいてほしい拡張&#x3C;/span>
  &#x3C;span class="hljs-attr">"extensions"&#x3C;/span>&#x3C;span class="hljs-punctuation">:&#x3C;/span> &#x3C;span class="hljs-punctuation">[&#x3C;/span>&#x3C;span class="hljs-string">"ms-dotnettools.csharp"&#x3C;/span>&#x3C;span class="hljs-punctuation">]&#x3C;/span>
&#x3C;span class="hljs-punctuation">}&#x3C;/span>
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>いじり倒したいときは &#x3C;a href="https://code.visualstudio.com/docs/remote/devcontainerjson-reference">&#x3C;cite>devcontainer.json reference&#x3C;/cite>&#x3C;/a> を読むといいでしょう。&#x3C;/p>
&#x3C;h3>完成！&#x3C;/h3>
&#x3C;p>これで準備完了です。 VSCode で「Reopen in Container」を実行すると、コンテナ上で VSCode が動き始めます。 Dockerfile のビルドが走るので気長に待ちましょう。&#x3C;/p>
&#x3C;p>また、 Visual Studio でも docker-compose プロジェクトをスタートアッププロジェクトに設定して実行できるはずです！&#x3C;/p>
&#x3C;div class="admonitionblock caution" role="note">&#x3C;div class="icon">Caution&#x3C;/div>&#x3C;div class="content">
&#x3C;p>Visual Studio と VSCode の同時実行は危険です。同じマウント先のデータベースがふたつ動くことになってしまいます。また、それぞれ終了後 30 秒くらいはコンテナが動いているので、コンテナが終了されたことを確認してから、他方を使ってください。&#x3C;/p>
&#x3C;/div>&#x3C;/div>
&#x3C;h2>まとめ&#x3C;/h2>
&#x3C;p>頑張れば Visual Studio でも VSCode でも使える Docker Compose 環境がつくれることを示しました。これで開発が捗ればいいね。捗らんか……。&#x3C;/p>
&#x3C;p>ここまでの内容を clone するだけでお試しできるものを GitHub に置いておきました。&#x3C;/p>
&#x3C;p>&#x3C;a href="https://github.com/azyobuzin/vs-docker-compose-example">azyobuzin/vs-docker-compose-example&#x3C;/a>&#x3C;/p></content><id>https://blog.azyobuzi.net/2020/09/28/01-vs-docker-compose/</id><link href="https://blog.azyobuzi.net/2020/09/28/01-vs-docker-compose/" rel="alternate" type="text/html" /><published>2020-09-28T02:29:00+09:00</published><title type="html">Visual Studio と VSCode どちらでも使える Docker Compose 環境</title><updated>2021-09-24T23:30:48+09:00</updated></entry><entry><category term="tech" label="tech" /><category term="Docker" label="Docker" /><content type="html">&#x3C;p>&#x3C;a href="https://cilium.io/">Cilium&#x3C;/a> の Docker プラグインの導入を検討したものの、無理みがあった。ぱたり。&#x3C;/p>
&#x3C;h2>イントロダクション&#x3C;/h2>
&#x3C;p>ケチケチしたインターネットライフに Kubernetes は無縁です。&#x3C;/p>
&#x3C;p>以前、 Docker のネットワークに細かい設定ができないという不満があって、 Kubernetes の調査をしていたこともありました（&#x3C;a href="https://azyobuzin.hatenablog.com/entry/2019/03/21/024504">「&#x3C;cite>Kubernetesで隔離Mastodonネットワークを作った&#x3C;/cite>」&#x3C;/a>）。しかしながら、趣味で動かしている web サーバに Kubernetes を導入するのは、ケチケチした人間には不可能です。メモリ 2GB (GMO の株主優待を受けて、スペックアップしました！) の VPS に詰め込めるだけのアプリを詰める、そういうことをしている人間にとっては、 Kubernetes の導入はデメリットの方が多くなります。&#x3C;/p>
&#x3C;p>そんなわけで、私が管理しているサービスは、基本的に Docker Compose で管理されています。しかし、動かしているアプリも増えてきて、 Pleroma のような SSRF 対策も必要なアプリ（例: &#x3C;a href="https://azyobuzin.hatenablog.com/entry/2019/11/12/005317">「&#x3C;cite>比較的安全に Docker で Pleroma サーバーを建てる&#x3C;/cite>」&#x3C;/a>）も出てくると、そろそろ真面目にネットワークポリシーを導入して、安心してコンテナを動かしたくなります。&#x3C;/p>
&#x3C;p>しかしまぁどう検索しても Kubernetes の話しか出てこなくてキレそうだったわけですが、 &#x3C;a href="https://cilium.io/">Cilium&#x3C;/a> という仮想ネットワークツールが Docker のプラグインとして動いてくれるみたいなので、検証してみました。&#x3C;/p>
&#x3C;h2>Docker ネットワークの課題&#x3C;/h2>
&#x3C;p>Docker 標準の bridge ネットワークの表現力を確認して、課題を確認します。&#x3C;/p>
&#x3C;p>まず、 Docker のネットワークとは何かですが、隔離されたサブネットです。コンテナはネットワークに接続することで、そのサブネットの IP アドレスが与えられます。 &#x3C;code>docker network connect&#x3C;/code> コマンドで接続できるので「接続」と書きましたが、「参加」という表現のほうがわかりやすいかもしれません。コンテナは 0 個以上のネットワークに参加することができます。&#x3C;/p>
&#x3C;figure class="fig-img">
&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20200913/20200913020748.png" alt="">
&#x3C;figcaption>コンテナとネットワークの関係&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>基本的なネットワークの種類である bridge ネットワークでは、ネットワークごとに次のような設定ができます。&#x3C;/p>
&#x3C;ol>
&#x3C;li>ネットワーク内のコンテナ間で通信 (Inter Container Connectivity) できるようにするか&#x3C;/li>
&#x3C;li>IP マスカレードを有効にするか = ホストの外に通信できるようにするか&#x3C;/li>
&#x3C;/ol>
&#x3C;p>これの何が不満かというと、コンテナ間の通信の可否はネットワーク単位でしか設定できないということです。&#x3C;/p>
&#x3C;p>例えば、次の図のように、ふたつのアプリがひとつのデータベースを共有しているとします。前提がケチケチなので、アプリごとにデータベースのプロセスを分けたりしないという想定です。これを bridge ネットワークで実現しようとすると、DB、アプリ1、アプリ2が同一ネットワークに参加している必要があります。すると、アプリとデータベースの通信だけできればいいにも関わらず、アプリ同士の通信も可能になっています。これがまずい状況であるという例を示しましょう。アプリ1がクリティカルな情報を扱っているものの、認証は前段のリバースプロキシに任せている、とします。ここでアプリ2に脆弱性があったら、意図せずアプリ1のデータを認証なしで読み出してしまうかもしれません。&#x3C;/p>
&#x3C;figure class="fig-img">
&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20200913/20200913022141.png" alt="">
&#x3C;figcaption>DBを参照するふたつのアプリ&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>このような想定をし始めると、 bridge ネットワークに不満を感じてくるでしょう。コンテナ間の通信を制御しているのは iptables なので、 iptables を直接いじってあげればどうにかできなくはないですが、自分でやりたくはないです。&#x3C;/p>
&#x3C;h2>Cilium&#x3C;/h2>
&#x3C;p>とりあえず「docker network policy」でググってみてください。はい、 1 ページ目のすべてが Kubernetes ですね。というわけで、意外と Docker のネットワークを強固にしようという試みはやられていないようです。存在するネットワークプラグインは皆複数ノードをひとつのネットワークとして使えるようにするみたいなやつばかりです。そんな中で、やっと見つけてきたのが Cilium です。&#x3C;/p>
&#x3C;p>Cilium も複数ノードをひとつのネットワークとして使えるようにするやつのひとつです。メインの用途は Kubernetes の仮想ネットワークです。 Kubernetes の仮想ネットワークといえば、クラスタ内がひとつのネットワークになっていて、初期状態では任意の Pod 同士で通信ができるやつです。そして、それを制限する方法として NetworkPolicy リソースがあります。 Cilium はこれを実現します。&#x3C;/p>
&#x3C;p>Cilium が他の仮想ネットワークツールと違うところは、 Kubernetes がなくてもネットワークポリシーが設定できるところです。つまり単体で使い物になる！ ……はずでした。&#x3C;/p>
&#x3C;h2>Getting Started&#x3C;/h2>
&#x3C;p>Cilium を Docker で使う例は、ドキュメントにこの 1 ページしかありません。ありがとうございました。&#x3C;/p>
&#x3C;p>&#x3C;a href="https://docs.cilium.io/en/v1.8/gettingstarted/docker/">&#x3C;cite>Cilium with Docker &#x26;#x26; libnetwork ― Cilium 1.8.3 documentation&#x3C;/cite>&#x3C;/a>&#x3C;/p>
&#x3C;p>Debian 10 で試してみましたが、特に Linux の設定は必要なく、&#x3C;a href="https://github.com/cilium/cilium/blob/v1.8.3/examples/getting-started/docker-compose.yml">サンプルの docker-compose.yml&#x3C;/a> を投入するだけで起動することができました。&#x3C;/p>
&#x3C;p>とにかく、この 1 ページを一通り読むと、ポリシー設定を突っ込むところまで体験できます。&#x3C;/p>
&#x3C;p>メモリ使用量は Cilium + Consul で 100MB 弱と、まぁまぁ許容範囲内かなというところでした。&#x3C;/p>
&#x3C;h2>で、何がダメだったの？&#x3C;/h2>
&#x3C;ol>
&#x3C;li>ポートバインディング (&#x3C;code>--publish&#x3C;/code>) が使えない&#x3C;/li>
&#x3C;li>ポリシーが永続化されない&#x3C;/li>
&#x3C;/ol>
&#x3C;h3>1. ポートバインディングが使えない&#x3C;/h3>
&#x3C;p>&#x3C;code>docker run -p 80:80 nginx&#x3C;/code> と書くとホストの 80 番ポートからコンテナの 80 番ポートにつながるやつです。 Cilium の Docker プラグインはこのオプションを実装していないので、指定しても何も起こりません。&#x3C;/p>
&#x3C;p>改造して解決しようかと挑んだものの、別の課題を先になんとかしないといけないことがわかったので面倒になりました。&#x3C;/p>
&#x3C;p>これは現実的な解決策があり、 Traefik を使ったリバースプロキシを host ネットワークに用意すればいいです。 Traefik 2 からは TCP のリバースプロキシもできるようになったので、 HTTP に限らず何でもいけます。&#x3C;/p>
&#x3C;h3>2. ポリシーが永続化されない&#x3C;/h3>
&#x3C;p>これが致命的。&#x3C;/p>
&#x3C;p>ポリシーを設定しても永続化してくれません。 Consul や etcd がそこにあるのにどうして記憶してくれないの？&#x3C;/p>
&#x3C;p>永続化されないということは Cilium が起動したときにポリシーを設定する必要があります。これが問題になるのは、特にマシンや Docker デーモンを再起動したときです。 Cilium が起動するのを待ち、ポリシーを設定するようなサイドカーを用意しておかないと、正しくポリシーが適用されません。このようなサイドカーの実装を考え始めると、どんどん制御ループ、つまり Kubernetes のコンセプトに近づいていきます。&#x3C;/p>
&#x3C;h2>結局&#x3C;/h2>
&#x3C;p>&#x3C;a href="https://azyobuzin.hatenablog.com/entry/2019/03/04/144245" title="k3s の中身とメモリ使用量の調査">K3s に最初に食いついた&#x3C;/a>人間なので、諦めて K3s と仲良くするのが一番いいのかもしれません。うっ……。&#x3C;/p>
&#x3C;figure class="fig-quote">
&#x3C;blockquote cite="https://twitter.com/azyobuzin/status/1251774353579978758">
働かざる者Kubeからずというように、個人の趣味プロジェクトでKubernetesを使うべきではない
&#x3C;/blockquote>
&#x3C;figcaption>&#x3C;a href="https://twitter.com/azyobuzin/status/1251774353579978758">@azyobuzin&#x3C;/a>&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;h2>おまけ: IPv6 を使う&#x3C;/h2>
&#x3C;p>&#x3C;a href="https://docs.cilium.io/en/v1.8/gettingstarted/docker/">サンプル&#x3C;/a>をいくらか改造すると IPv6 も使えるようになります。&#x3C;/p>
&#x3C;ol>
&#x3C;li>
&#x3C;p>Vagrantfile の &#x3C;code>cilium_opts&#x3C;/code> から &#x3C;code>--enable-ipv6=false&#x3C;/code> を削除する&#x3C;/p>
&#x3C;/li>
&#x3C;li>
&#x3C;p>&#x3C;code>cilium-net&#x3C;/code> を作成するコマンドで &#x3C;code>--ipv6&#x3C;/code> を指定する&#x3C;/p>
&#x3C;pre>&#x3C;code class="">docker network create --driver cilium --ipam-driver cilium --ipv6 cilium-net
&#x3C;/code>&#x3C;/pre>
&#x3C;/li>
&#x3C;/ol>
&#x3C;p>これでコンテナに IPv6 アドレスが振られるようになります。が、 NAT が設定されないので外に出ていったパケットが帰ってこられなくなります。これは Cilium の Issue に積まれていますが、なかなか修正される様子がないです。ワークアラウンドとしては、自分で ip6tables を設定してねということです。&#x3C;/p>
&#x3C;figure class="fig-quote">
&#x3C;blockquote>
&#x3C;p>Install an ip6tables MASQUERADE rule for IPv6 traffic leaving the node.&#x3C;/p>
&#x3C;pre>&#x3C;code class="">ip6tables -t nat -A POSTROUTING ! -o cilium_+ -s f00d::/16 -j MASQUERADE
&#x3C;/code>&#x3C;/pre>
&#x3C;/blockquote>
&#x3C;figcaption>&#x3C;a href="https://github.com/cilium/cilium/issues/6320#issuecomment-442722329">&#x3C;cite>Cilium needs ip6tables rules to route IPv6 packets · Issue #6320 · cilium/cilium&#x3C;/cite>&#x3C;/a>&#x3C;/figcaption>
&#x3C;/figure></content><id>https://blog.azyobuzi.net/2020/09/14/01-cilium/</id><link href="https://blog.azyobuzi.net/2020/09/14/01-cilium/" rel="alternate" type="text/html" /><published>2020-09-14T22:13:00+09:00</published><title type="html">結局、理想のネットワークは Docker で実現できなかった</title><updated>2021-09-27T19:22:31+09:00</updated></entry><entry><category term="tech" label="tech" /><category term="C#" label="C#" /><content type="html">&#x3C;p>複数のプロジェクトをひとつのリポジトリで管理するとき、プロジェクト間の参照関係は csproj に &#x3C;code>&#x26;#x3C;ProjectReference>&#x3C;/code> を書くわけですが、ここで、このプロジェクトを NuGet パッケージ化するときのことを考えます。例えば、 A と B というプロジェクトがあり、 B が A に依存しているとします。このとき B を &#x3C;code>dotnet pack&#x3C;/code> してできあがるパッケージの A への依存はどのようになるでしょうか？ 実際にやってみると、現在の A のバージョン&#x3C;strong>以上&#x3C;/strong>という依存関係になります。&#x3C;/p>
&#x3C;p>ここで、 A の現在のバージョンを 1.0.0 とします。 Semantic Versioning に従っていると考えると、もし 2.0.0 がリリースされたら、破壊的な変更が入っているかもしれません。それでも B から A への依存は 1.0.0 &#x3C;strong>以上&#x3C;/strong>で良いのでしょうか？ と考えると、「以上」以外の柔軟な依存関係を指定したくなりませんか？ というわけで、 &#x3C;code>&#x26;#x3C;ProjectReference>&#x3C;/code> を使ったプロジェクト間参照で、柔軟なバージョン範囲指定をしたいというのが今回のお話です。&#x3C;/p>
&#x3C;h2>サンプルプロジェクト&#x3C;/h2>
&#x3C;p>文章でだらだらと説明されても読みたくないのはわかります。ので、実際の csproj を示しておきます。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>A/A.csproj&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-xml">&#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">Project&#x3C;/span> &#x3C;span class="hljs-attr">Sdk&#x3C;/span>=&#x3C;span class="hljs-string">"Microsoft.NET.Sdk"&#x3C;/span>>&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">PropertyGroup&#x3C;/span>>&#x3C;/span>
    &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">TargetFramework&#x3C;/span>>&#x3C;/span>netstandard2.0&#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">TargetFramework&#x3C;/span>>&#x3C;/span>
    &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">Version&#x3C;/span>>&#x3C;/span>1.0.0&#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">Version&#x3C;/span>>&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">PropertyGroup&#x3C;/span>>&#x3C;/span>
&#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">Project&#x3C;/span>>&#x3C;/span>
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;figure class="fig-code">
&#x3C;figcaption>B/B.csproj&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-xml">&#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">Project&#x3C;/span> &#x3C;span class="hljs-attr">Sdk&#x3C;/span>=&#x3C;span class="hljs-string">"Microsoft.NET.Sdk"&#x3C;/span>>&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">PropertyGroup&#x3C;/span>>&#x3C;/span>
    &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">TargetFramework&#x3C;/span>>&#x3C;/span>netstandard2.0&#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">TargetFramework&#x3C;/span>>&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">PropertyGroup&#x3C;/span>>&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">ItemGroup&#x3C;/span>>&#x3C;/span>
    &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">ProjectReference&#x3C;/span> &#x3C;span class="hljs-attr">Include&#x3C;/span>=&#x3C;span class="hljs-string">"..\A\A.csproj"&#x3C;/span> />&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">ItemGroup&#x3C;/span>>&#x3C;/span>
&#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">Project&#x3C;/span>>&#x3C;/span>
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>ここで、 B に対して &#x3C;code>dotnet pack&#x3C;/code> を実行したときの nuspec の &#x3C;code>&#x26;#x3C;dependencies>&#x3C;/code> はこのようになります。&#x3C;/p>
&#x3C;pre>&#x3C;code class="language-xml">&#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">dependencies&#x3C;/span>>&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">group&#x3C;/span> &#x3C;span class="hljs-attr">targetFramework&#x3C;/span>=&#x3C;span class="hljs-string">".NETStandard2.0"&#x3C;/span>>&#x3C;/span>
    &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">dependency&#x3C;/span> &#x3C;span class="hljs-attr">id&#x3C;/span>=&#x3C;span class="hljs-string">"A"&#x3C;/span> &#x3C;span class="hljs-attr">version&#x3C;/span>=&#x3C;span class="hljs-string">"1.0.0"&#x3C;/span> &#x3C;span class="hljs-attr">exclude&#x3C;/span>=&#x3C;span class="hljs-string">"Build,Analyzers"&#x3C;/span> />&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">group&#x3C;/span>>&#x3C;/span>
&#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">dependencies&#x3C;/span>>&#x3C;/span>
&#x3C;/code>&#x3C;/pre>
&#x3C;p>&#x3C;code>version="1.0.0"&#x3C;/code> という指定は、「1.0.0 以上」と解釈されます。&#x3C;/p>
&#x3C;h2>目標設定&#x3C;/h2>
&#x3C;p>ここでは、 Semantic Versioning という前提で、 B が依存するのは A v1.0.0 以上 2.0.0 未満、としましょう。こうすれば、 B が A の Public API のみに依存しているならば、 B はこの依存関係が解決できる限り、必ず動作するといえます。&#x3C;/p>
&#x3C;h2>一筋縄で実現できたらブログ書いてない&#x3C;/h2>
&#x3C;p>はい。これは NuGet の Issue (&#x3C;a href="https://github.com/NuGet/Home/issues/5556">NuGet/Home#5556&#x3C;/a>) に挙がっており、現在も実現されていません。しかし頑張ればできないこともない状況になっています。&#x3C;/p>
&#x3C;p>必要なものは &#x3C;a href="https://dotnet.microsoft.com/download/dotnet/5.0">.NET 5.0 Preview SDK&#x3C;/a> (執筆時点で 5.0.100-preview.3.20216.6) です。最新の NuGet を搭載している SDK を使うと、 csproj に少し手を入れるだけで、 &#x3C;code>&#x26;#x3C;ProjectReference>&#x3C;/code> に対する依存関係に介入できるようになります。&#x3C;/p>
&#x3C;h2>目標をクリアする csproj&#x3C;/h2>
&#x3C;p>仕組みとかいいからとりあえず使いたいって人は、これをコピペしてください。バージョンの指定方法は、 NuGet のドキュメント (&#x3C;a href="https://docs.microsoft.com/ja-jp/nuget/concepts/package-versioning#version-ranges">&#x3C;cite>Version ranges&#x3C;/cite>&#x3C;/a>) を確認してください。&#x3C;/p>
&#x3C;pre>&#x3C;code class="language-xml">&#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">Project&#x3C;/span> &#x3C;span class="hljs-attr">Sdk&#x3C;/span>=&#x3C;span class="hljs-string">"Microsoft.NET.Sdk"&#x3C;/span>>&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">PropertyGroup&#x3C;/span>>&#x3C;/span>
    &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">TargetFramework&#x3C;/span>>&#x3C;/span>netstandard2.0&#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">TargetFramework&#x3C;/span>>&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">PropertyGroup&#x3C;/span>>&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">ItemGroup&#x3C;/span>>&#x3C;/span>
    &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">ProjectReference&#x3C;/span> &#x3C;span class="hljs-attr">Include&#x3C;/span>=&#x3C;span class="hljs-string">"..\A\A.csproj"&#x3C;/span> />&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">ItemGroup&#x3C;/span>>&#x3C;/span>

  &#x3C;span class="hljs-comment">&#x26;#x3C;!-- 以下を追加 -->&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">Target&#x3C;/span> &#x3C;span class="hljs-attr">Name&#x3C;/span>=&#x3C;span class="hljs-string">"SetDependencyVersion"&#x3C;/span> &#x3C;span class="hljs-attr">AfterTargets&#x3C;/span>=&#x3C;span class="hljs-string">"_GetProjectReferenceVersions"&#x3C;/span>>&#x3C;/span>
    &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">ItemGroup&#x3C;/span>>&#x3C;/span>
      &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">_ProjectReferencesWithVersions&#x3C;/span> &#x3C;span class="hljs-attr">Update&#x3C;/span>=&#x3C;span class="hljs-string">"..\A\A.csproj"&#x3C;/span> &#x3C;span class="hljs-attr">ProjectVersion&#x3C;/span>=&#x3C;span class="hljs-string">"[1.0.0,2.0.0)"&#x3C;/span> />&#x3C;/span>
    &#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">ItemGroup&#x3C;/span>>&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">Target&#x3C;/span>>&#x3C;/span>
&#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">Project&#x3C;/span>>&#x3C;/span>
&#x3C;/code>&#x3C;/pre>
&#x3C;p>出力される nuspec の &#x3C;code>&#x26;#x3C;dependencies>&#x3C;/code> はこんな感じになります。&#x3C;/p>
&#x3C;pre>&#x3C;code class="language-xml">&#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">dependencies&#x3C;/span>>&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">group&#x3C;/span> &#x3C;span class="hljs-attr">targetFramework&#x3C;/span>=&#x3C;span class="hljs-string">".NETStandard2.0"&#x3C;/span>>&#x3C;/span>
    &#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">dependency&#x3C;/span> &#x3C;span class="hljs-attr">id&#x3C;/span>=&#x3C;span class="hljs-string">"A"&#x3C;/span> &#x3C;span class="hljs-attr">version&#x3C;/span>=&#x3C;span class="hljs-string">"[1.0.0, 2.0.0)"&#x3C;/span> &#x3C;span class="hljs-attr">exclude&#x3C;/span>=&#x3C;span class="hljs-string">"Build,Analyzers"&#x3C;/span> />&#x3C;/span>
  &#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">group&#x3C;/span>>&#x3C;/span>
&#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">dependencies&#x3C;/span>>&#x3C;/span>
&#x3C;/code>&#x3C;/pre>
&#x3C;h2>仕組み&#x3C;/h2>
&#x3C;p>&#x3C;code>dotnet pack&#x3C;/code> (MSBuild で &#x3C;code>Pack&#x3C;/code> ターゲットを実行する) では、 &#x3C;code>&#x26;#x3C;ProjectReference>&#x3C;/code> Item があったら、そのプロジェクトのバージョンを読み込み、 &#x3C;code>&#x26;#x3C;_ProjectReferencesWithVersions>&#x3C;/code> という Item を作成します。そこで、その処理が行われる &#x3C;code>_GetProjectReferenceVersions&#x3C;/code> ターゲットの後に、読み込まれたバージョンを上書きするようなターゲットを作成することで、好きなバージョンに書き換えることができます。&#x3C;/p>
&#x3C;p>ここまでは古い SDK でもできたのですが、古い SDK では &#x3C;code>ProjectVersion&#x3C;/code> 属性にバージョンの&#x3C;strong>範囲&#x3C;/strong>が指定されることを想定していませんでした。つまり &#x3C;code>1.0.0&#x3C;/code> は受け付けるけど、 &#x3C;code>[1.0.0,2.0.0)&#x3C;/code> は受け付けてくれなかったわけです。新しい SDK では、範囲を指定してもエラーにならないようになったので、このようなハックでお茶を濁せるようになりました。&#x3C;/p>
&#x3C;h2>今後もっと簡単になるか？&#x3C;/h2>
&#x3C;p>&#x3C;a href="https://github.com/NuGet/Home/issues/5556">NuGet/Home#5556&#x3C;/a> を監視していきましょう。&#x3C;/p>
&#x3C;h2>NuGet に対するぼやき&#x3C;/h2>
&#x3C;p>依存関係解決の戦略がデフォルトで「条件を満たす最小バージョン」な所為で、依存バージョンをすぐ「以上」にしてしまうのは NuGet の悪いところだなぁと思っています。そのおかげで lock ファイルを使わなくても、あまり崩壊しないという利点はありますが、少なくともリビジョンリリースは自動で最新にしてほしくない？ という思いがあります。&#x3C;/p></content><id>https://blog.azyobuzi.net/2020/05/03/01-projectref/</id><link href="https://blog.azyobuzi.net/2020/05/03/01-projectref/" rel="alternate" type="text/html" /><published>2020-05-03T04:07:00+09:00</published><title type="html">ProjectReference にバージョン範囲を指定したい</title><updated>2021-09-24T23:30:48+09:00</updated></entry><entry><category term="tech" label="tech" /><category term="C#" label="C#" /><content type="html">&#x3C;p>以前、&#x3C;a href="https://azyobuzin.hatenablog.com/entry/2019/05/26/164155">「&#x3C;cite>いまさら使う TPL Dataflow&#x3C;/cite>」&#x3C;/a>で紹介した TPL Dataflow は、入力されたデータを並列に処理するプログラムを、ブロックの組み合わせで簡単に記述できるライブラリです。
&#x3C;a href="https://azyobuzin.hatenablog.com/entry/2019/05/26/164155#%E9%A1%9E%E4%BC%BC%E5%93%81%E3%81%A8%E3%81%AE%E6%AF%94%E8%BC%83">「&#x3C;cite>類似品との比較&#x3C;/cite>」&#x3C;/a>で述べたように、 TPL Dataflow は、プッシュ型とプル型の両方の性質を持っており、送信者（&#x3C;i>Producer&#x3C;/i>）が、受信者（&#x3C;i>Consumer&#x3C;/i>）が処理しきれないほど大量のデータをプッシュしようとするとき、受信者がそのデータの受信を遅延させることで、データフロー内を流れるデータ量を制御します。&#x3C;/p>
&#x3C;p>一方で、このような、大量のデータや時系列データ（イベント列）を入力し、データフロー内を流れるデータ量を制御しながら、並列にデータを加工する仕組みは、一般的に、特に Java のコミュニティでは &#x3C;a href="https://www.reactive-streams.org/">&#x3C;dfn>Reactive Streams&#x3C;/dfn>&#x3C;/a> と呼ばれています。 Reactive Streams に用いられるインターフェイスは Java 9 で &#x3C;code>java.util.concurrent.Flow&#x3C;/code> として標準ライブラリ入りしており、 RxJava や Akka Streams がこのインターフェイスの実装を提供しています（実際には、互換性のため &#x3C;a href="https://github.com/reactive-streams/reactive-streams-jvm">reactive-streams パッケージ&#x3C;/a>を通じて実装しています）。&#x3C;/p>
&#x3C;p>C# においても Reactive Streams は他人事ではなく、 &#x3C;code>java.util.concurrent.Flow&#x3C;/code> と同様のインターフェイスが &#x3C;a href="https://github.com/reactive-streams/reactive-streams-dotnet">Reactive.Streams パッケージ&#x3C;/a>として NuGet で配布されており、標準的なインターフェイスの座を狙っています。また Akka.NET Streams がこのインターフェイスの実装を提供しています。&#x3C;/p>
&#x3C;p>いずれの方法も、 Reactive Extensions (Rx) 的なプッシュ型に対して、流量制限（&#x3C;i>back pressure&#x3C;/i>）を導入することで、データ量を制御しています。この記事では、 Reactive Streams と TPL Dataflow をプロトコル（インターフェイスとその実装方法）から比較します。&#x3C;/p>
&#x3C;h2>1. Reactive Streams&#x3C;/h2>
&#x3C;p>先に Reactive Streams のほうから導入していきましょう。 Reactive Streams の基本思想は、&#x3C;strong>受信者がどれだけデータを受け入れられるかを送信者に申告する&#x3C;/strong>ことによって、流量の合意を取ります。&#x3C;/p>
&#x3C;p>インターフェイスを見ていきましょう。 Reactive Streams では、送信者は &#x3C;dfn>Publisher&#x3C;/dfn>、受信者は &#x3C;dfn>Subscriber&#x3C;/dfn> と呼ばれます。 Publisher は Rx における Observable に対応し、 Subscriber は Observer に対応します。インターフェイスは次のようになっており、 &#x3C;code>IPublisher.Subscribe&#x3C;/code> に、購読者のコールバックを表す &#x3C;code>ISubscriber&#x3C;/code> インスタンスを渡すことによって、購読を開始します。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>&#x3C;a href="https://github.com/reactive-streams/reactive-streams-dotnet/blob/v1.0.2/src/api/Reactive.Streams/IPublisher.cs">IPublisher&#x3C;/a>&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-cs">&#x3C;span class="hljs-keyword">public&#x3C;/span> &#x3C;span class="hljs-keyword">interface&#x3C;/span> &#x3C;span class="hljs-title">IPublisher&#x3C;/span>&#x26;#x3C;&#x3C;span class="hljs-keyword">out&#x3C;/span> &#x3C;span class="hljs-title">T&#x3C;/span>>
{
    &#x3C;span class="hljs-function">&#x3C;span class="hljs-keyword">void&#x3C;/span> &#x3C;span class="hljs-title">Subscribe&#x3C;/span>(&#x3C;span class="hljs-params">ISubscriber&#x26;#x3C;T> subscriber&#x3C;/span>)&#x3C;/span>;
}
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;figure class="fig-code">
&#x3C;figcaption>&#x3C;a href="https://github.com/reactive-streams/reactive-streams-dotnet/blob/v1.0.2/src/api/Reactive.Streams/ISubscriber.cs">ISubscriber&#x3C;/a>&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-cs">&#x3C;span class="hljs-keyword">public&#x3C;/span> &#x3C;span class="hljs-keyword">interface&#x3C;/span> &#x3C;span class="hljs-title">ISubscriber&#x3C;/span>&#x26;#x3C;&#x3C;span class="hljs-keyword">in&#x3C;/span> &#x3C;span class="hljs-title">T&#x3C;/span>>
{
    &#x3C;span class="hljs-function">&#x3C;span class="hljs-keyword">void&#x3C;/span> &#x3C;span class="hljs-title">OnSubscribe&#x3C;/span>(&#x3C;span class="hljs-params">ISubscription subscription&#x3C;/span>)&#x3C;/span>;
    &#x3C;span class="hljs-function">&#x3C;span class="hljs-keyword">void&#x3C;/span> &#x3C;span class="hljs-title">OnNext&#x3C;/span>(&#x3C;span class="hljs-params">T element&#x3C;/span>)&#x3C;/span>;
    &#x3C;span class="hljs-function">&#x3C;span class="hljs-keyword">void&#x3C;/span> &#x3C;span class="hljs-title">OnError&#x3C;/span>(&#x3C;span class="hljs-params">Exception cause&#x3C;/span>)&#x3C;/span>;
    &#x3C;span class="hljs-function">&#x3C;span class="hljs-keyword">void&#x3C;/span> &#x3C;span class="hljs-title">OnComplete&#x3C;/span>(&#x3C;span class="hljs-params">&#x3C;/span>)&#x3C;/span>;
}
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>&#x3C;code>ISubscriber&#x3C;/code> について、 Publisher がデータを送信するために &#x3C;code>OnNext&#x3C;/code> が呼び出され、 Publisher が送信すべきすべてのデータを送信しきったら &#x3C;code>OnComplete&#x3C;/code> が呼び出されます。また Publisher でエラーが発生したら &#x3C;code>OnError&#x3C;/code> が呼び出されます。 &#x3C;code>OnComplete&#x3C;/code> または &#x3C;code>OnError&#x3C;/code> が呼び出されたあとは、いずれのメソッドも呼び出されることはありません。このあたりのルールは Observer とまったく同じになっています。&#x3C;/p>
&#x3C;p>&#x3C;code>IObservable&#x3C;/code>、&#x3C;code>IObserver&#x3C;/code> と比較して、 &#x3C;code>Subscribe&#x3C;/code> の戻り値が &#x3C;code>IDisposable&#x3C;/code> ではなく &#x3C;code>void&#x3C;/code> ですが、これは &#x3C;a href="http://reactivex.io/RxJava/3.x/javadoc/io/reactivex/rxjava3/core/ObservableSource.html#subscribe-io.reactivex.rxjava3.core.Observer-">RxJava にあわせた&#x3C;/a>ためだと思われます。購読の解除には、 &#x3C;code>ISubscriber.OnSubscribe&#x3C;/code> で受け取ることができる &#x3C;code>ISubscription&#x3C;/code> を使います。&#x3C;/p>
&#x3C;p>Observable と異なり、 Subscribe を呼び出した瞬間にデータが飛んでくる（&#x3C;code>ISubscriber.OnNext&#x3C;/code> が呼び出される）ことはありません。 Publisher は Subscriber がどれだけのデータを受け取る準備があるかを確認してから、データを送信します。 Subscriber は、今どれだけのデータを受け取ることができるかを &#x3C;code>OnSubscribe&#x3C;/code> で受け取った &#x3C;code>ISubscription&#x3C;/code> インスタンスを通じて Publisher に申告します。 &#x3C;code>ISubscription&#x3C;/code> は次のように定義されています。 &#x3C;code>Request&#x3C;/code> メソッドに渡す引数が、どれだけデータを受信できるかを表します。 &#x3C;code>Cancel&#x3C;/code> は先ほど説明した &#x3C;code>IDisposable&#x3C;/code> の代わりとなるものです。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>&#x3C;a href="https://github.com/reactive-streams/reactive-streams-dotnet/blob/v1.0.2/src/api/Reactive.Streams/ISubscription.cs">ISubscription&#x3C;/a>&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-cs">&#x3C;span class="hljs-keyword">public&#x3C;/span> &#x3C;span class="hljs-keyword">interface&#x3C;/span> &#x3C;span class="hljs-title">ISubscription&#x3C;/span>
{
    &#x3C;span class="hljs-function">&#x3C;span class="hljs-keyword">void&#x3C;/span> &#x3C;span class="hljs-title">Request&#x3C;/span>(&#x3C;span class="hljs-params">&#x3C;span class="hljs-built_in">long&#x3C;/span> n&#x3C;/span>)&#x3C;/span>;
    &#x3C;span class="hljs-function">&#x3C;span class="hljs-keyword">void&#x3C;/span> &#x3C;span class="hljs-title">Cancel&#x3C;/span>(&#x3C;span class="hljs-params">&#x3C;/span>)&#x3C;/span>;
}
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>Reactive Streams は以上のインターフェイスとルールによって成り立っています。キーポイントは &#x3C;strong>Subscriber が Publisher に自分のキャパシティを伝え、 Publisher はそのキャパシティの範囲内で &#x3C;code>OnNext&#x3C;/code> を呼び出す&#x3C;/strong>ことによって、データを送信を行っているところです。流量についてプル型でありながら、データを送信するタイミングは自由（プッシュ型）というところでしょうか。&#x3C;/p>
&#x3C;p>Reactive Streams には、 Rx と同様に、 &#x3C;strong>Hot な Publisher と Cold な Publisher があります&#x3C;/strong>。 Hot と Cold の違いについては&#x3C;a href="https://blog.xin9le.net/entry/2012/01/18/105003">「&#x3C;cite>Rx入門 (13) - HotとCold - xin9le.net&#x3C;/cite>」&#x3C;/a>が参考になります。ただし、 Reactive Streams では、 Rx と異なり流量制限があります。したがって、 Hot な Publisher や、時系列データを扱う Publisher が Subscriber に対してデータを送信しようとしたとき、キャパシティが足りない Subscriber がいる可能性があります。そのときに、どのような動作をするかは、実装次第です。例えば RxJava において Observable から Publisher に変換するときは、あふれた値を破棄したり、例外を送出したり、などの選択肢が与えられています（参考: &#x3C;a href="http://reactivex.io/RxJava/3.x/javadoc/io/reactivex/rxjava3/core/Observable.html#toFlowable-io.reactivex.rxjava3.core.BackpressureStrategy-">Observable#toFlowable&#x3C;/a>）。&#x3C;/p>
&#x3C;p>最後に、シーケンス図で例を示しておきます。 2 件のデータを出力する Publisher と、データを 1 件ずつ処理することができる Subscriber を接続すると、次のように通信を行います。&#x3C;/p>
&#x3C;figure class="fig-img">
&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20200429/20200429204015.png" alt="">
&#x3C;figcaption>Reactive Streams のシーケンス図&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>実際には、 Cold な Publisher を実装するときには、 &#x3C;code>IPublisher&#x3C;/code> は &#x3C;code>ISubscription&#x3C;/code> を作成するだけの存在となり、 &#x3C;code>ISubscription&#x3C;/code> が実際に Subscriber と通信するような実装になります。&#x3C;/p>
&#x3C;figure class="fig-img">
&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20200429/20200429230100.png" alt="">
&#x3C;figcaption>Cold な Publisher のシーケンス図&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;h2>2. TPL Dataflow&#x3C;/h2>
&#x3C;p>Reactive Streams は流量についてプル型とまとめましたが、 TPL Dataflow では逆の設計思想となっています。 TPL Dataflow では、&#x3C;strong>データをプッシュしてみて、失敗したらプルされるのを待つ&#x3C;/strong>、という戦略を取ることによって、流量制限を実現しています。&#x3C;/p>
&#x3C;p>登場人物の紹介です。 TPL Dataflow では、送信者は &#x3C;dfn>Source&#x3C;/dfn>、受信者は &#x3C;dfn>Target&#x3C;/dfn> と呼ばれます。どちらもデータフローを構成する要素で、これら構成要素のことを&#x3C;dfn>データフローブロック&#x3C;/dfn>と呼びます。&#x3C;/p>
&#x3C;p>まず、データフローブロック共通のインターフェイスである &#x3C;code>IDataflowBlock&#x3C;/code> を導入します。 &#x3C;code>Completion&#x3C;/code> はそのブロックがすべてのデータの処理が完了したら完了する（またはエラーとなる） &#x3C;code>Task&#x3C;/code> を表します。 &#x3C;code>Complete&#x3C;/code> と &#x3C;code>Fault&#x3C;/code> は Reactive Streams の &#x3C;code>ISubscriber.OnComplete&#x3C;/code>、&#x3C;code>OnError&#x3C;/code> に対応するものですが、 Target 以外もこのメソッドを実装します。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>&#x3C;a href="https://docs.microsoft.com/ja-jp/dotnet/api/system.threading.tasks.dataflow.idataflowblock?view=netcore-3.1">IDataflowBlock&#x3C;/a>&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-cs">&#x3C;span class="hljs-keyword">public&#x3C;/span> &#x3C;span class="hljs-keyword">interface&#x3C;/span> &#x3C;span class="hljs-title">IDataflowBlock&#x3C;/span>
{
    Task Completion { &#x3C;span class="hljs-keyword">get&#x3C;/span>; }
    &#x3C;span class="hljs-function">&#x3C;span class="hljs-keyword">void&#x3C;/span> &#x3C;span class="hljs-title">Complete&#x3C;/span>(&#x3C;span class="hljs-params">&#x3C;/span>)&#x3C;/span>;
    &#x3C;span class="hljs-function">&#x3C;span class="hljs-keyword">void&#x3C;/span> &#x3C;span class="hljs-title">Fault&#x3C;/span>(&#x3C;span class="hljs-params">Exception exception&#x3C;/span>)&#x3C;/span>;
}
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>Source から Target への接続は、リンクと呼ばれます。リンクによって、 Source は Target を認知し、もし送信できるデータがあるならば、データを送信します。&#x3C;/p>
&#x3C;p>まずは Source のインターフェイスを見てみます。ユーザーが &#x3C;code>LinkTo&#x3C;/code> を呼び出すことによって、 Source から Target へのリンクが作成されます。戻り値の &#x3C;code>IDisposable&#x3C;/code> を使って、リンクを解除できます。その他のメソッドは Target によって呼び出されます。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>&#x3C;a href="https://docs.microsoft.com/ja-jp/dotnet/api/system.threading.tasks.dataflow.isourceblock-1?view=netcore-3.1">ISourceBlock&#x3C;/a>&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-cs">&#x3C;span class="hljs-keyword">public&#x3C;/span> &#x3C;span class="hljs-keyword">interface&#x3C;/span> &#x3C;span class="hljs-title">ISourceBlock&#x3C;/span>&#x26;#x3C;&#x3C;span class="hljs-keyword">out&#x3C;/span> &#x3C;span class="hljs-title">TOutput&#x3C;/span>> : &#x3C;span class="hljs-title">IDataflowBlock&#x3C;/span>
{
    &#x3C;span class="hljs-function">IDisposable &#x3C;span class="hljs-title">LinkTo&#x3C;/span>(&#x3C;span class="hljs-params">ITargetBlock&#x26;#x3C;TOutput> target, DataflowLinkOptions linkOptions&#x3C;/span>)&#x3C;/span>;
    &#x3C;span class="hljs-function">TOutput &#x3C;span class="hljs-title">ConsumeMessage&#x3C;/span>(&#x3C;span class="hljs-params">DataflowMessageHeader messageHeader, ITargetBlock&#x26;#x3C;TOutput> target, &#x3C;span class="hljs-keyword">out&#x3C;/span> &#x3C;span class="hljs-built_in">bool&#x3C;/span> messageConsumed&#x3C;/span>)&#x3C;/span>;
    &#x3C;span class="hljs-function">&#x3C;span class="hljs-built_in">bool&#x3C;/span> &#x3C;span class="hljs-title">ReserveMessage&#x3C;/span>(&#x3C;span class="hljs-params">DataflowMessageHeader messageHeader, ITargetBlock&#x26;#x3C;TOutput> target&#x3C;/span>)&#x3C;/span>;
    &#x3C;span class="hljs-function">&#x3C;span class="hljs-keyword">void&#x3C;/span> &#x3C;span class="hljs-title">ReleaseReservation&#x3C;/span>(&#x3C;span class="hljs-params">DataflowMessageHeader messageHeader, ITargetBlock&#x26;#x3C;TOutput> target&#x3C;/span>)&#x3C;/span>;
}
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>対して、 Target のインターフェイスは、データを受信するための &#x3C;code>OfferMessage&#x3C;/code> と、 Source の完了を受け取る &#x3C;code>IDataflowBlock.Complete&#x3C;/code>、&#x3C;code>Fault&#x3C;/code> になります。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>&#x3C;a href="https://docs.microsoft.com/ja-jp/dotnet/api/system.threading.tasks.dataflow.itargetblock-1?view=netcore-3.1">ITargetBlock&#x3C;/a>&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-cs">&#x3C;span class="hljs-keyword">public&#x3C;/span> &#x3C;span class="hljs-keyword">interface&#x3C;/span> &#x3C;span class="hljs-title">ITargetBlock&#x3C;/span>&#x26;#x3C;&#x3C;span class="hljs-keyword">in&#x3C;/span> &#x3C;span class="hljs-title">TInput&#x3C;/span>> : &#x3C;span class="hljs-title">IDataflowBlock&#x3C;/span>
{
    &#x3C;span class="hljs-function">DataflowMessageStatus &#x3C;span class="hljs-title">OfferMessage&#x3C;/span>(&#x3C;span class="hljs-params">DataflowMessageHeader messageHeader, TInput messageValue, ISourceBlock&#x26;#x3C;TInput>? source, &#x3C;span class="hljs-built_in">bool&#x3C;/span> consumeToAccept&#x3C;/span>)&#x3C;/span>;
}
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>さて、 &#x3C;code>LinkTo&#x3C;/code> と &#x3C;code>OfferMessage&#x3C;/code> だけで成り立つならば話は簡単だったのですが、流量制限を導入するために、 Source と Target は密接に通信する必要があります。&#x3C;/p>
&#x3C;p>まず、いくつかのメソッドの引数に現れた &#x3C;a href="https://docs.microsoft.com/ja-jp/dotnet/api/system.threading.tasks.dataflow.dataflowmessageheader?view=netcore-3.1">&#x3C;code>DataflowMessageHeader&#x3C;/code>&#x3C;/a> について説明します。中身は &#x3C;code>long&#x3C;/code> 型の数値です。 Source が送信するメッセージには、 Source 内でユニークな（通常連番の） ID が振られます。この ID を用いて、どのメッセージについての呼び出しなのかを判定します（実際には、送信しようとしている最新のメッセージについてかどうかのアサーションを行うために用いられます）。&#x3C;/p>
&#x3C;p>次に、 &#x3C;code>OfferMessage&#x3C;/code> がどのように振る舞うかです。もし、 Target に空きがあり、データを受信することができるならば、 &#x3C;code>DataflowMessageStatus.Accepted&#x3C;/code> を返して終わりです（ただし &#x3C;code>consumeToAccept&#x3C;/code> 引数が &#x3C;code>true&#x3C;/code> ならば、 Source の &#x3C;code>ConsumeMessage&#x3C;/code> を呼び出す必要があります）。一方で、 Target に空きがなく、データを受信することができないとき、 &#x3C;code>DataflowMessageStatus.Postponed&#x3C;/code> を返します。このとき Target は、受信できなかったメッセージの ID をキューに記録します。その後、空きができて受信できるようになったら、キューから ID を取り出し、 &#x3C;code>ConsumeMessage&#x3C;/code> を呼び出すことによって、 Source からデータを受信します。ただし、 Source は複数のリンク先を持つことができ、 Target が &#x3C;code>Postponed&#x3C;/code> を返したとき、他の Target へ送信しようとします。したがって、 &#x3C;code>ConsumeMessage&#x3C;/code> を呼び出しても、データを取得できないことがあります。&#x3C;/p>
&#x3C;p>&#x3C;code>OfferMessage&#x3C;/code> は同一 ID のメッセージについて、複数回呼び出されることを許容する必要があります。これは Source のリンクが変更されたときに、再度送信を試みるためです。&#x3C;/p>
&#x3C;p>&#x3C;code>ReserveMessage&#x3C;/code>、&#x3C;code>ReleaseReservation&#x3C;/code> については、最短一致モード（&#x3C;i>non-greedy mode&#x3C;/i>）を実装するときと、 Source より先に Target が終了するときに Source にリンク解除を要求するために利用されます。&#x3C;/p>
&#x3C;p>ここまでだらだらと文章で説明してきましたが、&#x3C;strong>アホほど面倒くさい&#x3C;/strong>インターフェイスだということがわかったと思います。&#x3C;/p>
&#x3C;p>最後に、 Reactive Streams と同じように、 2 件のデータを出力する Source と、データを 1 件ずつ処理することができる Target のシーケンス図を示します。ここでは、 &#x3C;code>LinkTo&#x3C;/code> のオプションとして、完了を通知する &#x3C;code>&#x3C;a href="https://docs.microsoft.com/ja-jp/dotnet/api/system.threading.tasks.dataflow.dataflowlinkoptions.propagatecompletion?view=netcore-3.1">PropagateCompletion&#x3C;/a> = true&#x3C;/code> を指定したものとします。&#x3C;/p>
&#x3C;figure class="fig-img">
&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20200429/20200429224922.png" alt="">
&#x3C;figcaption>TPL Dataflow のシーケンス図&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;h2>3. 動作開始タイミングの違いについて&#x3C;/h2>
&#x3C;p>TPL Dataflow では、データフローブロック間のリンクが作成された時点で、 Source の準備ができていれば、データが送信されます。次の図は、 Source が送信したデータが Propagator（Target と Source の両方の性質を持つブロック）を経由して Target に到達するフローに対して、前から順にリンクを行ったときの動作の様子です。&#x3C;/p>
&#x3C;figure class="fig-img">
&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20200429/20200429232247.gif" alt="TPL Dataflow が動作を開始する様子">
&#x3C;/figure>
&#x3C;p>一方で、 Reactive Streams では、上の図のような使い方もできますが、通常はフローを作成し、それに対して Subscribe を呼び出すことで実際の処理を開始する、という使い方のほうが一般的かと思います。例えば、次の RxJava の例では、 &#x3C;a href="http://reactivex.io/RxJava/3.x/javadoc/io/reactivex/rxjava3/core/Flowable.html#range-int-int-">&#x3C;code>range&#x3C;/code>&#x3C;/a> という Publisher と、それを加工する &#x3C;code>map&#x3C;/code> を接続したストリーム &#x3C;code>flowable&#x3C;/code>（&#x3C;code>Publisher&#x26;#x3C;Integer>&#x3C;/code> を実装しています）を定義していますが、 &#x3C;code>subscribe&#x3C;/code> を呼び出すまでは、何も処理を行いません。また、 &#x3C;code>range&#x3C;/code> は Cold なストリームなので、複数回 &#x3C;code>subscribe&#x3C;/code> すると、そのたびに値が送信されます。&#x3C;/p>
&#x3C;pre>&#x3C;code class="language-java">&#x3C;span class="hljs-type">var&#x3C;/span> &#x3C;span class="hljs-variable">flowable&#x3C;/span> &#x3C;span class="hljs-operator">=&#x3C;/span> Flowable.range(&#x3C;span class="hljs-number">1&#x3C;/span>, &#x3C;span class="hljs-number">1&#x3C;/span>).map(x -> x + &#x3C;span class="hljs-number">1&#x3C;/span>);
flowable.blockingForEach(System.out::println); &#x3C;span class="hljs-comment">// 2&#x3C;/span>
flowable.blockingForEach(System.out::println); &#x3C;span class="hljs-comment">// 2&#x3C;/span>
&#x3C;/code>&#x3C;/pre>
&#x3C;p>逆に TPL Dataflow で Cold なストリームを実現するには、フローの作成を関数で包むという方法が必要になります。&#x3C;/p>
&#x3C;h2>4. 並列化について&#x3C;/h2>
&#x3C;p>Reactive Streams プロトコルでは、 &#x3C;code>OnNext&#x3C;/code> を並行に呼び出すことを禁止されています。また TPL Dataflow も &#x3C;code>OfferMessage&#x3C;/code> を並行に呼び出すことはできません（これを間違えて、デッドロックを起こした経験が……）。したがって、いずれのプロトコルも、ひとつの Publisher の境界を越えて並列化することはできません。そこで、それぞれの実装から、どのように処理の並列化を行っているかを見ていきましょう。&#x3C;/p>
&#x3C;p>Reactive Streams の実装である RxJava では、並列部分については &#x3C;code>Publisher&#x3C;/code> を実装しない独自の &#x3C;a href="http://reactivex.io/RxJava/3.x/javadoc/io/reactivex/rxjava3/parallel/ParallelFlowable.html">&#x3C;code>ParallelFlowable&#x3C;/code>&#x3C;/a> 型で表されます。並列処理を終え、また直列なフローに戻るときに &#x3C;code>Flowable&#x3C;/code>（&#x3C;code>Publisher&#x3C;/code> の実装）で包み直します。&#x3C;/p>
&#x3C;pre>&#x3C;code class="language-java">&#x3C;span class="hljs-type">var&#x3C;/span> &#x3C;span class="hljs-variable">flowable&#x3C;/span> &#x3C;span class="hljs-operator">=&#x3C;/span> Flowable.range(&#x3C;span class="hljs-number">1&#x3C;/span>, &#x3C;span class="hljs-number">100&#x3C;/span>) &#x3C;span class="hljs-comment">// Flowable&#x3C;/span>
    .parallel() &#x3C;span class="hljs-comment">//  ParallelFlowable&#x3C;/span>
    .runOn(Schedulers.computation())
    .map(x -> x + &#x3C;span class="hljs-number">1&#x3C;/span>)
    .sequential() &#x3C;span class="hljs-comment">// Flowable&#x3C;/span>
    .map(x -> x + &#x3C;span class="hljs-number">1&#x3C;/span>);
&#x3C;/code>&#x3C;/pre>
&#x3C;p>TPL Dataflow では、各データフローブロックが並列に処理を行います。例えば、 &#x3C;code>map&#x3C;/code> に相当する &#x3C;a href="https://docs.microsoft.com/ja-jp/dotnet/api/system.threading.tasks.dataflow.transformblock-2?view=netcore-3.1">&#x3C;code>TransformBlock&#x3C;/code>&#x3C;/a> や、基本的な Target である &#x3C;a href="https://docs.microsoft.com/ja-jp/dotnet/api/system.threading.tasks.dataflow.actionblock-1?view=netcore-3.1">&#x3C;code>ActionBlock&#x3C;/code>&#x3C;/a> はオプションとして &#x3C;a href="https://docs.microsoft.com/ja-jp/dotnet/api/system.threading.tasks.dataflow.executiondataflowblockoptions.maxdegreeofparallelism?view=netcore-3.1">&#x3C;code>MaxDegreeOfParallelism&#x3C;/code>&#x3C;/a> を指定することで、データが並列に処理されます。また RxJava では、並列部分ではデータの順番が維持される保証がありませんが、 &#x3C;code>TransformBlock&#x3C;/code> では &#x3C;code>&#x3C;a href="https://docs.microsoft.com/ja-jp/dotnet/api/system.threading.tasks.dataflow.dataflowblockoptions.ensureordered?view=netcore-3.1">EnsureOrdered&#x3C;/a> = true&#x3C;/code> を指定することで、データの順番を維持できます。&#x3C;/p>
&#x3C;p>いずれも実装の違いであり、インターフェイス上はどうにでもできます。&#x3C;/p>
&#x3C;h2>5. それぞれのメリット、デメリット&#x3C;/h2>
&#x3C;h3>5.1. プロトコル&#x3C;/h3>
&#x3C;p>Reactive Streams のプロトコルには、一度 &#x3C;code>Request&#x3C;/code> した数を取り消せないという問題があります。したがって、状況によって受け入れられるデータ量が増減するようなとき、もっとも保守的な手法、すなわち 1 件受け取っては &#x3C;code>Request(1)&#x3C;/code> を呼び出すという非効率的な方法を取らざるを得なくなります。しかし、これが問題かというと、問題になるユースケースが特に思いつかないです。&#x3C;/p>
&#x3C;p>一方 TPL Dataflow は、独自でデータフローブロックを実装するのが非常に難しいです。標準で提供されているブロックの組み合わせだけでなんとかしてくださいという感じです。&#x3C;/p>
&#x3C;h3>5.2. 実装&#x3C;/h3>
&#x3C;p>Reactive Streams は、 Java では RxJava という最強の実装がありますが、 C# には Akka.NET Streams しかない状況です。 Akka.NET Streams は Akka のランタイムを必要とする重厚なものになっており、 RxJava ほど軽い気持ちで導入しにくいという印象があります。&#x3C;/p>
&#x3C;p>TPL Dataflow は、半標準ライブラリな存在であり、品質も良いです。ただし、提供されているブロックは、有用ではありますが、もしかすると痒いところに手が届かないかもしれないなという品揃えです。ですが、先ほど述べたように、独自でデータフローブロックを実装するのはとても大変です（ある程度妥協できるなら、 &#x3C;a href="https://docs.microsoft.com/ja-jp/dotnet/api/system.threading.tasks.dataflow.dataflowblock.encapsulate?view=netcore-3.1">&#x3C;code>DataflowBlock.Encapsulate&#x3C;/code>&#x3C;/a> という便利メソッドがあることは覚えておいてください）。&#x3C;/p>
&#x3C;h2>6. C# で Reactive Streams とどう向き合うか&#x3C;/h2>
&#x3C;p>Rx と並んで登場した Ix (Interactive Extensions) には AsyncEnumerable が含まれていました。 .NET Standard 2.1 では &#x3C;a href="https://docs.microsoft.com/ja-jp/dotnet/api/system.collections.generic.iasyncenumerable-1?view=netcore-3.1">&#x3C;code>IAsyncEnumerable&#x3C;/code>&#x3C;/a> が標準入りを果たしました。 AsyncEnumerable は、常に &#x3C;code>Request(1)&#x3C;/code> を投げる Reactive Streams と見なすこともできます。&#x3C;/p>
&#x3C;p>ここまで Reactive Streams と TPL Dataflow の比較をしてきましたが、&#x3C;strong>AsyncEnumerable が C# における Reactive Streams の大本命&#x3C;/strong>なのでは、と考えています（正確にはこの章を書き始めて気づいた……）。「並列化について」で述べたように、 Reactive Streams はいくら上流にキャパシティを報告したところで、 &#x3C;code>OnNext&#x3C;/code> を並行実行できません。したがって、キャパシティを報告することにあまり意味はなく、 AsyncEnumerable のように常にプル型でも問題ないと考えられます。キャパシティを気にする必要がある、流量の制御できないデータソースからの入力や、ある程度まとまったデータがないとパフォーマンスメリットがない並列化部分の前後にバッファを置くだけで解決できてしまいます。&#x3C;/p>
&#x3C;p>一方で、並列処理という観点では TPL Dataflow は非常に良質なライブラリです。並列処理において困る部分が隠蔽されており、本質的な処理を書くことに集中できます。&#x3C;/p>
&#x3C;p>現在の私の野心としては、 AsyncEnumerable のメソッドチェーンの中に、 TPL Dataflow を導入することと、 &#x3C;code>IAsyncEnumerable&#x3C;/code> と &#x3C;code>IPublisher&#x3C;/code> の相互変換です。前者によって、 AsyncEnumerable を並列に処理する表現力が向上します。後者は Akka.NET Streams のような Java 由来のライブラリで Reactive Streams の利用が考えられることから、相互変換が容易に行えると便利だという考えです。これらは現在開発中のライブラリ（&#x3C;a href="https://github.com/azyobuzin/BiDaFlow">BiDaFlow&#x3C;/a>）で実現できればなと考えています。&#x3C;/p>
&#x3C;h2>7. おわりに&#x3C;/h2>
&#x3C;p>（Reactive Streams と TPL Dataflow を比較しようと思って書き始めたはずだったのに、最終的に AsyncEnumerable 最強という結論になってしまって :thinking_face:）&#x3C;/p></content><id>https://blog.azyobuzi.net/2020/04/30/01-reactivestreams/</id><link href="https://blog.azyobuzi.net/2020/04/30/01-reactivestreams/" rel="alternate" type="text/html" /><published>2020-04-30T02:36:00+09:00</published><title type="html">プロトコルから比較する Reactive Streams と TPL Dataflow</title><updated>2021-09-27T19:22:31+09:00</updated></entry><entry><category term="tech" label="tech" /><category term="JavaScript" label="JavaScript" /><content type="html">&#x3C;p>Qiita 騒動で脱 Qiita といって静的サイトジェネレータに向き合うみなさん、こんにちは。私はほとんど Qiita に書いていない、根っからのはてなブログユーザーだったのですが、以前からいくつかの理由で脱はてなブログしたいなぁ～と考えており、本日ついに、自前のブログ基盤ができたので、移行していきたいと思います！&#x3C;/p>
&#x3C;p>一発目の記事ということで、ブログの要件と、それに合わせてどうツールを選んだのかについて、書き残しておきたいともいます。&#x3C;/p>
&#x3C;ins class="ins-block" datetime="2021-09-24" role="note">&#x3C;div class="icon">追記 &#x3C;time datetime="2021-09-24">2021/09/24&#x3C;/time>&#x3C;/div>&#x3C;div class="content">
&#x3C;p>AsciiDoc をやめ Markdown に移行しました。&#x3C;/p>
&#x3C;p>&#x3C;a href="https://blog.azyobuzi.net/2021/09/24/01-markdown/">&#x3C;cite>結局ブログをMarkdownで書くことにした話&#x3C;/cite>&#x3C;/a>&#x3C;/p>
&#x3C;/div>&#x3C;/ins>
&#x3C;h2>1. なぜ脱はてなブログ&#x3C;/h2>
&#x3C;ol>
&#x3C;li>
&#x3C;p>URL の永続化&#x3C;/p>
&#x3C;p>簡単に言えば、独自ドメインが良かった。例えば、はてなブログが突然サービスを終了すると言い出したら、今までの記事の URL は無効になってしまいます。そこで、独自ドメインに載せておけば、いざというときに URL を破壊せず、移行することができます。しかし、はてなブログ Pro は、少なくとも私のブログの利用状況に対して、料金が高い。高いよぉ。&#x3C;/p>
&#x3C;p>とはいえ、もうすでにはてなブログに投稿してしまった分はどうしようもないので、このままにしておきます。もしサービスが終了するようなことがあって、私がまだ生きていたら、いくつかはこのドメイン下にコピーして来ようと思います。&#x3C;/p>
&#x3C;/li>
&#x3C;li>
&#x3C;p>マークアップ言語&#x3C;/p>
&#x3C;p>はてな記法は悪くないけど、 &#x3C;code>&#x26;#x3C;code>&#x3C;/code> タグを書きまくるのはつらかった。一方で Markdown は、はてな記法より表現力が低くて、あまり楽しく書けませんでした。&#x3C;/p>
&#x3C;/li>
&#x3C;li>
&#x3C;p>（広告のロードが遅いので、全体的に遅く感じる）&#x3C;/p>
&#x3C;/li>
&#x3C;li>
&#x3C;p>なぜ Qiita ではないのか&#x3C;/p>
&#x3C;figure class="fig-quote">
&#x3C;blockquote cite="https://mstdn.maud.io/@azyobuzin/103884235813994300">
Qiita なんて承認欲求が通常のブログより満たせる以外のメリット何一つないのに、その一点のメリットに負けた人たちが使うサービスでしょゲラゲラって言ってる
&#x3C;/blockquote>
&#x3C;figcaption>&#x3C;a href="https://mstdn.maud.io/@azyobuzin/103884235813994300">@azyobuzin@mstdn.maud.io&#x3C;/a>&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;/li>
&#x3C;/ol>
&#x3C;h2>2. このブログの技術構成&#x3C;/h2>
&#x3C;p>上記の要件を踏まえて、マークアップ言語に AsciiDoc（処理系として &#x3C;a href="https://github.com/asciidoctor/asciidoctor.js">Asciidoctor.js&#x3C;/a>）を、静的サイトジェネレータに &#x3C;a href="https://www.gatsbyjs.org/">Gatsby&#x3C;/a> を選択しました。本当は、管理画面とか欲しいので、静的サイトじゃないほうが好きなのですが、バージョン管理を考えると、実装したくないなぁという気持ちになりました。&#x3C;/p>
&#x3C;p>デザインについては &#x3C;a href="https://milligram.io/">Milligram&#x3C;/a> を使用しました。もともとは 1 から CSS を組んでいたのですが、 Asciidoctor が要求する要素が多すぎて面倒になって、 CSS フレームワークに乗せました。&#x3C;/p>
&#x3C;h2>3. なぜ AsciiDoc&#x3C;/h2>
&#x3C;p>なぜ Markdown ではないのか。&#x3C;/p>
&#x3C;p>プレーンな Markdown （GitHub Flavored ではない）を思い出してください。機能が何もかも足りていないですね。&#x3C;/p>
&#x3C;p>Markdown 処理系を思い出してください。いくつ方言があるんだよお前ら。&#x3C;/p>
&#x3C;p>というわけで、プレーンな Markdown は弱すぎ、方言はみんなバラバラ、 Markdown 対応サービス間でもコピペしたあとに修正を加えるなんて日常茶飯事な、そんなマークアップ言語で書きたくはありません。そこで、もともと機能が豊富で、さらに要素の拡張方法も仕様に含まれている AsciiDoc を採用することにしました。機能豊富なぶん、 HTML への変換結果と、それに必要なスタイルシートがつらいという問題はありますが、該当機能を使うまでは問題を先延ばしにできます。先延ばしていけ。&#x3C;/p>
&#x3C;h2>4. なぜ Gatsby&#x3C;/h2>
&#x3C;p>Gatsby、こいつだけはないなと思っていたツールでした。それなのに今は……。そういうラブコメ好きですよ。&#x3C;/p>
&#x3C;p>静的サイトジェネレータといえば、 Jekyll を筆頭に、有名なものがいくつかありますが、大体どれも共通の問題があり、それは Frontmatter（文書の先頭の &#x3C;code>---&#x3C;/code> から始まる YAML ブロック）が必要ということです。こっちは AsciiDoc で書くつもりですから、そもそも Header Attribute という機能があります。それにも関わらず、 Jekyll も Hugo も Frontmatter を使うんです。許さない。&#x3C;/p>
&#x3C;p>そんな状況なので、既存の静的サイトジェネレータに嫌気がさして、自作を始めましたが、ブログとなるとトップページの記事一覧を作ったり、タグがあったりと考えることが多い上、 HTML テンプレートの処理系に与えるヘルパー関数すら無い状況からのスタートだったので、疲れて飽きてしまいました。&#x3C;/p>
&#x3C;p>そこで、改めて AsciiDoc を使える静的サイトジェネレータを調べていたとき、 Gatsby + AsciiDoc の組み合わせを見て、ふと Gatsby で AsciiDoc を読み込むプラグインである &#x3C;a href="https://github.com/gatsbyjs/gatsby/tree/master/packages/gatsby-transformer-asciidoc">gatsby-transformer-asciidoc のソースコード&#x3C;/a>を読んでみたら、「なんだ、 Gatsby いいじゃん」となって、今に至ります&#x3C;/p>
&#x3C;p>なぜ今まで Gatsby を避けてきたかというと、それはもう人々が声高に React！ PWA！ GraphQL！ モダン！ と叫んでいたからです。バズワードで埋め尽くされた、目的に対して無駄に遠回りなツールだと思っていました。こっちは 静的 HTML を吐き出したいんだ。静的と言いながらブラウザに大量のスクリプトを吐き出させるなんてごめんだという気持ちです。しかし、ちゃんと調べてみたら、まぁ無駄に遠回りなところもありますが、悪くないツールだということがわかりました。&#x3C;/p>
&#x3C;h3>4.1. 静的サイトジェネレータで GraphQL ってどういうこと？&#x3C;/h3>
&#x3C;p>Gatsby の基本的な設計は、&#x3C;a href="https://www.gatsbyjs.org/docs/gatsby-lifecycle-apis/#high-level-overview">ライフサイクルの図&#x3C;/a>がわかりやすいのですが、次のようになっています。&#x3C;/p>
&#x3C;ol>
&#x3C;li>入力データを集める&#x3C;/li>
&#x3C;li>入力データを View に合わせて整形する&#x3C;/li>
&#x3C;li>View をレンダリングする&#x3C;/li>
&#x3C;/ol>
&#x3C;p>「入力データを集める」では、このブログで言えば、ブログの設定や、記事のファイルがあります。ほかには、例えば時事的な内容で考えると、コロナウィルスの感染状況のオープンデータ（ローカルファイルまたは外部リソースとしてダウンロードしてくる）を入力とする、というのが考えられますね。そして、集めたデータを View、ここでは React に渡して、ブラウザで表示できる形式に変換します。&#x3C;/p>
&#x3C;p>では、この流れの中のどこで GraphQL が登場するのかというと、それは、集めた入力データが「オブジェクトの森」として表され、この森の中から、 View に必要なデータを過不足なく取得するときの記述方法として、 GraphQL が向いている、という話になります。&#x3C;/p>
&#x3C;h4>4.1.1. 入力データを集める&#x3C;/h4>
&#x3C;p>入力データは、さまざまな形式であることが考えられるので、プラグイン機構によって柔軟に処理できることが求められます。&#x3C;/p>
&#x3C;p>入力データを集めるだけでも、データソースからの取得と、データの解釈の 2 種類があります。前者は、ファイルシステムやインターネットからデータを取得してきます。後者は、例えば、データが Markdown なら、 Frontmatter を処理したり、 HTML に変換したりして、バイト列から View で使える意味のあるデータに変形します。&#x3C;/p>
&#x3C;p>さて、この取得・解釈パイプラインにおいて、ひとつのデータについて、ひとつの解釈とは限りません。複数のプラグインが同じデータを異なる方法で解釈することもあります。つまり、まっすぐなパイプラインにはなりません。そこで Gatsby が採用した、共通の入力データ形式は「オブジェクトの森」でした。あるデータに対する解釈は、そのデータの子オブジェクトになる、と表現します（&#x3C;a href="https://blog.azyobuzi.net/2020/04/04/01-hello-gatsby/#image-forest-example">図 1&#x3C;/a>）。このような表現を用いることで、非常に柔軟に入力データを扱うことができるようになりました。&#x3C;/p>
&#x3C;figure class="fig-img" data-num="図">
&#x3C;img src="https://cdn-ak.f.st-hatena.com/images/fotolife/a/azyobuzin/20200403/20200403235038.png" width="500" alt="">
&#x3C;figcaption>図 1: データと、データの解釈結果オブジェクト&#x3C;/figcaption>
&#x3C;/figure>
&#x3C;p>さて、ここで入力データを集めてできたオブジェクトの森をどのように扱うか、というのが鍵になります。静的サイトなので、 DB を使うことはできませんから、サイト生成時に集めてきた情報を、ページごとに、表示に必要なだけ抽出する必要があります。そこで、 JavaScript Way ということで、抽出してきたデータが JSON 形式なっていると考えましょう。すると、 JSON を入力とする React コンポーネントを作れば、レンダリングができそうですね。&#x3C;/p>
&#x3C;h3>4.2. GraphQL と Gatsby のビルドプロセス&#x3C;/h3>
&#x3C;p>必要なものは、オブジェクトの森からデータを取り出し、 JSON を作成する方法だということがわかりました。そこで満を持して GraphQL の登場です。 GraphQL はオブジェクトの森に対して柔軟なクエリを記述でき、出力が JSON となります。完璧にマッチしますね。&#x3C;/p>
&#x3C;p>では、どのタイミングで、どのクエリが呼び出されるのでしょうか。答えは、ビルド時にすべてのクエリです。&#x3C;/p>
&#x3C;p>まず、 Gatsby をまだ触っていない方のために、クエリの書き方を紹介します。あるページ &#x3C;code>/hoge&#x3C;/code> に対応する &#x3C;code>pages/hoge.js&#x3C;/code> があったとして、次のように、 &#x3C;code>query&#x3C;/code> または &#x3C;code>pageQuery&#x3C;/code> を &#x3C;code>export&#x3C;/code> することでクエリを指定すると、 &#x3C;code>export default&#x3C;/code> している関数の引数に &#x3C;code>data&#x3C;/code> として、そのクエリの結果が代入されます。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>pages/hoge.js&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-js">&#x3C;span class="hljs-keyword">import&#x3C;/span> &#x3C;span class="hljs-title hljs-class">React&#x3C;/span> &#x3C;span class="hljs-keyword">from&#x3C;/span> &#x3C;span class="hljs-string">"react"&#x3C;/span>
&#x3C;span class="hljs-keyword">import&#x3C;/span> { graphql } &#x3C;span class="hljs-keyword">from&#x3C;/span> &#x3C;span class="hljs-string">"gatsby"&#x3C;/span>

&#x3C;span class="hljs-keyword">export&#x3C;/span> &#x3C;span class="hljs-keyword">default&#x3C;/span> &#x3C;span class="hljs-keyword">function&#x3C;/span> (&#x3C;span class="hljs-params">{ data }&#x3C;/span>) {
  &#x3C;span class="hljs-keyword">const&#x3C;/span> title = data.&#x3C;span class="hljs-property">site&#x3C;/span>.&#x3C;span class="hljs-property">siteMetadata&#x3C;/span>.&#x3C;span class="hljs-property">title&#x3C;/span>
  &#x3C;span class="hljs-keyword">return&#x3C;/span> &#x3C;span class="xml">&#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">p&#x3C;/span>>&#x3C;/span>{title}&#x3C;span class="hljs-tag">&#x26;#x3C;/&#x3C;span class="hljs-name">p&#x3C;/span>>&#x3C;/span>&#x3C;/span>
}

&#x3C;span class="hljs-keyword">export&#x3C;/span> &#x3C;span class="hljs-keyword">const&#x3C;/span> query = graphql&#x3C;span class="hljs-string">`
  query HogePage {
    site {
      siteMetadata {
        title
      }
    }
  }
`&#x3C;/span>
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;p>または、 &#x3C;a href="https://www.gatsbyjs.org/docs/static-query/">StaticQuery&#x3C;/a> コンポーネントを使うことができます。&#x3C;/p>
&#x3C;p>これをビルドツールの観点から見ると、実行するべきクエリは、すべてのページの &#x3C;code>query&#x3C;/code> または &#x3C;code>pageQuery&#x3C;/code>、それと、一度だけ各ページをレンダリングしてみることで、 &#x3C;code>StaticQuery&#x3C;/code> から取得することができます。 Gatsby は、このようにすべてのクエリを収集し、クエリ結果を JSON ファイルとして保存します。&#x3C;/p>
&#x3C;p>結果がすべて JSON ファイルとして保存してあると、 Gatsby の特徴である、静的ページの生成と、 Single Page Application の両立をすることができます。 SPA において、 GraphQL クエリ部分が、実行済みクエリ結果をダウンロードするよう振る舞えば、それ以外はただの React アプリになっているので、普通に React の SPA になってしまうのです。そして静的ページ生成は、 React の Server Side Rendering を行うだけになります。&#x3C;/p>
&#x3C;p>というわけで、なぜ静的サイトジェネレータが GraphQL とかいう大層なものを取り出したのか、までつながりました。納得すると、 Gatsby 悪くないなと思えてきました。&#x3C;/p>
&#x3C;h2>5. ここがつらいよ Gatsby&#x3C;/h2>
&#x3C;p>このブログの構築に必要だったワークアラウンド集です。&#x3C;/p>
&#x3C;h3>5.1. ブラウザにとって静的なサイトになりたい&#x3C;/h3>
&#x3C;p>Gatsby がなぜ GraphQL を使っているのかについては、納得しました。しかし私が作りたいのは React でできたサイトではなく、ブログ本文が書かれた HTML が置いてあるだけのシンプルなブログです。 PWA でプリロード？ 知らん、読むかもわからんページを先読みしたところでたかが知れてるし、そのスクリプト分だけデータ量は増え、ブラウザの負荷もあります。エコじゃない。&#x3C;/p>
&#x3C;p>しかしまぁ、一応は Server Side Rendering 済み HTML が吐き出されるので、やりようでどうにかできます。 &#x3C;a href="https://www.gatsbyjs.org/packages/gatsby-plugin-no-javascript/">gatsby-plugin-no-javascript&#x3C;/a> という過激な名前のサードパーティープラグインがあり、吐き出される HTML の &#x3C;code>script&#x3C;/code> タグを全部消し去ります。今は特に動的な部分はないので、これで満足しています。&#x3C;/p>
&#x3C;p>あと、 SPA という前提に立っているので、デフォルトでは CSS が HTML の &#x3C;code>style&#x3C;/code> タグに全部入っています。外部リソースのダウンロードを減らす目的でしょうけれど、スクリプトを無効化すると、サイト内リンクは React 内でのルーティングではなく普通のリンクになるので、各ページに CSS が埋め込まれていると逆効果になりそうです。そこで &#x3C;code>style&#x3C;/code> タグではなく &#x3C;code>link&#x3C;/code> タグにしておきたいです。 &#x3C;code>link&#x3C;/code> タグへの変換は、ビルド中のフックで、簡単にできます（&#x3C;a href="https://github.com/gatsbyjs/gatsby/issues/1526#issuecomment-583740341">元ネタ&#x3C;/a>）。&#x3C;/p>
&#x3C;figure class="fig-code">
&#x3C;figcaption>gatsby-ssr.js&#x3C;/figcaption>
&#x3C;pre>&#x3C;code class="language-js">&#x3C;span class="hljs-keyword">const&#x3C;/span> &#x3C;span class="hljs-title hljs-class">React&#x3C;/span> = &#x3C;span class="hljs-built_in">require&#x3C;/span>(&#x3C;span class="hljs-string">"react"&#x3C;/span>)

&#x3C;span class="hljs-built_in">exports&#x3C;/span>.&#x3C;span class="hljs-property">onPreRenderHTML&#x3C;/span> = &#x3C;span class="hljs-function">(&#x3C;span class="hljs-params">{ getHeadComponents, replaceHeadComponents }&#x3C;/span>) =>&#x3C;/span> {
  &#x3C;span class="hljs-title hljs-function">replaceHeadComponents&#x3C;/span>(
    &#x3C;span class="hljs-title hljs-function">getHeadComponents&#x3C;/span>().&#x3C;span class="hljs-title hljs-function">map&#x3C;/span>(&#x3C;span class="hljs-function">(&#x3C;span class="hljs-params">el&#x3C;/span>) =>&#x3C;/span> {
      &#x3C;span class="hljs-keyword">if&#x3C;/span> (el.&#x3C;span class="hljs-property">type&#x3C;/span> !== &#x3C;span class="hljs-string">"style"&#x3C;/span>) &#x3C;span class="hljs-keyword">return&#x3C;/span> el
      &#x3C;span class="hljs-keyword">const&#x3C;/span> href = el.&#x3C;span class="hljs-property">props&#x3C;/span>[&#x3C;span class="hljs-string">"data-href"&#x3C;/span>]
      &#x3C;span class="hljs-keyword">return&#x3C;/span> href ? &#x3C;span class="xml">&#x3C;span class="hljs-tag">&#x26;#x3C;&#x3C;span class="hljs-name">link&#x3C;/span> &#x3C;span class="hljs-attr">rel&#x3C;/span>=&#x3C;span class="hljs-string">"stylesheet"&#x3C;/span> &#x3C;span class="hljs-attr">href&#x3C;/span>=&#x3C;span class="hljs-string">{href}&#x3C;/span> />&#x3C;/span>&#x3C;/span> : el
    })
  )
}
&#x3C;/code>&#x3C;/pre>
&#x3C;/figure>
&#x3C;h3>5.2. 公式の AsciiDoc プラグインでは満足できない&#x3C;/h3>
&#x3C;p>Gatsby で AsciiDoc を扱うには、公式より &#x3C;a href="https://www.gatsbyjs.org/packages/gatsby-transformer-asciidoc/">gatsby-transformer-asciidoc&#x3C;/a> プラグインが提供されており、これを使うのが一般的だと思います。しかし、 Header Attribute の取得があまり自由にできず、 &#x3C;code>page-&#x3C;/code> から始まる Header Attribute しか取得できません。これは、 Asciidoctor が使用するような AsciiDoc 的に一般的に用いられる属性と合わせられないという問題のほかに、まだ実装していませんが、数式表示が必要かを表す &#x3C;code>:stem:&#x3C;/code> を取得できないと、数式レンダリングライブラリをロードするべきかの判断ができない問題もあります。&#x3C;/p>
&#x3C;p>この問題については、 gatsby-transformer-asciidoc の代わりを、適当に自作することにしました。 Asciidoctor.js を呼び出すだけなので、そんなに大がかりではありません。&#x3C;/p>
&#x3C;h3>5.3. 「#」を含むパス問題&#x3C;/h3>
&#x3C;p>私のブログなので、今後「C#」といったタグをつけた記事が出てくることが予想されるので、先に実験しておきました。タグのパスは &#x3C;code>/tags/:tag&#x3C;/code> の形式なのですが見事に死亡しました。「#」をエスケープすると 404 になり、エスケープしないとブラウザがフラグメント扱いします。&#x3C;/p>
&#x3C;p>結局、 &#x3C;a href="https://www.gatsbyjs.org/docs/actions/#createPage">&#x3C;code>createPage&#x3C;/code>&#x3C;/a> に渡すパスはエスケープせず、 &#x3C;a href="https://www.gatsbyjs.org/docs/gatsby-link/">&#x3C;code>&#x26;#x3C;Link>&#x3C;/code>&#x3C;/a> に渡すパスはエスケープすることでお茶を濁しました。この方法では、静的サイトとして振る舞う場合は問題なく動作しますが、 SPA として振る舞う場合は死にます。より良い方法があれば教えてください。&#x3C;/p>
&#x3C;p>追記: Netlify にデプロイしようとしたら &#x3C;samp>Deployed filenames cannot contain # or ? characters&#x3C;/samp> と怒られてしまいました。静的ファイルをホスティングするだけの分際で無駄な忖度をするんじゃないという気持ちになったので、 Vercel に移行しました。&#x3C;/p>
&#x3C;h2>6. さいごに&#x3C;/h2>
&#x3C;p>下手な既存ツールで満足できない人間が、自前でブログを構築しようとすると、要求が膨らんで大変だということがよくわかりました。そんな中で、妥協点として Gatsby を採用しました。いくらか不満はありますが、解決できるだけの柔軟性はあるので、これからも仲良くやっていきたいと思います。&#x3C;/p>
&#x3C;p>ブログを構築しようとして、何日を無駄にしたのでしょう。この 4 月より大学院に進学し、これから 2 年間どんな研究をするのかを考える大事な時期に、研究（文献調査）の進捗が出ていません。そんな時期に現実逃避していたら、数年の悲願であった自作ブログ基盤ができてしまいました。せっかくブログを作ったので、いろいろアウトプットできたらいいなぁと思います。&#x3C;/p></content><id>https://blog.azyobuzi.net/2020/04/04/01-hello-gatsby/</id><link href="https://blog.azyobuzi.net/2020/04/04/01-hello-gatsby/" rel="alternate" type="text/html" /><published>2020-04-04T02:29:00+09:00</published><title type="html">さよならはてなブログ、こんにちはGatsby</title><updated>2021-09-27T19:22:31+09:00</updated></entry></feed>